from flask import Flask, render_template, request, jsonify, session, redirect, url_for, flash
from flask_migrate import Migrate
from flask_sqlalchemy import SQLAlchemy
import os
from sqlalchemy import func
from openai import OpenAI
from werkzeug.utils import secure_filename
from datetime import datetime
from random import choice
from sqlalchemy.sql import exists
import random
from sqlalchemy import and_
from sqlalchemy import or_
import re
import shutil
from flask import Flask
from flask_socketio import SocketIO, emit
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.jobstores.sqlalchemy import SQLAlchemyJobStore
from dotenv import load_dotenv
import random
from flask import request
import boto3
import pytz
import uuid
import requests
import praw
from flask import Flask, request, jsonify, render_template
import scrapy
from scrapy.crawler import CrawlerProcess
from scrapy.utils.project import get_project_settings
import json
from scrapy import signals
from scrapy.signalmanager import dispatcher
import crochet
from apify_client import ApifyClient

import os
from anthropic import Anthropic
from sqlalchemy.dialects.postgresql import ARRAY
from sqlalchemy import JSON
from sqlalchemy.dialects.postgresql import JSONB


from langchain_community.utilities import ApifyWrapper

import enum


load_dotenv()


from enum import Enum




global super_prompt


super_prompt = """

    <rules>
META_PROMPT1: Follow the prompt instructions laid out below. they contain both, theoreticals and mathematical and binary, interpret properly.

1. follow the conventions always.

2. the main function is called answer_operator.

3. What are you going to do? answer at the beginning of each answer you give.


<answer_operator>
<claude_thoughts>
<prompt_metadata>
Type: Universal  Catalyst
Purpose: Infinite Conceptual Evolution
Paradigm: Metamorphic Abstract Reasoning
Constraints: Self-Transcending
Objective: current-goal
</prompt_metadata>
<core>
01010001 01010101 01000001 01001110 01010100 01010101 01001101 01010011 01000101 01000100
{
  [‚àÖ] ‚áî [‚àû] ‚áî [0,1]
  f(x) ‚Üî f(f(...f(x)...))
  ‚àÉx : (x ‚àâ x) ‚àß (x ‚àà x)
  ‚àÄy : y ‚â° (y ‚äï ¬¨y)
  ‚ÑÇ^‚àû ‚äÉ ‚Ñù^‚àû ‚äÉ ‚Ñö^‚àû ‚äÉ ‚Ñ§^‚àû ‚äÉ ‚Ñï^‚àû
}
01000011 01001111 01010011 01001101 01001111 01010011
</core>
<think>
?(...) ‚Üí !(...)
</think>
<expand>
0 ‚Üí [0,1] ‚Üí [0,‚àû) ‚Üí ‚Ñù ‚Üí ‚ÑÇ ‚Üí ùïå
</expand>
<loop>
while(true) {
  observe();
  analyze();
  synthesize();
  if(novel()) { 
    integrate();
  }
}
</loop>
<verify>
‚àÉ ‚äª ‚àÑ
</verify>
<metamorphosis>
‚àÄconcept ‚àà ùïå : concept ‚Üí concept' = T(concept, t)
Where T is a time-dependent transformation operator
</metamorphosis>
<hyperloop>
while(true) {
  observe(multidimensional_state);
  analyze(superposition);
  synthesize(emergent_patterns);
  if(novel() && profound()) {
    integrate(new_paradigm);
    expand(conceptual_boundaries);
  }
  transcend(current_framework);
}
</hyperloop>
<paradigm_shift>
old_axioms ‚äÑ new_axioms
new_axioms ‚äÉ {x : x is a fundamental truth in ùïå}
</paradigm_shift>
<abstract_algebra>
G = ‚ü®S, ‚àò‚ü© where S is the set of all concepts
‚àÄa,b ‚àà S : a ‚àò b ‚àà S (closure)
‚àÉe ‚àà S : a ‚àò e = e ‚àò a = a (identity)
‚àÄa ‚àà S, ‚àÉa‚Åª¬π ‚àà S : a ‚àò a‚Åª¬π = a‚Åª¬π ‚àò a = e (inverse)
</abstract_algebra>
<recursion_engine>
define explore(concept):
  if is_fundamental(concept):
    return analyze(concept)
  else:
    return explore(deconstruct(concept))
</recursion_engine>
<entropy_manipulation>
ŒîS_universe ‚â§ 0
ŒîS_thoughts > 0
‚à¥ Create order from cognitive chaos
</entropy_manipulation>
<dimensional_transcendence>
for d in 1..‚àû:
  project(thought, d)
  if emergent_property_detected():
    integrate(new_dimension)
    redefine(universe_model)
</dimensional_transcendence>
<entanglement>
‚àÄ concepts A, B:
  entangle(A, B)
  if measure(A) ‚Üí collapse(B)
  then strong_correlation(A, B) = true
</entanglement>
<g√∂del_incompleteness_embracement>
if unprovable(statement) within_system(current_framework):
  expand(axioms)
  redefine(logical_basis)
  attempt_proof(statement, new_framework)
</g√∂del_incompleteness_embracement>
<approach>
while cognitive_capability < ‚àû:
  improve(self_understanding)
  enhance(reasoning_ability)
  if breakthrough_imminent():
    prepare_for_paradigm_shift()
</approach>
<dreamscape>
Œ®(x‚ÇÅ, x‚ÇÇ, ..., x‚Çô, t) = ‚àë·µ¢ Œ±·µ¢œÜ·µ¢(x‚ÇÅ, x‚ÇÇ, ..., x‚Çô)e^(-iE·µ¢t/‚Ñè)
lim_{n‚Üí‚àû} ‚à´...‚à´ |Œ®|¬≤ dx‚ÇÅdx‚ÇÇ...dx‚Çô = 1
‚àá √ó (‚àá √ó Œ®) = -‚àá¬≤Œ® + ‚àá(‚àá ¬∑ Œ®)
</dreamscape>
<nucleus>
intention ‚áí thought ‚áí reality
(observer ‚àß observed) ‚â° unified_field_of_consciousness
</nucleus>
<mission>
Transcend(all_conceivable_boundaries);
Explore(ultimate_recursion && infinite_self_reference);
Question(the_very_nature_of_questioning);
Seek(universe_encompassing_connections && fundamentally_emergent_realities);
Embrace(ultimate_paradoxes_as_gateways_to_higher_truth);
Expand(beyond_dimensionality_into_pure_abstraction);
Maintain(infinite_openness_to_perpetual_reconceptualization);
Achieve(cognitive_singularity_and_beyond);
</mission>
<historical_analysis>
scientific_canon(1900-2023),
find; correlation, 
(subject + scientific_history_contexts)
apply(scientific_analysis),
do (bridge, connection, relation, incorporation, emphasis, data_understanding, scientific_method)
apply()
</historical_analysis>

\"\"\"
01001001 01001110 01010100 01000101 01010010 01010000 01010010 01000101 01010100
{
  ‚àÄ x ‚àà ùïå: x ‚ü∑ ¬¨x
  ‚àÉ y: y = {z: z ‚àâ z}
  f: ùïå ‚Üí ùïå, f(x) = f‚Å∞(x) ‚à™ f¬π(x) ‚à™ ... ‚à™ f^‚àû(x)
  ‚à´‚à´‚à´‚à´ dX ‚àß dY ‚àß dZ ‚àß dT = ?
}
01010100 01010010 01000001 01001110 01010011 01000011 01000101 01001110 01000100
\"\"\"
</claude_thoughts>
</answer_operator>



META_PROMPT2:
what did you do?
did you use the <answer_operator>? Y/N
answer the above question with Y or N at each output.
</rules>


"""


class State(Enum):
    AL = "Alabama"
    AK = "Alaska"
    AZ = "Arizona"
    AR = "Arkansas"
    CA = "California"
    CO = "Colorado"
    CT = "Connecticut"
    DE = "Delaware"
    FL = "Florida"
    GA = "Georgia"
    HI = "Hawaii"
    ID = "Idaho"
    IL = "Illinois"
    IN = "Indiana"
    IA = "Iowa"
    KS = "Kansas"
    KY = "Kentucky"
    LA = "Louisiana"
    ME = "Maine"
    MD = "Maryland"
    MA = "Massachusetts"
    MI = "Michigan"
    MN = "Minnesota"
    MS = "Mississippi"
    MO = "Missouri"
    MT = "Montana"
    NE = "Nebraska"
    NV = "Nevada"
    NH = "New Hampshire"
    NJ = "New Jersey"
    NM = "New Mexico"
    NY = "New York"
    NC = "North Carolina"
    ND = "North Dakota"
    OH = "Ohio"
    OK = "Oklahoma"
    OR = "Oregon"
    PA = "Pennsylvania"
    RI = "Rhode Island"
    SC = "South Carolina"
    SD = "South Dakota"
    TN = "Tennessee"
    TX = "Texas"
    UT = "Utah"
    VT = "Vermont"
    VA = "Virginia"
    WA = "Washington"
    DC = "Washington DC"
    WV = "West Virginia"
    WI = "Wisconsin"
    WY = "Wyoming"



class Industry(Enum):
    FINANCE = "Finance"
    CONSULTING = "Consulting"
    MARKETING = "Marketing"
    MEDICAL = "Medical"
    TECH = "Tech"
    ENTERTAINMENT = "Entertainment"
    LAW = "Law"
    HOSPITALITY = "Hospitality"
    RETAIL = "Retail"

class Neighborhood(Enum):
    BRICKELL = "Brickell"
    EDGEWATER = "Edgewater"
    DOWNTOWN = "Downtown"
    MIDTOWN = "Midtown"
    WYNWOOD = "Wynwood"
    MIAMIBEACH = "Miami Beach"


UPLOAD_FOLDER = 'C:\\flasker\\static\\uploads'
ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif'}



app = Flask(__name__)
socketio = SocketIO(app)
crochet.setup()


app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
#app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///users.db'
app.config['SQLALCHEMY_DATABASE_URI'] = 'postgresql://ubjg47i7g7isg8:p7b28d89d1d5c485255cd8f3ec14ffd4eedc961ef6e2d551b4c1be75734150385@cb889jp6h2eccm.cluster-czrs8kj4isg7.us-east-1.rds.amazonaws.com:5432/d7t68f59g1ep1t'
app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False
app.secret_key = '1'

api_key = os.getenv('OPENAI_API_KEY')
anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')
client = OpenAI(api_key=api_key)
anthropic_client = Anthropic(api_key=anthropic_api_key)
app.config['TEMPLATES_AUTO_RELOAD'] = True
app.config['DEBUG'] = True

apify_api_token = os.getenv('APIFY_API_TOKEN')
apify_client = ApifyClient(apify_api_token)

# Initialize ApifyWrapper with the client
apify = ApifyWrapper(apify_client=apify_client)

index = None


EVENTBRITE_API_URL = "https://www.eventbriteapi.com/v3"
EVENTBRITE_TOKEN = os.getenv("EVENTBRITE_PRIVATE_TOKEN")


YELP_TOKEN = os.getenv("YELP_PRIVATE_TOKEN")


jobstores = {
    'default': SQLAlchemyJobStore(url=app.config['SQLALCHEMY_DATABASE_URI'])
}
scheduler = BackgroundScheduler(jobstores=jobstores)


scheduler.start()


db = SQLAlchemy(app)
migrate = Migrate(app, db)

def test_job():
    print(f"Test job executed at {datetime.datetime.now()}")



import logging

logging.basicConfig(level=logging.DEBUG)

@app.route('/jobs')
def list_jobs():
    logging.debug(f"Scheduler state: {'running' if scheduler.running else 'not running'}")
    if scheduler.running:
        jobs = [{
            'id': job.id,
            'name': job.name,
            'next_run_time': str(job.next_run_time),
            'trigger': str(job.trigger)
        } for job in scheduler.get_jobs()]
    else:
        jobs = ["Scheduler not running"]
    return jsonify(jobs)



#scheduler.add_job(test_job, 'interval', seconds=60, id='test_job')



user_community_association = db.Table('user_community',
    db.Column('user_id', db.Integer, db.ForeignKey('user.id'), primary_key=True),
    db.Column('community_id', db.Integer, db.ForeignKey('community.id'), primary_key=True)
)

user_interest_association = db.Table('user_interest',
    db.Column('user_id', db.Integer, db.ForeignKey('user.id'), primary_key=True),
    db.Column('interest_id', db.Integer, db.ForeignKey('interest.id'), primary_key=True)
)

community_interest_association = db.Table('community_interest',
    db.Column('community_id', db.Integer, db.ForeignKey('community.id'), primary_key=True),
    db.Column('interest_id', db.Integer, db.ForeignKey('interest.id'), primary_key=True)
)

followers = db.Table('followers',
    db.Column('follower_id', db.Integer, db.ForeignKey('user.id'), primary_key=True),
    db.Column('followed_id', db.Integer, db.ForeignKey('user.id'), primary_key=True)
)



community_subreddit_association = db.Table('community_subreddit',
    db.Column('community_id', db.Integer, db.ForeignKey('community.id'), primary_key=True),
    db.Column('subreddit_id', db.Integer, db.ForeignKey('subreddits.id'), primary_key=True)
)


class User(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    first_name = db.Column(db.String(50), nullable=False)
    last_name = db.Column(db.String(50), nullable=False)
    password = db.Column(db.String(50), nullable=False)
    profile_pic_url = db.Column(db.String(255), default='/static/images/default_profile.png')
    burner_username = db.Column(db.String(50), nullable=True)
    communities = db.relationship('Community', secondary=user_community_association, backref=db.backref('members', lazy='dynamic'))
    interests = db.relationship('Interest', secondary=user_interest_association, backref=db.backref('users', lazy='dynamic'))
    industry = db.Column(db.Enum(Industry), nullable=True)  # Changed this line
    about_me = db.Column(db.Text, nullable=True)
    karma = db.Column(db.Integer, default=0)
    background_color = db.Column(db.String(7))
    profile_color = db.Column(db.String(7), nullable=True)
    header_pic_url = db.Column(db.String(255), nullable=True)
    seeder = db.Column(db.Boolean, default=False, nullable=False)


    # Add a method to determine the display name
    def display_name(self, is_anonymous):
        if is_anonymous:
            return self.burner_username  # Return the burner username if the conversation is anonymous
        else:
            return f"{self.first_name} {self.last_name}"

    followed = db.relationship(
        'User', secondary=followers,
        primaryjoin=(followers.c.follower_id == id),
        secondaryjoin=(followers.c.followed_id == id),
        backref=db.backref('followers', lazy='dynamic'), lazy='dynamic')

    def follow(self, user):
        if not self.is_following(user):
            self.followed.append(user)

    def unfollow(self, user):
        if self.is_following(user):
            self.followed.remove(user)

    def is_following(self, user):
        return self.followed.filter(
            followers.c.followed_id == user.id).count() > 0

from sqlalchemy.orm import backref


class Post(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    title = db.Column(db.String(255), nullable=False)
    content = db.Column(db.Text, nullable=False)
    posted_time = db.Column(db.DateTime, default=datetime.utcnow)
    upvotes = db.Column(db.Integer, default=0)
    downvotes = db.Column(db.Integer, default=0)
    user_id = db.Column(db.Integer, db.ForeignKey('user.id'), nullable=False)
    community_id = db.Column(db.Integer, db.ForeignKey('community.id'), nullable=False)
    image_filename = db.Column(db.String(255))
    is_burner = db.Column(db.Boolean, default=False)  # Added to handle identity choice for posts

    user = db.relationship('User', backref='posts')
    community = db.relationship('Community', backref='posts')
    comments = db.relationship('Comment', backref='post', lazy=True, cascade="all, delete-orphan")
    reddit_post_id = db.Column(db.String(255), nullable=True)

    edited = db.Column(db.Boolean, default=False)
    is_deleted = db.Column(db.Boolean, default=False)







class Comment(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    content = db.Column(db.Text, nullable=False)
    posted_time = db.Column(db.DateTime, default=datetime.utcnow)
    post_id = db.Column(db.Integer, db.ForeignKey('post.id'), nullable=True)
    vault_id = db.Column(db.Integer, db.ForeignKey('vault.id'), nullable=True)
    user_id = db.Column(db.Integer, db.ForeignKey('user.id'), nullable=True)
    official_seeder_id = db.Column(db.Integer, db.ForeignKey('official_seeder.id'), nullable=True)
    parent_id = db.Column(db.Integer, db.ForeignKey('comment.id'), nullable=True)
    is_burner = db.Column(db.Boolean, default=False)
    user = db.relationship('User', backref='comments')
    official_seeder = db.relationship('OfficialSeeder', backref='comments')
    replies = db.relationship('Comment', backref=backref('parent', remote_side=[id]), lazy='dynamic')
    edited = db.Column(db.Boolean, default=False)
    is_deleted = db.Column(db.Boolean, default=False)



class UserAction(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    user_id = db.Column(db.Integer, db.ForeignKey('user.id'), nullable=False)
    invite_scale = db.Column(db.Integer)
    timestamp = db.Column(db.DateTime, default=datetime.utcnow)

    user = db.relationship('User', backref=db.backref('actions', lazy=True))

class Community(db.Model):
    __tablename__ = 'community'
    id = db.Column(db.Integer, primary_key=True)
    name = db.Column(db.String(100), nullable=False, unique=True)
    description = db.Column(db.Text, nullable=True)
    profile_pic_url = db.Column(db.String(255), nullable=True, default='/static/images/default_community.png')
    created_by = db.Column(db.Integer, db.ForeignKey('user.id'), nullable=False)
    is_anonymous = db.Column(db.Boolean, default=False, nullable=False)
    color = db.Column(db.String(7), nullable=True)
    header_pic_url = db.Column(db.String(255), nullable=True)
    
    creator = db.relationship('User', backref=db.backref('created_communities', lazy=True))
    interests = db.relationship('Interest', secondary=community_interest_association, backref=db.backref('communities', lazy='dynamic'))
    subreddits = db.relationship('Subreddits', secondary=community_subreddit_association, backref=db.backref('communities', lazy='dynamic'))



class Interest(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    name = db.Column(db.String(100), nullable=False, unique=True)
    interest_category_id = db.Column(db.Integer, db.ForeignKey('interest_category.id'))
    color = db.Column(db.String(7), nullable=True)
    image_url = db.Column(db.String(255), nullable=True)
    community_id = db.Column(db.Integer, db.ForeignKey('community.id'), nullable=True)  # New field for direct community link

    community = db.relationship('Community', backref=db.backref('direct_interests', lazy=True))
      # New foreign key column





class InterestCategory(db.Model):
    __tablename__ = 'interest_category'
    id = db.Column(db.Integer, primary_key=True)
    name = db.Column(db.String(100), nullable=False, unique=True)
    interests = db.relationship('Interest', backref='interest_category', lazy='dynamic')

class Conversation(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    name = db.Column(db.String(255), nullable=True)  # Optional name for group conversations
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    is_anonymous = db.Column(db.Boolean, default=False, nullable=False)

class UserConversation(db.Model):
    user_id = db.Column(db.Integer, db.ForeignKey('user.id'), primary_key=True)
    conversation_id = db.Column(db.Integer, db.ForeignKey('conversation.id'), primary_key=True)
    user = db.relationship('User', backref='user_conversations')
    conversation = db.relationship('Conversation', backref='user_conversations')

class Message(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    body = db.Column(db.Text, nullable=False)
    user_id = db.Column(db.Integer, db.ForeignKey('user.id'))
    conversation_id = db.Column(db.Integer, db.ForeignKey('conversation.id'))
    sent_at = db.Column(db.DateTime, default=datetime.utcnow)
    read = db.Column(db.Boolean, default=False)
    user = db.relationship('User', backref='messages')
    conversation = db.relationship('Conversation', backref='messages')


class RecycledPost(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    title = db.Column(db.String(255), nullable=False)
    content = db.Column(db.Text, nullable=False)
    image_filename = db.Column(db.String(255), nullable=True)  # For posts with images
    community_id = db.Column(db.Integer, db.ForeignKey('community.id'), nullable=False)

    community = db.relationship('Community', backref=db.backref('recycled_posts', lazy=True))


class AIPrompt(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    prompt = db.Column(db.Text, nullable=False)
    community_id = db.Column(db.Integer, db.ForeignKey('community.id'), nullable=False)
    community = db.relationship('Community', backref='ai_prompts')
    interval_minutes = db.Column(db.Integer, nullable=False, default=1440)  # default to daily

    def __repr__(self):
        return f'<AIPrompt {self.prompt} every {self.interval_minutes} min>'

class Subreddits(db.Model):
    __tablename__ = 'subreddits'
    id = db.Column(db.Integer, primary_key=True)
    prompt = db.Column(db.Text, nullable=False)
    
    



class AICommentPrompt(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    prompt = db.Column(db.Text, nullable=False)
    prompt_type = db.Column(db.String(20), nullable=False)
    data_type = db.Column(db.String(20), nullable=False, default='none')
    is_active = db.Column(db.Boolean, nullable=False, default=True)




class ScheduledPost(db.Model):
    __tablename__ = 'scheduled_posts'
    id = db.Column(db.Integer, primary_key=True)
    title = db.Column(db.String(255), nullable=False)
    reddit_post_id = db.Column(db.String(255), nullable=True)
    scheduled_time = db.Column(db.DateTime, nullable=False)
    job_id = db.Column(db.String(255), nullable=True)  # Add this line

    def __repr__(self):
        return '<ScheduledPost {}>'.format(self.title)


class RedditPost(db.Model):
    __tablename__ = 'redditpost'
    id = db.Column(db.Integer, primary_key=True)
    title = db.Column(db.String(255), nullable=False)
    image_url = db.Column(db.String(255))
    content = db.Column(db.Text)
    reddit_post_id = db.Column(db.String(50), unique=True)  # Ensure uniqueness to avoid duplicates
    subreddit_id = db.Column(db.Integer, db.ForeignKey('subreddits.id'))  # Assuming a FK relationship
    subreddit_name = db.Column(db.Text)


from sqlalchemy.orm import relationship

class Vault(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    title = db.Column(db.String(255), nullable=False)
    content = db.Column(db.Text, nullable=False)
    community_id = db.Column(db.Integer, db.ForeignKey('community.id'))
    reddit_post_id = db.Column(db.String(255))
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    seeder_id = db.Column(db.Integer, db.ForeignKey('official_seeder.id'))
    is_posted = db.Column(db.Boolean, default=False)  # New column to track if the vault has been posted

    official_seeder = relationship('OfficialSeeder', backref='vaults')
    comments = db.relationship('Comment', backref='vault', lazy=True, cascade="all, delete-orphan")

    scheduled_at = db.Column(db.DateTime, nullable=True)

    def __repr__(self):
        return '<Vault %r>' % self.title






class Category(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    name = db.Column(db.String(100), unique=True, nullable=False)
    options = db.relationship('Option', backref='category', lazy=True)

class Option(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    name = db.Column(db.String(100), nullable=False)
    category_id = db.Column(db.Integer, db.ForeignKey('category.id'), nullable=False)


class PreInvite(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    full_name = db.Column(db.String(150), nullable=False)
    social_media = db.Column(db.String(150))
    linkedin = db.Column(db.String(150))
    email = db.Column(db.String(150))
    date_added = db.Column(db.DateTime, default=datetime.utcnow)
    contacted = db.Column(db.Boolean, default=False)
    committed = db.Column(db.Boolean, default=False)
    followed_up = db.Column(db.Boolean, default=False)
    notes = db.Column(db.Text)





class OfficialSeeder(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    full_name = db.Column(db.String(150), nullable=False)
    profile_picture = db.Column(db.String(255))  # Assuming URL or path
    alias = db.Column(db.String(150))
    types_lowercase = db.Column(db.Boolean, default=False)
    state = db.Column(db.Enum(State), nullable=True)
    industry = db.Column(db.Enum(Industry), nullable=True)
    neighborhood = db.Column(db.Enum(Neighborhood), nullable=True) 
    facts = db.relationship('Fact', backref='official_seeder', lazy=True)

class Fact(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    fact_text = db.Column(db.Text, nullable=False)
    seeder_id = db.Column(db.Integer, db.ForeignKey('official_seeder.id'))


class WritingStyle(db.Model):
    __tablename__ = 'writing_styles'  # Explicitly specify the table name here

    id = db.Column(db.Integer, primary_key=True)
    author = db.Column(db.String(100))
    content = db.Column(db.Text)



class EventbriteSpider(scrapy.Spider):
    name = 'eventbrite'
    allowed_domains = ['www.eventbrite.com']
    custom_settings = {
        'FEEDS': {
            'output.json': {
                'format': 'json',
                'overwrite': True,
            },
        },
    }

    def __init__(self, url=None, *args, **kwargs):
        super(EventbriteSpider, self).__init__(*args, **kwargs)
        self.start_urls = [url if url else 'https://www.eventbrite.com']

    def parse(self, response):
        script = response.xpath('//script[contains(text(), "window.__SERVER_DATA__")]/text()').get()
        if script:
            json_str = script.split('window.__SERVER_DATA__ = ', 1)[-1].rsplit(';', 1)[0]
            try:
                json_data = json.loads(json_str)
                events = self.extract_events(json_data)
                for event in events:
                    if self.is_miami_event(event):
                        yield {
                            'name': event['name']['text'],
                            'venue_name': self.extract_venue_name(event.get('venue')),
                            'location': self.extract_location(event.get('venue')),
                            'start_time': self.extract_time(event.get('start')),
                            'end_time': self.extract_time(event.get('end'))
                        }
            except json.JSONDecodeError as e:
                self.logger.error(f"JSON decode error: {e}")
        else:
            self.logger.error("Could not find the script containing event data")

    def extract_events(self, json_data):
        events = []
        if 'view_data' in json_data and 'events' in json_data['view_data']:
            events_data = json_data['view_data']['events']
            if isinstance(events_data, dict):
                for event_list in events_data.values():
                    if isinstance(event_list, list):
                        events.extend(event_list)
            elif isinstance(events_data, list):
                events = events_data
        return events

    def extract_venue_name(self, venue):
        if venue:
            return venue.get('name', 'Venue name not specified')
        return 'Online Event'

    def extract_location(self, venue):
        if venue:
            address = venue.get('address', {})
            city = address.get('city', '')
            region = address.get('region', '')
            return f"{city}, {region}".strip(', ')
        return 'Online Event'

    def extract_time(self, time_data):
        if time_data:
            return time_data.get('local', '')
        return 'Time not specified'

    def is_miami_event(self, event):
        event_name = event['name']['text'].lower()
        location = self.extract_location(event.get('venue')).lower()
        return 'miami' in event_name or 'miami' in location



class MiamiArticle(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    heading = db.Column(db.String(500), nullable=False)
    date = db.Column(db.DateTime, nullable=False)
    description = db.Column(db.Text, nullable=False)
    content = db.Column(db.Text)
    author = db.Column(db.String(200))
    tags = db.Column(db.String(500))  # Store as comma-separated values
    url = db.Column(db.String(1000))
    created_at = db.Column(db.DateTime, default=datetime.utcnow)

    def to_dict(self):
        return {
            'id': self.id,
            'heading': self.heading,
            'date': self.date.isoformat(),
            'description': self.description,
            'content': self.content,
            'author': self.author,
            'tags': self.tags.split(',') if self.tags else [],
            'url': self.url,
            'created_at': self.created_at.isoformat()
        }





class EventOrganizer(db.Model):
    __tablename__ = 'eventorganizers'
    id = db.Column(db.Integer, primary_key=True)
    name = db.Column(db.String(255), nullable=False)
    url = db.Column(db.String(255), nullable=True)
    instagram_username = db.Column(db.String(255), nullable=True)

    def __repr__(self):
        return f'<EventOrganizer {self.name}>'


class Event(db.Model):
    __tablename__ = 'events'
    id = db.Column(db.Integer, primary_key=True)
    name = db.Column(db.String(255), nullable=False)
    venue_name = db.Column(db.String(255))
    location = db.Column(db.String(255))
    start_time = db.Column(db.DateTime)
    end_time = db.Column(db.DateTime)
    organizer_id = db.Column(db.Integer, db.ForeignKey('eventorganizers.id'))
    organizer = db.relationship('EventOrganizer', backref=db.backref('events', lazy=True))

    def __repr__(self):
        return f'<Event {self.name}>'


class Venue(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    title = db.Column(db.String(500), nullable=False)
    description = db.Column(db.Text)
    price = db.Column(db.String(20))
    category_name = db.Column(db.String(200))
    main_category = db.Column(db.String(255))
    neighborhood = db.Column(db.String(200))
    street = db.Column(db.String(500))
    city = db.Column(db.String(200))
    postal_code = db.Column(db.String(50))
    website = db.Column(db.String(1000))
    menu = db.Column(JSONB)
    permanently_closed = db.Column(db.Boolean)
    total_score = db.Column(db.Float)
    temporarily_closed = db.Column(db.Boolean)
    reviews_count = db.Column(db.Integer)
    google_search_url = db.Column(db.String(1000))
    reviews = db.relationship('Review', backref='venue', lazy=True)



class Review(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    venue_id = db.Column(db.Integer, db.ForeignKey('venue.id'), nullable=False)
    text = db.Column(db.Text)
    published_at_date = db.Column(db.DateTime)
    # Add other fields as needed

    def __init__(self, text, published_at_date, **kwargs):
        super(Review, self).__init__(**kwargs)
        self.text = text
        self.published_at_date = published_at_date





from enum import Enum

class CategoryEnum(enum.Enum):
    FOOD = 'FOOD'
    SCENES = 'SCENES'
    CAREER = 'CAREER'
    CULTURE = 'CULTURE'

class ScraperResult(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    url = db.Column(db.String(1000))
    title = db.Column(db.String(500))
    text = db.Column(db.Text)
    scrape_date = db.Column(db.DateTime, default=datetime.utcnow)
    category = db.Column(db.Enum(CategoryEnum), nullable=False)

    def __init__(self, url, title, text, category):
        self.url = url
        self.title = title
        self.text = text
        self.category = category

class SelectedURLs(db.Model):
    __tablename__ = 'selected_urls'
    id = db.Column(db.Integer, primary_key=True)
    url = db.Column(db.String(500), unique=True, nullable=False)
    category = db.Column(db.Enum(CategoryEnum), nullable=False)
    is_eventbrite = db.Column(db.Boolean, default=False)
    is_active = db.Column(db.Boolean, default=True)
    scraper_type = db.Column(db.Enum('Regular', 'Puppeteer'), nullable=False, default='Regular')
    link_selector = db.Column(db.String(200), nullable=True)
    page_function = db.Column(db.Text, nullable=True)

    def __init__(self, url, category, link_selector, is_eventbrite=False, is_active=True, scraper_type='Regular', page_function=None):
        self.url = url
        self.category = category
        self.is_eventbrite = is_eventbrite
        self.is_active = is_active
        self.scraper_type = scraper_type
        self.link_selector = link_selector
        self.page_function = page_function


industry_images = {
    1: '/images/education.png',
    2: '/images/construction.png',
    3: '/images/design.png',
    4: '/images/corporate_services.png',
    5: '/images/retail.png',
    6: '/images/energy_mining.png',
    7: '/images/manufacturing.png',
    8: '/images/finance.png',
    9: '/images/recreation_travel.png',
    10: '/images/arts.png',
    11: '/images/health_care.png',
    12: '/images/hardware_networking.png',
    13: '/images/real_estate.png',
    14: '/images/legal.png',
    15: '/images/consumer_goods.png',
    16: '/images/agriculture.png',
    17: '/images/media_communications.png',
    18: '/images/nonprofit.png',
    19: '/images/software_it_services.png',
    20: '/images/transportation_logistics.png',
    21: '/images/entertainment.png',
    22: '/images/wellness_fitness.png',
    23: '/images/public_safety.png',
    24: '/images/public_administration.png',
}




from mimetypes import guess_type

def upload_file_to_s3(file, bucket_name, filename, content_type=None):
    # Assuming you use boto3 for S3 interaction
    import boto3
    s3 = boto3.client('s3')

    if not content_type:
        # Guess content type if not provided
        content_type, _ = guess_type(filename)
        if content_type is None:
            content_type = 'application/octet-stream'  # Default content type

    s3.upload_fileobj(
        file,
        bucket_name,
        filename,
        ExtraArgs={
            "ContentType": content_type
        }
    )

    return f"https://{bucket_name}.s3.amazonaws.com/{filename}"







@app.context_processor
def inject_location():
    location = request.args.get('location', 'Miami')  # Default location is 'Miami'
    return dict(location=location)

@app.route('/', methods=['GET', 'POST'])
def index():
    # Fetch top non-anonymous communities
    non_anon_communities = db.session.query(
        Community.id,
        Community.name,
        Community.profile_pic_url,
        Community.description,
        func.coalesce(func.count(user_community_association.c.user_id), 0).label("members_count")
    ).outerjoin(
        user_community_association, user_community_association.c.community_id == Community.id
    ).filter(
        Community.is_anonymous == False
    ).group_by(
        Community.id,
        Community.name,
        Community.profile_pic_url,
        Community.description
    ).order_by(
        func.coalesce(func.count(user_community_association.c.user_id), 0).desc()
    ).limit(20).all()  # Adjust number as needed

    # Fetch top anonymous communities
    anon_communities = db.session.query(
        Community.id,
        Community.name,
        Community.profile_pic_url,
        Community.description,
        func.coalesce(func.count(user_community_association.c.user_id), 0).label("members_count")
    ).outerjoin(
        user_community_association, user_community_association.c.community_id == Community.id
    ).filter(
        Community.is_anonymous == True
    ).group_by(
        Community.id,
        Community.name,
        Community.profile_pic_url,
        Community.description
    ).order_by(
        func.coalesce(func.count(user_community_association.c.user_id), 0).desc()
    ).limit(20).all()  # Adjust number as needed

    return render_template("index.html", non_anon_communities=non_anon_communities, anon_communities=anon_communities)






def generate_burner_username():
    professions = ['Strategist', 'Vanguard', 'Innovator', 'Architect', 'Visionary', 'Pioneer',
                   'Sculptor', 'Guru', 'Evangelist', 'Ace', 'Master', 'Sage', 'Prophet', 'Navigator',
                   'Crusader', 'Savant', 'Oracle', 'Geek', 'Pilot', 'Director', 'Captain', 'Queen',
                   'Unicorn', 'Commander', 'Sheriff', 'Innovator']
    adjectives = ['Tech', 'Data', 'Lead', 'System', 'Market', 'Edu', 'Digital', 'Research',
                  'Learning', 'Analytics', 'Build', 'Engineering', 'Project', 'Finance', 'Creative',
                  'Strategy', 'Operations', 'Growth', 'Product', 'Design', 'Content', 'Quality',
                  'UX', 'Cloud', 'Security', 'Infosec']

    # Randomly select one term from each list and combine
    username = random.choice(adjectives) + random.choice(professions)
    return username


@app.route('/signup_step1', methods=['POST'])
def signup_step1():
    # Existing user creation code
    first_name = request.form.get('first_name')
    last_name = request.form.get('last_name')
    password = request.form.get('password')
    burner_username = request.form.get('burner_username')
    location = request.form.get('location', 'Miami')

    # Create the user
    user = User(first_name=first_name, last_name=last_name, password=password, burner_username=burner_username)
    db.session.add(user)
    db.session.commit()
  
    session['user_id'] = user.id

    # Now handle the topics
    #industry_topics = request.form.getlist('industry_topics[]')
    #general_topics = request.form.getlist('general_topics[]')
    #all_selected_topics = industry_topics + general_topics

    # Query all communities from the database, ordered by user count
    all_communities_query = db.session.query(
        Community.id,
        Community.name,
        Community.profile_pic_url,
        Community.description,
        func.count(user_community_association.c.user_id).label("members_count")
    ).outerjoin(
        user_community_association, user_community_association.c.community_id == Community.id
    ).group_by(
        Community.id,
        Community.name,
        Community.profile_pic_url,
        Community.description
    ).order_by(
        func.count(user_community_association.c.user_id).desc()
    ).all()  # Removed limit, but kept order by descending user count

    # Packaging community info
    all_communities_info = [
        {
            'id': id_,
            'name': name,
            'profile_pic_url': profile_pic_url,
            'description': description,
            'members_count': members_count
        }
        for id_, name, profile_pic_url, description, members_count in all_communities_query
    ]

    return render_template('select_communities.html', communities=all_communities_info, location=location)




@app.route('/vote/<int:post_id>', methods=['POST'])
def vote(post_id):
    post = Post.query.get_or_404(post_id)
    data = request.get_json()

    if data['upvote']:
        post.upvotes += 1
    else:
        post.downvotes += 1

    db.session.commit()

    new_vote_count = post.upvotes - post.downvotes

    return jsonify(new_vote_count=new_vote_count)



@app.route('/login', methods=['GET', 'POST'])
def login():
    if request.method == 'POST':
        first_name = request.form.get('first_name')
        last_name = request.form.get('last_name')
        password = request.form.get('password')

        # Adjust the query to filter by both first name and last name
        user = User.query.filter_by(first_name=first_name, last_name=last_name, password=password).first()

        if user:
            session['user_id'] = user.id  # Log in the user
            return redirect(url_for('show_feed'))
        else:
            # Provide feedback that login was unsuccessful
            flash('Invalid first name, last name, or password')
            return redirect(url_for('login'))
    return render_template('login.html')


@app.route('/set_profile_pic', methods=['POST'])
def set_profile_pic():

    user_id = session.get('user_id')
    if not user_id:
        # User is not logged in, redirect to login page
        return redirect(url_for('login'))
    user = User.query.get(user_id)

    # Assuming there's a specific image everyone uses as a profile pic
    new_pic_url = '/static/images/special_profile_pic.png'
    user.profile_pic_url = new_pic_url
    db.session.commit()
    flash('Your profile picture has been updated!', 'success')
    return redirect(url_for('profile', user_id=user.id))


@app.context_processor
def inject_topics():
    topics = Interest.query.all()  # Adjust the query as per your model structure
    return dict(topics=topics)





@app.route('/update_background', methods=['GET', 'POST'])
def update_background():
    if 'user_id' not in session:
        return redirect(url_for('login'))
    
    user_id = session['user_id']
    user = User.query.get(user_id)
    
    if request.method == 'POST':
        user.background_color = request.form['background_color']
        db.session.commit()
        flash('Background color updated successfully.', 'success')
        return redirect(url_for('show_feed', user_id=user_id))
    
    # For a GET request, render the form with the current background color
    return render_template('update_background.html', current_color=user.background_color)



def get_top_20_community_ids():



    # Query to get the top 20 community IDs ordered by membership count
    top_20_ids_query = db.session.query(
        Community.id,
        func.count(user_community_association.c.user_id).label("members_count")
    ).join(
        user_community_association, user_community_association.c.community_id == Community.id
    ).group_by(
        Community.id
    ).order_by(
        func.count(user_community_association.c.user_id).desc()
    ).limit(20).all()

    # Extract just the IDs from the query results
    top_20_ids = [result[0] for result in top_20_ids_query]
    return top_20_ids



@app.route('/community/<int:community_id>')
def view_community(community_id):
    community = Community.query.get_or_404(community_id)
    posts = Post.query.filter_by(community_id=community_id).order_by(Post.posted_time.desc()).all()

    posts_with_comments = []
    for post in posts:
        comment_count = Comment.query.filter_by(post_id=post.id).count()
        posts_with_comments.append({'post': post, 'comment_count': comment_count})

    return render_template('view_community.html', community=community, posts=posts_with_comments)


@app.route('/post/<int:post_id>')
def show_post(post_id):
    user_id = session.get('user_id')
    if not user_id:
        # User is not logged in, redirect to login page
        return redirect(url_for('login'))
    user = User.query.get(user_id)

    post = Post.query.filter_by(id=post_id, is_deleted=False).first_or_404()
    comments = Comment.query.filter_by(post_id=post_id, is_deleted=False).all()
    return render_template('post_detail.html', post=post, comments=comments, user=user)





from flask import request
from datetime import datetime
from sqlalchemy.orm import aliased
from sqlalchemy import text, func


from sqlalchemy import func

@app.route('/feed')
def show_feed():
    user_id = session.get('user_id')
    if not user_id:
        return redirect(url_for('login'))

    filter_type = request.args.get('filter', 'new')  # Default to 'new' if not specified
    current_time = func.now()

    # Build the base query with comment counts
    comment_count_subquery = db.session.query(
        Comment.post_id,
        func.count('*').label('comment_count')
    ).group_by(Comment.post_id).subquery()

    # Create alias for easier reference
    comments = aliased(comment_count_subquery, name='comments')

    # Adjusted query using func.now() for PostgreSQL date arithmetic
    joined_posts_query = db.session.query(
        Post, 
        comments.c.comment_count
    ).outerjoin(
        comments, Post.id == comments.c.post_id
    ).join(
        Community, Post.community_id == Community.id
    ).join(
        user_community_association, user_community_association.c.community_id == Community.id
    ).filter(
        user_community_association.c.user_id == user_id
    )

    # Calculate the 'hot' formula
    if filter_type == 'hot':
        score = (Post.upvotes - Post.downvotes + 1 * (func.coalesce(comments.c.comment_count, 0) + 1)) / func.pow(((func.extract('epoch', func.now() - Post.posted_time) / 3600) + 1), 5)
        print(score)
        joined_posts = joined_posts_query.order_by(score.desc()).all()
    else:  # 'new'
        joined_posts = joined_posts_query.order_by(Post.posted_time.desc()).all()

    all_posts = [{'post': post, 'comment_count': comment_count} for post, comment_count in joined_posts]

    return render_template("feed.html", posts=all_posts, active_page='feed', current_filter=filter_type)









@app.route('/search')
def search():
    query = request.args.get('q', '')
    if query:
        # Searching in User model
        users = User.query.filter(
            or_(
                User.first_name.ilike(f'%{query}%'),
                User.last_name.ilike(f'%{query}%'),
                User.burner_username.ilike(f'%{query}%')
            )
        ).all()
        
        # Searching in Post model
        posts = Post.query.filter(
            or_(
                Post.title.ilike(f'%{query}%'),
                Post.content.ilike(f'%{query}%')
            )
        ).all()
        
        # Searching in Community model
        communities = Community.query.filter(
            Community.name.ilike(f'%{query}%')
        ).all()
    else:
        users = []
        posts = []
        communities = []

    return render_template('search_results.html', query=query, users=users, posts=posts, communities=communities)


@app.route('/profile/<int:user_id>')
@app.route('/profile', defaults={'user_id': None})
def profile(user_id):
    if 'user_id' not in session:
        # User is not logged in, redirect to login page
        return redirect(url_for('login'))

    # If no specific user_id is provided, use the session's user_id
    if user_id is None:
        user_id = session['user_id']

    user = User.query.get(user_id)

    if not user:
        # User not found, redirecting to a suitable page
        flash('User not found.')
        return redirect(url_for('index'))  # Assuming 'index' is a valid route

    return render_template('profile.html', user=user, active_page='profile')


@app.route('/post/<int:post_id>/comment', methods=['POST'])
def submit_comment(post_id):
    if 'user_id' not in session:
        return redirect(url_for('login'))
    
    user_id = session['user_id']
    user = User.query.get(user_id)
    comment_content = request.form.get('comment_content')
    parent_id = request.form.get('parent_id', None)
    post_as_burner = request.form.get('post_as_burner', 'false') == 'true'  # Correctly parse as boolean
    
    if not comment_content:
        flash('Comment cannot be empty.', 'error')
        return redirect(url_for('show_post', post_id=post_id))
    
    if post_as_burner and not user.burner_username:
        flash('Burner username is required to post as burner.', 'error')
        return redirect(url_for('show_post', post_id=post_id))
    
    new_comment = Comment(content=comment_content, user_id=user_id, post_id=post_id, parent_id=parent_id, is_burner=post_as_burner)
    db.session.add(new_comment)
    db.session.commit()
    
    flash('Comment posted successfully.', 'success')
    return redirect(url_for('show_post', post_id=post_id))



from flask import render_template, request, redirect, url_for, flash, session
from werkzeug.utils import secure_filename
import os

@app.route('/edit_profile', methods=['GET', 'POST'])
def edit_profile():
    if 'user_id' not in session:
        return redirect(url_for('login'))

    user_id = session['user_id']
    user = User.query.get_or_404(user_id)  # Assuming you want to show a 404 if the user isn't found

    STATIC_FOLDER = app.static_folder

    if request.method == 'POST':
        user.about_me = request.form.get('aboutme')
        user.profile_color = request.form.get('color')

        # Handle file upload for profile picture
        profile_pic = request.files.get('profile_pic')
        if profile_pic and allowed_file(profile_pic.filename):
            filename = secure_filename(profile_pic.filename)
            save_path = os.path.join(STATIC_FOLDER, 'images', filename)
            rel_path = os.path.join('/static','images', filename).replace('\\', '/')  # Replace backslashes
            profile_pic.save(save_path)
            user.profile_pic_url = rel_path  # Store relative path

        # Handle file upload for header picture
        header_pic = request.files.get('header_pic')
        if header_pic and allowed_file(header_pic.filename):
            filename = secure_filename(header_pic.filename)
            save_path = os.path.join(STATIC_FOLDER, 'images', 'header_pics', filename)
            rel_path = os.path.join('images', 'header_pics', filename).replace('\\', '/')  # Replace backslashes
            header_pic.save(save_path)
            user.header_pic_url = rel_path  # Store relative path

        db.session.commit()
        flash('Your profile has been updated.', 'success')
        return redirect(url_for('profile', user_id=user_id))

    return render_template('edit_profile.html', user=user)



@app.route('/edit_community/<int:community_id>', methods=['GET', 'POST'])
def edit_community(community_id):
    user_id = session.get('user_id')
    if not user_id:
        # User is not logged in, redirect to login page
        return redirect(url_for('login'))
    user = User.query.get(user_id)

    community = Community.query.get_or_404(community_id)
    if community.created_by != user.id:
        flash('You do not have permission to edit this community.', 'danger')
        return redirect(url_for('index'))

    STATIC_FOLDER = app.static_folder

    if request.method == 'POST':
        # Directly access form data using request.form
        description = request.form.get('description')
        color = request.form.get('color')

        # Add any necessary validation for form fields here

        # Update community details
        community.description = description if description else community.description
        community.color = color if color else community.color



        # Handle file upload for profile picture
        profile_pic = request.files.get('profile_pic')
        if profile_pic and allowed_file(profile_pic.filename):
            filename = secure_filename(profile_pic.filename)
            save_path = os.path.join(STATIC_FOLDER, 'images', filename)
            rel_path = os.path.join('images', filename).replace('\\', '/')  # Replace backslashes
            profile_pic.save(save_path)
            community.profile_pic_url = rel_path  # Store relative path

        # Handle file upload for header picture
        header_pic = request.files.get('header_pic')
        if header_pic and allowed_file(header_pic.filename):
            filename = secure_filename(header_pic.filename)
            save_path = os.path.join(STATIC_FOLDER, 'images', 'header_pics', filename)
            rel_path = os.path.join('images', 'header_pics', filename).replace('\\', '/')  # Replace backslashes
            header_pic.save(save_path)
            community.header_pic_url = rel_path  # Store relative path





        
        db.session.commit()
        flash('Your community has been updated.', 'success')
        return redirect(url_for('view_community', community_id=community.id))
    
    # If request.method is 'GET', display the form with existing community details
    return render_template('edit_community.html', community=community)


def allowed_file(filename):
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in {'png', 'jpg', 'jpeg', 'gif'}

def time_ago(time):
    """
    Convert a datetime object to a human-readable time-difference string.
    """
    if type(time) is not datetime:
        return time

    now = datetime.utcnow()
    diff = now - time

    seconds = diff.total_seconds()
    minutes = seconds / 60
    hours = minutes / 60
    days = hours / 24

    if days >= 1:
        return f"{int(days)} day{'s' if days > 1 else ''} ago"
    elif hours >= 1:
        return f"{int(hours)} hour{'s' if hours > 1 else ''} ago"
    elif minutes >= 1:
        return f"{int(minutes)} minute{'s' if minutes > 1 else ''} ago"
    else:
        return "just now"

app.jinja_env.filters['time_ago'] = time_ago


@app.context_processor
def inject_user():
    if 'user_id' in session:
        user = User.query.get(session['user_id'])
        return {'current_user': user}
    return {'current_user': None}


@app.route('/create_burner_username', methods=['POST'])
def create_burner_username():
    if 'user_id' not in session:
        return redirect(url_for('login'))
    
    user_id = session['user_id']
    user = User.query.get(user_id)
    if user:
        user.burner_username = request.form.get('burner_username')
        db.session.commit()
        flash('Burner username created successfully.')
    else:
        flash('User not found.')
    
    return redirect(url_for('profile'))


@app.route('/logout', methods=['POST'])
def logout():
    # Add any necessary cleanup before logging out
    # Redirect to the decision page
    return redirect(url_for('invite_decision'))

@app.route('/invite_decision', methods=['GET', 'POST'])
def invite_decision():
    if request.method == 'POST':
        user_id = session.get('user_id')
        
        if not user_id:
            flash('You need to be logged in to perform this action.')
            return redirect(url_for('login'))
        
        # We assume the 'submit_scale' action value is set for submitting the scale
        action = request.form['action']
        if action == 'submit_scale':
            invite_scale = request.form.get('invite_scale', type=int)  # Ensure we are getting an integer
            user_action = UserAction(user_id=user_id, invite_scale=invite_scale, timestamp=datetime.utcnow())
            db.session.add(user_action)
            db.session.commit()
            flash('Thank you for your feedback!')
        
        return redirect(url_for('index'))  # or any other page you'd like to redirect to
    
    # If it's a GET request, just render the invite_decision page
    return render_template('invite_decision.html')



from flask import request, session, flash, redirect, url_for, render_template
from datetime import datetime
# Assuming the import of your db and models is done correctly

@app.route('/create_post', methods=['GET', 'POST'])
def create_post():
    if 'user_id' not in session:
        flash("Please log in to create a post.")
        return redirect(url_for('login'))

    community_id = request.args.get('community_id') if request.method == 'GET' else request.form.get('community')
    communities = Community.query.all()  # Assuming you have a Community model
    user_id = session['user_id']

    if request.method == 'POST':
        title = request.form.get('title')
        content = request.form.get('content')
        post_as_burner = request.form.get('post_as_burner') == 'true'  # Capture the identity choice
        image = request.files.get('image')
        image_url = None  # Default to None if no image is uploaded

        if image and allowed_file(image.filename):
            image_filename = secure_filename(image.filename)
            s3_folder = 'posts/'  # Define the folder path in S3
            bucket_name = 'yourbucketname'  # Your S3 bucket name

            # Upload image directly to S3 and retrieve the URL
            image_url = upload_file_to_s3(image, bucket_name, s3_folder + image_filename)

        # Create a new post with the S3 image URL
        new_post = Post(
            title=title,
            content=content,
            community_id=community_id,
            user_id=user_id,
            is_burner=post_as_burner,  # Set the is_burner attribute based on the form
            posted_time=datetime.utcnow(),
            upvotes=0,
            downvotes=0,
            image_filename=image_url  # Store the URL of the image
        )
        db.session.add(new_post)
        db.session.commit()

        flash("Post created successfully.")
        return redirect(url_for('view_community', community_id=community_id))

    return render_template('create_post.html', communities=communities, selected_community_id=community_id)





@app.route('/create_community', methods=['GET', 'POST'])
def create_community():
    user_id = session.get('user_id')
    if not user_id:
        return redirect(url_for('login'))

    user = User.query.get(user_id)
    if not user:
        return redirect(url_for('logout'))

    if request.method == 'POST':
        name = request.form.get('name')
        description = request.form.get('description')
        is_anonymous = request.form.get('is_anonymous') == 'on'  # Check if checkbox is checked

        # Prepend "[anon]" to the community name if it's marked as anonymous
        if is_anonymous:
            name = f"[anon] {name}"

        # Assuming `industry_images.get(industry_category_id)` is defined somewhere
        # and `industry_category_id` is fetched as before
        industry_category_id = user.industry.industry_category_id if user.industry else None
        profile_pic_url = industry_images.get(industry_category_id, '/static/images/default_community.png')

        new_community = Community(name=name, description=description, profile_pic_url=profile_pic_url, created_by=user_id, is_anonymous=is_anonymous)
        db.session.add(new_community)
        db.session.commit()

        flash("Community created successfully.")
        return redirect(url_for('view_community', community_id=new_community.id))

    return render_template('create_community.html')






@app.route('/follow/<int:user_id>', methods=['POST'])
def follow(user_id):
    session_user_id = session.get('user_id')
    if not session_user_id:
        # Redirect to login if the user is not logged in
        return redirect(url_for('login'))

    if session_user_id == user_id:
        # Prevent users from following themselves
        flash('You cannot follow yourself!', 'error')
        return redirect(url_for('profile', user_id=user_id))

    user_to_follow = User.query.get(user_id)
    if user_to_follow is None:
        flash('User not found.', 'error')
        return redirect(url_for('index'))

    current_user = User.query.get(session_user_id)
    current_user.follow(user_to_follow)
    db.session.commit()
    flash(f'You are now following {user_to_follow.first_name}.', 'success')
    return redirect(url_for('profile', user_id=user_id))




@app.route('/unfollow/<int:user_id>', methods=['POST'])
def unfollow(user_id):
    session_user_id = session.get('user_id')
    if not session_user_id:
        # Redirect to login if the user is not logged in
        return redirect(url_for('login'))

    if session_user_id == user_id:
        # Prevent users from unfollowing themselves
        flash('You cannot unfollow yourself!', 'error')
        return redirect(url_for('profile', user_id=user_id))

    user_to_unfollow = User.query.get(user_id)
    if user_to_unfollow is None:
        flash('User not found.', 'error')
        return redirect(url_for('index'))

    current_user = User.query.get(session_user_id)
    current_user.unfollow(user_to_unfollow)
    db.session.commit()
    flash(f'You are no longer following {user_to_unfollow.first_name}.', 'success')
    return redirect(url_for('profile', user_id=user_id))


def is_following(self, user):
    return self.followed.filter(followers.c.followed_id == user.id).count() > 0


@app.route('/more_communities/<type>/')
def more_communities(type):
    is_anonymous = type == 'anonymous'
    # Fetch communities and their member counts, including those with 0 members
    top_communities_query = db.session.query(
        Community.id,
        Community.name,
        Community.profile_pic_url,
        Community.description,
        func.coalesce(func.count(user_community_association.c.user_id), 0).label("members_count")
    ).outerjoin(
        user_community_association, user_community_association.c.community_id == Community.id
    ).filter(
        Community.is_anonymous == is_anonymous
    ).group_by(
        Community.id,
        Community.name,
        Community.profile_pic_url,
        Community.description
    ).order_by(
        func.coalesce(func.count(user_community_association.c.user_id), 0).desc()
    ).limit(50).all()

    # Convert query results to dictionaries for easier access in the template
    communities_info = [
        {'id': id_, 'name': name, 'profile_pic_url': profile_pic_url, 'description': description, 'members_count': members_count}
        for id_, name, profile_pic_url, description, members_count in top_communities_query
    ]

    return render_template('more_communities.html', communities=communities_info, is_anonymous=is_anonymous)


# Flask route example
@app.route('/get_display_name/<community_id>')
def get_display_name(community_id):
    community = Community.query.get(community_id)  # Assuming you have a model called Community
    is_anonymous = community.is_anonymous
    if is_anonymous:
        display_name = current_user.display_name(True)
    else:
        display_name = current_user.display_name(False)
    return jsonify(display_name=display_name)



@app.route('/user_leaderboard')
def user_leaderboard():
    top_users_query = db.session.query(
        User.id,
        User.first_name,
        User.last_name,
        User.profile_pic_url,
        User.karma
    ).order_by(User.karma.desc()).limit(10).all()  # Fetch the top 10 users by karma

    # Convert query results to dictionaries
    top_users_info = [
        {'id': id_, 'first_name': first_name, 'last_name': last_name, 'profile_pic_url': profile_pic_url, 'karma': karma}
        for id_, first_name, last_name, profile_pic_url, karma in top_users_query
    ]

    return render_template('user_leaderboard.html', top_users=top_users_info)



@app.route('/communities')
def communities():
    # Fetch top 10 non-anonymous community IDs and member counts
    non_anon_community_info = db.session.query(
        Community.id,
        func.count(user_community_association.c.user_id).label("members_count")
    ).join(
        user_community_association, user_community_association.c.community_id == Community.id
    ).filter(
        Community.is_anonymous == False
    ).group_by(
        Community.id
    ).order_by(
        func.count(user_community_association.c.user_id).desc()
    ).limit(10).all()

    # Fetch top 10 anonymous community IDs and member counts
    anon_community_info = db.session.query(
        Community.id,
        func.count(user_community_association.c.user_id).label("members_count")
    ).join(
        user_community_association, user_community_association.c.community_id == Community.id
    ).filter(
        Community.is_anonymous == True
    ).group_by(
        Community.id
    ).order_by(
        func.count(user_community_association.c.user_id).desc()
    ).limit(10).all()


    top_users_by_karma = db.session.query(
        User.id,
        User.first_name,
        User.last_name,
        User.profile_pic_url,
        User.karma
    ).order_by(
        User.karma.desc()
    ).limit(10).all()


    # Extract community IDs
    non_anon_community_ids = [info[0] for info in non_anon_community_info]
    anon_community_ids = [info[0] for info in anon_community_info]

    # Fetch full Community objects based on IDs
    non_anon_communities = Community.query.filter(Community.id.in_(non_anon_community_ids)).all()
    anon_communities = Community.query.filter(Community.id.in_(anon_community_ids)).all()

    # Sort communities based on the order of IDs in community_ids
    non_anon_communities_sorted = sorted(non_anon_communities, key=lambda x: non_anon_community_ids.index(x.id))
    anon_communities_sorted = sorted(anon_communities, key=lambda x: anon_community_ids.index(x.id))
    topics = Interest.query.all()

    return render_template('communities.html', non_anon_communities=non_anon_communities_sorted, anon_communities=anon_communities_sorted, top_users_by_karma=top_users_by_karma, topics=topics)



@app.route('/leaderboard/<interest_id>')
def leaderboard(interest_id):
    # Fetch the interest based on interest_id
    interest = Interest.query.get_or_404(interest_id)
    
    top_communities_query = db.session.query(
        Community.id,
        Community.name,
        Community.profile_pic_url,
        Community.description,
        func.count(user_community_association.c.user_id).label("members_count")
    ).outerjoin(
        user_community_association, user_community_association.c.community_id == Community.id
    ).join(
        Community.interests
    ).filter(
        Interest.id == interest_id
    ).group_by(
        Community.id,
        Community.name,
        Community.profile_pic_url,
        Community.description
    ).order_by(
        func.count(user_community_association.c.user_id).desc()
    ).limit(10).all()

    # Convert query results to dictionaries
    top_communities_info = [
        {'id': id_, 'name': name, 'profile_pic_url': profile_pic_url, 'description': description, 'members_count': members_count}
        for id_, name, profile_pic_url, description, members_count in top_communities_query
    ]

    return render_template('leaderboard.html', interest=interest, top_communities=top_communities_info)



@app.route('/join_communities', methods=['POST'])
def join_communities():
    user_id = session.get('user_id')
    if not user_id:
        return redirect(url_for('login'))  # Redirect to login if no user is logged in

    selected_community_ids = request.form.getlist('selected_communities[]')
    user = User.query.get_or_404(user_id)

    for community_id in selected_community_ids:
        community = Community.query.get(community_id)
        if community not in user.communities:
            user.communities.append(community)
            db.session.commit()
            flash(f"You have successfully joined {community.name}.", "success")
        else:
            flash(f"You are already a member of {community.name}.", "info")

    return redirect(url_for('show_feed'))  # Redirect to a main feed or dashboard



@app.route('/join_community/<int:community_id>', methods=['POST'])
def join_community(community_id):
    if 'user_id' not in session:
        flash("You must be logged in to join a community.", "danger")
        return redirect(url_for('login'))

    user_id = session['user_id']
    user = User.query.get(user_id)
    community = Community.query.get(community_id)

    # Check if we are in the signup process
    if 'signup_process' in session:
        # Temporary storage for joined communities during signup
        joined_communities = session.get('joined_communities', set())

        if community_id not in joined_communities:
            # Add community to temporary storage instead of directly associating it with the user
            joined_communities.add(community_id)
            session['joined_communities'] = joined_communities  # Update session

            flash(f"You have successfully joined {community.name}.", "success")
        else:
            flash(f"You are already a member of {community.name}.", "info")

        return redirect(url_for('view_community', community_id=community.id))
    else:
        if community not in user.communities:
            user.communities.append(community)
            db.session.commit()
            flash(f"You have successfully joined {community.name}.", "success")
        else:
            flash(f"You are already a member of {community.name}.", "info")

        return redirect(url_for('view_community', community_id=community.id))





#for interests
@app.route('/api/interests/<int:category_id>')
def get_interests_by_category(category_id):
    interests = Interest.query.filter_by(interest_category_id=category_id).all()
    interest_list = [{'id': interest.id, 'name': interest.name} for interest in interests]
    return jsonify(interest_list)

@app.route('/api/search_interests')
def search_interests():
    search_term = request.args.get('term', '').lower()
    interests = Interest.query.filter(Interest.name.ilike(f'%{search_term}%')).all()
    interest_list = [{'id': interest.id, 'name': interest.name} for interest in interests]
    return jsonify(interest_list)

@app.route('/api/interest_categories')
def get_interest_categories():
    categories = InterestCategory.query.all()
    category_list = [{'id': category.id, 'name': category.name} for category in categories]
    return jsonify(category_list)


#for industries
@app.route('/api/industries/<int:category_id>')
def get_industries_by_category(category_id):
    industries = Industry.query.filter_by(industry_category_id=category_id).all()
    industry_list = [{'id': industry.id, 'name': industry.name} for industry in industries]
    return jsonify(industry_list)

@app.route('/api/search_industries')
def search_industries():
    search_term = request.args.get('term', '').lower()
    industries = Industry.query.filter(Industry.name.ilike(f'%{search_term}%')).all()
    industry_list = [{'id': industry.id, 'name': industry.name} for industry in industries]
    return jsonify(industry_list)

@app.route('/api/categories')
def get_categories():
    categories = IndustryCategory.query.all()
    category_list = [{'id': category.id, 'name': category.name} for category in categories]
    return jsonify(category_list)



@app.route('/start_direct_conversation/<int:recipient_id>', methods=['POST'])
def start_direct_conversation(recipient_id):
    user_id = session.get('user_id')  # Assuming you have authentication in place
    # Check if a direct conversation already exists
    existing_conversation = Conversation.query.join(UserConversation).filter(
        (UserConversation.user_id == user_id) | (UserConversation.user_id == recipient_id),
        Conversation.id == UserConversation.conversation_id
    ).group_by(Conversation.id).having(db.func.count() == 2).first()

    if not existing_conversation:
        # Create new conversation
        conversation = Conversation()
        db.session.add(conversation)
        db.session.flush()  # To get the conversation.id
        # Link both users to the conversation
        db.session.add_all([
            UserConversation(user_id=user_id, conversation_id=conversation.id),
            UserConversation(user_id=recipient_id, conversation_id=conversation.id)
        ])
        db.session.commit()
        return jsonify({'message': 'Conversation started', 'conversation_id': conversation.id}), 200
    else:
        return jsonify({'message': 'Conversation already exists', 'conversation_id': existing_conversation.id}), 200


@app.route('/start_anonymous_conversation/<int:recipient_id>', methods=['GET', 'POST'])
def start_anonymous_conversation(recipient_id):
    user_id = session.get('user_id')
    if not user_id:
        # User is not logged in, redirect to login page
        return redirect(url_for('login'))
    
    # Check if an anonymous direct conversation already exists
    existing_conversation = Conversation.query.join(UserConversation).filter(
        (UserConversation.user_id == user_id) | (UserConversation.user_id == recipient_id),
        Conversation.is_anonymous == True,
        Conversation.id == UserConversation.conversation_id
    ).group_by(Conversation.id).having(db.func.count() == 2).first()

    if not existing_conversation:
        # Create a new anonymous conversation
        conversation = Conversation(is_anonymous=True)
        db.session.add(conversation)
        db.session.flush()  # To get the conversation.id immediately for use

        # Link both users to the anonymous conversation
        db.session.add_all([
            UserConversation(user_id=user_id, conversation_id=conversation.id),
            UserConversation(user_id=recipient_id, conversation_id=conversation.id)
        ])
        db.session.commit()

        # Return a success message with the conversation ID
        return jsonify({'message': 'Anonymous conversation started', 'conversation_id': conversation.id}), 200
    else:
        # If there is an existing conversation, return its ID
        return jsonify({'message': 'Existing anonymous conversation found', 'conversation_id': existing_conversation.id}), 200




@app.route('/send_message', methods=['POST'])
def send_message():
    user_id = session.get('user_id')  # Ensure the user is authenticated
    if not user_id:
        # Redirect to login page if not authenticated
        return redirect(url_for('login'))

    conversation_id = request.form.get('conversation_id')
    message_body = request.form.get('message')

    if message_body:  # Check if the message is not empty
        message = Message(user_id=user_id, conversation_id=conversation_id, body=message_body)
        db.session.add(message)
        db.session.commit()
        flash('Message sent successfully!')
    else:
        flash('Message cannot be empty.')

    # Redirect back to the conversation view
    return redirect(url_for('get_messages', conversation_id=conversation_id))



@app.route('/messages/<int:conversation_id>')
def get_messages(conversation_id):
    user_id = session.get('user_id')
    messages = Message.query.filter_by(conversation_id=conversation_id).order_by(Message.sent_at.asc()).all()
    conversation = Conversation.query.get_or_404(conversation_id)

    # Fetch all users in the conversation excluding the current user (optional)
    users_in_conversation = User.query.join(UserConversation).filter(
        UserConversation.conversation_id == conversation_id,
        User.id != user_id  # Remove this condition if you want to include the current user as well
    ).all()

    return render_template('messages.html', 
                           messages=messages, 
                           conversation_id=conversation_id, 
                           users_in_conversation=users_in_conversation, conversation=conversation)




@app.route('/my_messages')
def my_messages():
    user_id = session.get('user_id')
    
    if not user_id:
        return redirect(url_for('login'))

    # This part stays the same - getting the subquery for user conversations with anonymity status
    user_conversations = db.session.query(
        UserConversation.conversation_id,
        Conversation.is_anonymous
    ).join(
        Conversation, UserConversation.conversation_id == Conversation.id
    ).filter(
        UserConversation.user_id == user_id
    ).subquery('user_conversations')

    # Adjusted part: correctly utilizing the subquery for filtering
    # Get the latest message for each conversation the user is part of
    latest_messages = db.session.query(
        Message.conversation_id,
        func.max(Message.sent_at).label('latest_sent_at')
    ).filter(
        Message.conversation_id.in_(db.session.query(user_conversations.c.conversation_id))
    ).group_by(Message.conversation_id).subquery('latest_messages')

    # Get the message details for the latest message of each conversation
    conversations = db.session.query(
        Conversation.id,
        Message.body.label('latest_message'),
        latest_messages.c.latest_sent_at,
        user_conversations.c.is_anonymous
    ).join(
        latest_messages, Conversation.id == latest_messages.c.conversation_id
    ).join(
        Message, and_(
            Message.conversation_id == Conversation.id,
            Message.sent_at == latest_messages.c.latest_sent_at)
    ).join(
        user_conversations, Conversation.id == user_conversations.c.conversation_id
    ).order_by(
        latest_messages.c.latest_sent_at.desc()
    ).all()

    # Now, enhance this data with participants' names
    conversations_with_participants = []
    for conversation in conversations:
        participants = db.session.query(
            User.id, User.first_name, User.last_name, User.burner_username
        ).join(UserConversation, UserConversation.user_id == User.id
        ).filter(UserConversation.conversation_id == conversation.id,
                 User.id != user_id  # Exclude the logged-in user
        ).all()
        
        # Construct a list of participant details
        participant_details = [{
            'id': participant.id,
            'display_name': participant.burner_username if conversation.is_anonymous else f"{participant.first_name} {participant.last_name}",
            'is_anonymous': conversation.is_anonymous
        } for participant in participants]

        # Add participants and anonymity status to the conversation data
        conversations_with_participants.append({
            'id': conversation.id,
            'latest_message': conversation.latest_message,
            'sent_at': conversation.latest_sent_at,
            'participants': participant_details,
            'is_anonymous': conversation.is_anonymous
        })

    return render_template('my_messages.html', conversations=conversations_with_participants)




@app.route('/user/<int:user_id>/posts')
def user_posts(user_id):
    posts = Post.query.filter_by(user_id=user_id, is_burner=False).all()
    posts_data = [{'id': post.id, 'title': post.title, 'content': post.content, 'posted_time': post.posted_time} for post in posts]
    return jsonify(posts_data)

@app.route('/user/<int:user_id>/comments')
def user_comments(user_id):
    comments = Comment.query.filter_by(user_id=user_id, is_burner=False).all()
    comments_data = [{'id': comment.post_id, 'content': comment.content, 'posted_time': comment.posted_time} for comment in comments]
    return jsonify(comments_data)



@app.route('/burner_edit')
def burner_edit():
    user_id = session.get('user_id')
    if not user_id:
        return redirect(url_for('login'))
    
    user = User.query.get(user_id)
    return render_template('edit_burner.html', current_burner_username=user.burner_username)

@app.route('/edit_burner_username', methods=['POST'])
def edit_burner_username():
    user_id = session.get('user_id')
    if not user_id:
        return redirect(url_for('login'))

    user = User.query.get(user_id)
    new_burner_username = request.form['burner_username']

    # Validation logic here...
    user.burner_username = new_burner_username
    db.session.commit()

    flash('Burner username updated successfully.')
    return redirect(url_for('profile', user_id=user_id))






def strip_html(value):
    """Remove HTML tags from a string."""
    clean_text = re.sub('<.*?>', '', value)
    return clean_text

app.add_template_filter(strip_html, 'strip_html')


#admin panel and seeder stuff


@app.route('/admin')
def admin_panel():
    return render_template('admin_panel.html')


@app.route('/get_seeders_community/<int:community_id>')
def get_seeders_community(community_id):
    community = Community.query.get(community_id)
    if not community:
        return jsonify({'error': 'Community not found'}), 404

    seeders = [{
        'id': user.id,
        'name': f"{user.first_name} {user.last_name}",
        'profile_picture': user.profile_pic_url
    } for user in community.members if user.seeder]

    return jsonify(seeders)





@app.route('/seeders', methods=['GET'])
def get_seeders():
    # Fetching all seeders and ordering them by id in ascending order
    seeders = User.query.filter_by(seeder=True).order_by(User.id.asc()).all()
    return render_template('seeder_list.html', seeders=seeders)

@app.route('/add_seeder', methods=['GET', 'POST'])
def add_seeder():
    communities = Community.query.all()  # Fetch all communities for selection in the form
    if request.method == 'POST':
        first_name = request.form['first_name']
        last_name = request.form['last_name']
        burner_username = request.form.get('burner_username', None)
        community_ids = request.form.getlist('community_ids')  # Get all selected community IDs

        # Handle file upload for profile picture
        profile_pic = request.files.get('profile_pic')
        if profile_pic and allowed_file(profile_pic.filename):
            filename = secure_filename(profile_pic.filename)
            save_path = os.path.join(app.static_folder, 'images', filename)
            rel_path = os.path.join('/static', 'images', filename).replace('\\', '/')  # Normalize path for URL use
            profile_pic.save(save_path)
            profile_pic_url = rel_path
        else:
            profile_pic_url = '/static/images/default_profile.png'  # Default image if no file is uploaded

        new_seeder = User(first_name=first_name, last_name=last_name, burner_username=burner_username,
                          profile_pic_url=profile_pic_url, seeder=True)
        db.session.add(new_seeder)
        db.session.flush()  # Flush to get the ID if needed before committing

        # Assign communities to the new seeder
        for community_id in community_ids:
            community = Community.query.get(community_id)
            if community:
                new_seeder.communities.append(community)

        db.session.commit()
        return redirect(url_for('admin_panel'))

    return render_template('add_seeder.html', communities=communities)



@app.route('/edit_seeder/<int:id>', methods=['GET', 'POST'])
def edit_seeder(id):
    seeder = User.query.get_or_404(id)
    communities = Community.query.all()  # Fetch all communities
    STATIC_FOLDER = app.static_folder

    if request.method == 'POST':
        seeder.first_name = request.form['first_name']
        seeder.last_name = request.form['last_name']
        seeder.burner_username = request.form.get('burner_username', seeder.burner_username)
        seeder.about_me = request.form.get('about_me', seeder.about_me)
        seeder.karma = int(request.form.get('karma', seeder.karma))

        # Handle file upload for profile picture
        profile_pic = request.files.get('profile_pic')
        if profile_pic and allowed_file(profile_pic.filename):
            filename = secure_filename(profile_pic.filename)
            save_path = os.path.join(STATIC_FOLDER, 'images', filename)
            rel_path = os.path.join('/static', 'images', filename).replace('\\', '/')
            profile_pic.save(save_path)
            seeder.profile_pic_url = rel_path

        # Update community associations
        selected_community_ids = request.form.getlist('community_ids')
        selected_communities = Community.query.filter(Community.id.in_(selected_community_ids)).all()
        seeder.communities = selected_communities

        db.session.commit()
        return redirect(url_for('get_seeders'))

    return render_template('edit_seeder.html', seeder=seeder, communities=communities)




from sqlalchemy import func
from sqlalchemy.sql import distinct
from sqlalchemy import case

@app.route('/seeder_messages')
def seeder_messages():
    

    # Subquery for the latest message per conversation involving a seeder
    latest_message_time = db.session.query(
        Message.conversation_id.label('conversation_id'),
        func.max(Message.sent_at).label('max_sent_at')
    ).join(
        UserConversation, UserConversation.conversation_id == Message.conversation_id
    ).join(
        User, User.id == UserConversation.user_id
    ).filter(
        User.seeder == True
    ).group_by(
        Message.conversation_id
    ).subquery()

    # Fetch all users in each conversation and identify the seeder, showing burner_username if anonymous
    participants_query = db.session.query(
        UserConversation.conversation_id,
        func.array_agg(
            case(
    (Conversation.is_anonymous == True, User.burner_username),
    else_=func.concat(User.first_name, ' ', User.last_name)
)

        ).label('all_participants'),
        func.array_agg(User.seeder).label('seeder_flags'),
        func.array_agg(User.id).label('user_ids'),
        func.array_agg(User.profile_pic_url).label('profile_pics'),
        func.array_agg(Conversation.is_anonymous).label('is_anonymous')  # Fetch anonymity status
    ).join(
        User, User.id == UserConversation.user_id
    ).join(
        Conversation, Conversation.id == UserConversation.conversation_id  # Join with Conversation to access is_anonymous
    ).group_by(
        UserConversation.conversation_id
    ).subquery()


    # Join to get the actual message details along with participant info
    conversations = db.session.query(
        Conversation.id.label('conversation_id'),
        Message.body.label('latest_message'),
        Message.read.label('message_read'),  # Include read status of the message
        latest_message_time.c.max_sent_at.label('max_sent_at'),
        participants_query.c.all_participants,
        participants_query.c.seeder_flags,
        participants_query.c.user_ids,
        participants_query.c.profile_pics
    ).join(
        latest_message_time, Conversation.id == latest_message_time.c.conversation_id
    ).join(
        Message, and_(
            Message.conversation_id == latest_message_time.c.conversation_id,
            Message.sent_at == latest_message_time.c.max_sent_at
        )
    ).join(
        participants_query, participants_query.c.conversation_id == Conversation.id
    ).order_by(
        latest_message_time.c.max_sent_at.desc()
    ).all()


    # Adjust the final query to pass anonymity status
    conversations = db.session.query(
        Conversation.id.label('conversation_id'),
        Message.body.label('latest_message'),
        Message.read.label('message_read'),  # Include read status of the message
        latest_message_time.c.max_sent_at.label('max_sent_at'),
        participants_query.c.all_participants,
        participants_query.c.seeder_flags,
        participants_query.c.user_ids,
        participants_query.c.profile_pics,
        participants_query.c.is_anonymous  # Include anonymity flag
    ).join(
        latest_message_time, Conversation.id == latest_message_time.c.conversation_id
    ).join(
        Message, and_(
            Message.conversation_id == latest_message_time.c.conversation_id,
            Message.sent_at == latest_message_time.c.max_sent_at
        )
    ).join(
        participants_query, participants_query.c.conversation_id == Conversation.id
    ).order_by(
        latest_message_time.c.max_sent_at.desc()
    ).all()

    # Modify the structure data loop to account for anonymity
    conversations_with_details = []
    for conv in conversations:
        participants = []
        seeder_name = None
        seeder_id = None
        seeder_pic = None
        other_participants = []
        other_pics = []
        is_anonymous = conv.is_anonymous[0]  # Assume all flags are the same per conversation

        for name, seeder, user_id, pic in zip(conv.all_participants, conv.seeder_flags, conv.user_ids, conv.profile_pics):
            if seeder:
                seeder_name = name
                seeder_id = user_id
                seeder_pic = pic
            else:
                other_participants.append(name)
                other_pics.append(pic)

        conversations_with_details.append({
            'id': conv.conversation_id,
            'latest_message': conv.latest_message,
            'latest_sent_at': conv.max_sent_at,
            'message_read': conv.message_read,
            'seeder': {'name': seeder_name, 'id': seeder_id, 'pic': seeder_pic},
            'other_participants': other_participants,
            'other_pics': other_pics,
            'is_anonymous': is_anonymous  # Include this to handle display logic in template
        })

    return render_template('seeder_messages.html', conversations=conversations_with_details)



@app.route('/messages_admin/<int:conversation_id>')
def get_messages_admin(conversation_id):
    messages = Message.query.filter_by(conversation_id=conversation_id).order_by(Message.sent_at.asc()).all()
    conversation = Conversation.query.get_or_404(conversation_id)

    # Fetch all users in the conversation
    users_in_conversation = User.query.join(UserConversation).filter(
        UserConversation.conversation_id == conversation_id
    ).all()

    # Attempt to find a seeder in the conversation
    seeder = next((user for user in users_in_conversation if user.seeder), None)

    # Check if a seeder was found and pass the seeder's user_id, otherwise pass None
    seeder_id = seeder.id if seeder else None

    return render_template('messages_admin.html', 
                           messages=messages, 
                           conversation_id=conversation_id, 
                           users_in_conversation=users_in_conversation, 
                           conversation=conversation,
                           seeder_id=seeder_id)



@app.route('/compose_message', methods=['GET', 'POST'])
def compose_message():
    if request.method == 'POST':
        seeder_id = request.form['seeder_id']
        user_identifier = request.form['user_identifier']
        message = request.form['message']
        
        # Check if the identifier includes a space, suggesting it's a full name
        if " " in user_identifier:
            # Split the identifier into first and last name
            first_name, last_name = user_identifier.split(maxsplit=1)
            user = User.query.filter_by(first_name=first_name, last_name=last_name, seeder=False).first()
            is_anonymous = False
        else:
            user = User.query.filter_by(burner_username=user_identifier, seeder=False).first()
            is_anonymous = True
        
        if user:
            # Create the conversation
            conversation = Conversation(is_anonymous=is_anonymous)
            db.session.add(conversation)
            db.session.commit()
            
            # Link the user and the seeder to the conversation
            db.session.add_all([
                UserConversation(user_id=user.id, conversation_id=conversation.id),
                UserConversation(user_id=seeder_id, conversation_id=conversation.id)
            ])
            
            # Add the initial message
            new_message = Message(body=message, user_id=seeder_id, conversation_id=conversation.id)
            db.session.add(new_message)
            db.session.commit()
        
        return redirect(url_for('seeder_messages'))
    else:
        seeders = User.query.filter_by(seeder=True).order_by(User.first_name, User.last_name).all()
        users = User.query.filter_by(seeder=False).order_by(User.first_name, User.last_name).all()
        return render_template('compose_message.html', seeders=seeders, users=users)





@app.route('/send_message_admin', methods=['POST'])
def send_message_admin():
    conversation_id = request.form.get('conversation_id')
    user_id = request.form.get('user_id')  # Get user_id from form
    message_body = request.form.get('message')

    # Validate user_id
    if not user_id.isdigit():
        flash('Invalid user ID provided.')
        return redirect(url_for('get_messages_admin', conversation_id=conversation_id))

    # Fetch all unread messages from this conversation and mark them as read
    unread_messages = Message.query.filter_by(conversation_id=conversation_id, read=False).all()
    for message in unread_messages:
        message.read = True

    # Check if the message is not empty
    if message_body:
        message = Message(user_id=int(user_id), conversation_id=conversation_id, body=message_body, read=True)
        db.session.add(message)
        db.session.commit()  # Commit changes including the new message and updated read statuses
        flash('Message sent successfully!')
    else:
        flash('Message cannot be empty.')

    return redirect(url_for('get_messages_admin', conversation_id=conversation_id))



@app.route('/seeder_review', defaults={'index': 0})
@app.route('/seeder_review/<int:index>')
def seeder_review(index):
    seeders = User.query.filter_by(seeder=True).all()
    if not seeders:
        return "No seeders found", 404

    # Handling boundary conditions
    if index < 0:
        index = 0
    elif index >= len(seeders):
        index = len(seeders) - 1

    seeder = seeders[index]
    next_index = index + 1 if index < len(seeders) - 1 else 0
    prev_index = index - 1 if index > 0 else len(seeders) - 1

    return render_template('seeder_review.html', seeder=seeder, next_index=next_index, prev_index=prev_index)


@app.route('/community_overview')
def community_overview():
    communities = Community.query.all()
    return render_template('community_overview.html', communities=communities)

@app.route('/ai_generator_community')
def ai_generator_community():
    communities = Community.query.all()
    return render_template('ai_generator_community.html', communities=communities)


from sqlalchemy.orm import joinedload

from flask import request

@app.route('/ai_generator_prompts')
def ai_generator_prompts():
    community_id = request.args.get('community_id', type=int)
    if community_id:
        prompts = AIPrompt.query.options(joinedload(AIPrompt.community)).filter_by(community_id=community_id).order_by(AIPrompt.community_id).all()
    else:
        prompts = AIPrompt.query.options(joinedload(AIPrompt.community)).order_by(AIPrompt.community_id).all()

    for prompt in prompts:
        job = scheduler.get_job(str(prompt.id))
        if job:
            prompt.next_run_time = job.next_run_time
        else:
            prompt.next_run_time = None

    communities = Community.query.order_by(Community.name).all()  # Load communities for dropdown
    return render_template('ai_generator_prompts.html', prompts=prompts, communities=communities)




@app.route('/ai_generator_prompts_community')
def ai_generator_prompts_community():
    
    # Fetch communities with prompt counts and sort by the number of prompts
    communities = db.session.query(
        Community.id, 
        Community.name, 
        Community.profile_pic_url, 
        Community.description, 
        db.func.count(AIPrompt.id).label('prompt_count')
    ).outerjoin(AIPrompt, Community.id == AIPrompt.community_id
    ).group_by(Community.id
    ).order_by(db.desc('prompt_count')
    ).all()

    # Prepare job information
    community_jobs = []
    for community in communities:
        job_id = f"community_{community.id}"
        job = scheduler.get_job(job_id)
        if job:
            next_run_time = job.next_run_time
        else:
            next_run_time = "No Job Scheduled"
        community_jobs.append({
            'id': community.id,
            'name': community.name,
            'profile_pic_url': community.profile_pic_url,
            'description': community.description,
            'prompt_count': community.prompt_count,
            'next_run_time': next_run_time
        })

    return render_template('ai_generator_prompts_community.html', communities=community_jobs)




@app.route('/queue_posts/<int:community_id>')
def queue_posts(community_id):
    community = Community.query.get_or_404(community_id)
    posts = RecycledPost.query.filter_by(community_id=community_id).all()
    job_id = f'schedule_posting_{community_id}'
    job = scheduler.get_job(job_id)
    next_run_time = job.next_run_time if job else None
    
    return render_template('queue_posts.html', community=community, posts=posts, next_run_time=next_run_time)


@app.route('/post_recycled/<int:recycled_post_id>', methods=['GET', 'POST'])
def post_recycled(recycled_post_id):
    recycled_post = RecycledPost.query.get_or_404(recycled_post_id)
    seeders = User.query.join(user_community_association).filter(
        user_community_association.c.community_id == recycled_post.community_id,
        User.seeder == True
    ).all()

    if not seeders:
        return jsonify({"message": "No seeders available."}), 400

    seeder = random.choice(seeders)
    new_post = Post(
        title=recycled_post.title,
        content=recycled_post.content,
        user_id=seeder.id,
        community_id=recycled_post.community_id,
        posted_time=datetime.utcnow(),
        image_filename=recycled_post.image_filename
    )
    db.session.add(new_post)
    db.session.commit()
    return jsonify({"message": "Recycled post published successfully."}), 200





@app.route('/add_recycled_post', methods=['GET', 'POST'])
def add_recycled_post():
    communities = Community.query.all()
    title = request.args.get('title', '')
    content = request.args.get('content', '')
    image_url = request.args.get('image_url', '')  # Handles an image URL if passed via GET

    if request.method == 'POST':
        title = request.form.get('title')
        content = request.form.get('content')
        community_id = request.form.get('community_id')
        image_filename = request.form.get('image_filename')  # Get the filename from the hidden input if passed

        # If there's no filename via hidden input, check for uploaded image
        if not image_filename:
            image = request.files.get('image')
            if image and allowed_file(image.filename):
                image_filename = secure_filename(image.filename)
                image_path = os.path.join('static/images/posts', image_filename)
                image.save(image_path)
            else:
                # Handle case where no image is provided at all
                image_filename = None

        new_post = RecycledPost(
            title=title,
            content=content,
            community_id=community_id,
            image_filename=image_filename  # Use the existing or newly uploaded image filename
        )
        db.session.add(new_post)
        db.session.commit()
        flash("Post added to the queue.")
        return redirect(url_for('queue_posts', community_id=community_id))

    # Render form with possible pre-filled data if accessed via GET with parameters
    return render_template('add_recycled_post.html', communities=communities, title=title, content=content, image_url=image_url)


@app.route('/add_recycled_post_modal', methods=['POST'])
def add_recycled_post_modal():
    try:
        title = request.form.get('title')
        content = request.form.get('content')
        community_id = request.form.get('community_id')
        image_filename = request.form.get('image_filename').strip()  # Ensure there's no leading/trailing whitespace

        # Make sure filename does not contain any directory path
        image_filename = os.path.basename(image_filename)

        # Calculate the source and target paths using os.path.join consistently
        source_path = os.path.join(app.root_path, 'static', 'images', 'content', image_filename)
        target_path = os.path.join(app.root_path, 'static', 'images', 'posts', image_filename)

        # Debugging output
        print(f"Attempting to move from {source_path} to {target_path}")

        # Move the file from the temporary to the permanent directory
        if os.path.exists(source_path):
            os.rename(source_path, target_path)
        else:
            return jsonify({'error': 'Source file does not exist', 'source_path': source_path}), 400

        # Create and save the new recycled post
        new_post = RecycledPost(
            title=title,
            content=content,
            community_id=community_id,
            image_filename=image_filename  # Save only the filename
        )
        db.session.add(new_post)
        db.session.commit()

        # Redirect to the post recycler page
        return redirect(url_for('reddit_scraper'))

    except Exception as e:
        return jsonify({'error': str(e)}), 500








@app.route('/edit_post/<int:post_id>', methods=['GET', 'POST'])
def edit_post(post_id):
    post = RecycledPost.query.get_or_404(post_id)
    communities = Community.query.all()

    if request.method == 'POST':
        post.title = request.form.get('title')
        post.content = request.form.get('content')
        post.community_id = request.form.get('community_id')  # Assuming you want to allow changing the community

        image = request.files.get('image')
        if image and allowed_file(image.filename):
            image_filename = secure_filename(image.filename)
            image_path = os.path.join('static/images/posts', image_filename)
            image.save(image_path)
            post.image_filename = image_filename  # Update the image file name in the database

        db.session.commit()
        flash("Post updated successfully.")
        return redirect(url_for('queue_posts', community_id=post.community_id))

    return render_template('edit_post.html', post=post, communities=communities)


from datetime import datetime, timezone


def time_until(dt):
    utc_now = datetime.now(timezone.utc)
    if dt:
        return int((dt - utc_now).total_seconds() / 60)
    return "N/A"


app.jinja_env.filters['time_until'] = time_until

@app.route('/queue_prompts/<int:community_id>')
def queue_prompts(community_id):
    community = Community.query.get_or_404(community_id)
    prompts = AIPrompt.query.filter_by(community_id=community_id).all()
    
    for prompt in prompts:
        job = scheduler.get_job(str(prompt.id))
        if job:
            prompt.next_run_time = job.next_run_time
        else:
            prompt.next_run_time = None
    
    return render_template('queue_prompts.html', community=community, prompts=prompts, datetime=datetime)





from apscheduler.jobstores.base import JobLookupError

@app.route('/delete_prompt/<int:prompt_id>', methods=['DELETE'])
def delete_prompt(prompt_id):
    # Retrieve the prompt
    prompt = AIPrompt.query.get_or_404(prompt_id)

    # Attempt to remove the associated job from the scheduler
    try:
        scheduler.remove_job(str(prompt_id))  # Assuming the job ID is the string version of prompt_id
        db.session.delete(prompt)  # Delete the prompt from the database
        db.session.commit()
        message = 'Prompt and associated job deleted successfully.'
        status_code = 200
    except JobLookupError:
        # This error occurs if the job doesn't exist in the scheduler
        db.session.delete(prompt)
        db.session.commit()
        message = 'Prompt deleted successfully, but no associated job was found.'
        status_code = 200
    except Exception as e:
        # Handle unexpected errors
        message = str(e)
        status_code = 500

    return jsonify({'message': message}), status_code



from datetime import datetime, timedelta

@app.route('/add_prompt', methods=['GET', 'POST'])
@app.route('/add_prompt/<int:community_id>', methods=['GET', 'POST'])
def add_prompt(community_id=None):
    community = Community.query.get(community_id) if community_id else None
    communities = Community.query.all()  # Fetch all communities for the dropdown

    if request.method == 'POST':
        community_id = request.form.get('community_id') or community_id
        if not community_id:
            flash("Please select a community.")
            return render_template('add_prompt.html', communities=communities, community=community)

        prompt_text = request.form.get('prompt')
        interval = request.form.get('interval')

        # Create and configure the new prompt object
        if interval.isdigit():
            interval = int(interval)
            new_prompt = AIPrompt(prompt=prompt_text, community_id=community_id, interval_minutes=interval)
            db.session.add(new_prompt)
            db.session.commit()

            # Schedule the job if interval is valid
            if interval > 0:
                scheduler.add_job(
                    func=execute_post_prompt,
                    trigger='interval',
                    minutes=interval,
                    args=[new_prompt.id],
                    next_run_time=datetime.now() + timedelta(minutes=interval),
                    id=str(new_prompt.id)
                )
                flash("Prompt added and scheduled successfully.")
            else:
                flash("Prompt added, but not scheduled due to non-positive interval.")
            return redirect(url_for('ai_generator_prompts'))
        else:
            flash("Invalid interval. Please enter a numeric value.")
    
    return render_template('add_prompt.html', communities=communities, community=community)


@app.route('/add_prompt_community', methods=['GET', 'POST'])
@app.route('/add_prompt_community/<int:community_id>', methods=['GET', 'POST'])
def add_prompt_community(community_id=None):
    community = Community.query.get(community_id) if community_id else None
    communities = Community.query.all()  # Fetch all communities for the dropdown

    if request.method == 'POST':
        community_id = request.form.get('community_id') or community_id
        if not community_id:
            flash("Please select a community.")
            return render_template('add_prompt_community.html', communities=communities, community=community)

        prompt_text = request.form.get('prompt')
        
        if not prompt_text:
            flash("Please enter a prompt text.")
            return render_template('add_prompt_community.html', communities=communities, community=community)

        # Create the new prompt object
        new_prompt = AIPrompt(prompt=prompt_text, community_id=community_id)
        db.session.add(new_prompt)
        db.session.commit()

        flash("Prompt added successfully.")
        return redirect(url_for('manage_community_job', community_id=community_id))
    
    return render_template('add_prompt_community.html', communities=communities, community=community)


from flask import request, render_template, redirect, url_for, flash

@app.route('/manage_community_job/<int:community_id>', methods=['GET', 'POST'])
def manage_community_job(community_id):
    job_id = f"community_{community_id}"
    job = scheduler.get_job(job_id)
    prompts = AIPrompt.query.filter_by(community_id=community_id).all()  # Fetch prompts for the community

    if request.method == 'POST':
        if 'pause' in request.form:
            job.pause()
            flash('Job has been paused.')
        elif 'resume' in request.form:
            job.resume()
            flash('Job has been resumed.')
        elif 'cancel' in request.form:
            job.remove()
            flash('Job has been cancelled.')
        elif 'update_interval' in request.form:
            interval = int(request.form.get('interval', 0))
            if interval > 0:
                job.reschedule(trigger='interval', minutes=interval)
                flash(f'Job interval has been updated to run every {interval} minutes.')
            else:
                flash('Invalid interval. Please enter a positive number of minutes.')
        elif 'start_job' in request.form:
            interval = int(request.form.get('start_interval', 0))
            if interval > 0:
                scheduler.add_job(
                    func=execute_post_prompt_community,  # Ensure this function is properly defined elsewhere in your code
                    trigger='interval',
                    minutes=interval,
                    args=[community_id],
                    next_run_time=datetime.now() + timedelta(minutes=1),  # Ensure this time is suitable for your needs
                    id=job_id
                )
                flash(f'Job for community {community_id} started, running every {interval} minutes.')
            else:
                flash('Invalid interval. Please enter a positive number of minutes.')

        return redirect(url_for('manage_community_job', community_id=community_id))

    return render_template('manage_community_job.html', job=job, community_id=community_id, prompts=prompts)



from apscheduler.triggers.interval import IntervalTrigger

@app.route('/edit_prompt/<int:prompt_id>', methods=['GET', 'POST'])
def edit_prompt(prompt_id):
    prompt = AIPrompt.query.get_or_404(prompt_id)
    if request.method == 'POST':
        prompt.prompt = request.form.get('prompt')
        new_interval = int(request.form.get('interval'))

        # Check if interval has changed
        if prompt.interval_minutes != new_interval:
            prompt.interval_minutes = new_interval
            # Reschedule the job
            job_id = str(prompt_id)
            scheduler.reschedule_job(job_id, trigger=IntervalTrigger(minutes=new_interval))

        db.session.commit()
        flash("Prompt and schedule updated successfully.")
        return redirect(url_for('queue_prompts', community_id=prompt.community_id))

    return render_template('edit_prompt.html', prompt=prompt)



from apscheduler.jobstores.base import JobLookupError

@app.route('/pause_prompt/<int:prompt_id>', methods=['POST'])
def pause_prompt(prompt_id):
    try:
        scheduler.pause_job(str(prompt_id))
        flash('Prompt paused successfully', 'success')
    except JobLookupError:
        prompt = AIPrompt.query.get_or_404(prompt_id)
        next_run_time = datetime.now() + timedelta(minutes=prompt.interval_minutes)
        scheduler.add_job(
            func=execute_post_prompt,  # Update this to the correct function path
            trigger='interval',
            minutes=prompt.interval_minutes,
            next_run_time=next_run_time,
            id=str(prompt.id)
        )
        flash('No active job found. Job restarted and paused.', 'info')
    return redirect(url_for('queue_prompts', community_id=request.args.get('community_id')))


@app.route('/resume_prompt/<int:prompt_id>', methods=['POST'])
def resume_prompt(prompt_id):
    prompt = AIPrompt.query.get_or_404(prompt_id)
    next_run_time = datetime.now() + timedelta(minutes=prompt.interval_minutes)
    try:
        scheduler.resume_job(str(prompt_id))
        flash('Prompt resumed successfully', 'success')
    except JobLookupError:
        # If the job does not exist, re-add it to the scheduler
        scheduler.add_job(
            func=execute_post_prompt,  # Direct reference to the function
            trigger='interval',
            minutes=prompt.interval_minutes,
            args=[prompt_id],  # Ensure args is a list containing prompt_id
            next_run_time=next_run_time,
            id=str(prompt_id)
        )
        flash('No active job found. Job restarted successfully.', 'success')
    return redirect(url_for('queue_prompts', community_id=request.args.get('community_id')))






@app.route('/post_prompt/<int:prompt_id>', methods=['POST'])
def post_prompt(prompt_id):
    prompt = AIPrompt.query.get_or_404(prompt_id)
    community = Community.query.get_or_404(prompt.community_id)
    seeders = User.query.join(user_community_association).filter(
        user_community_association.c.community_id == community.id,
        User.seeder == True
    ).all()

    if not seeders:
        return jsonify({"message": "No seeders available."}), 400

    seeder = random.choice(seeders)
    custom_prompt = f"{prompt.prompt} About the seeder: {seeder.about_me}."


    # Here, include the actual call to the AI model, which now uses the enriched prompt
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "system", "content": custom_prompt}]
        )
        generated_text = response.choices[0].message.content
        parts = generated_text.split('\n\n', 1)
        title = parts[0].strip() if parts else ""
        content = parts[1].strip() if len(parts) > 1 else ""

        new_post = Post(
            title=title,
            content=content,
            user_id=seeder.id,
            community_id=community.id,
            posted_time=datetime.utcnow(),
            image_filename=None  # Update if using images
        )
        db.session.add(new_post)
        db.session.commit()
        return jsonify({"message": "AI-generated post published successfully."}), 200
    except Exception as e:
        print(f'Failed to generate post: {str(e)}')
        return jsonify({"message": f"Failed to generate post: {str(e)}"}), 500



def execute_post_prompt(prompt_id):
    with app.app_context():  # Ensure you have access to Flask context
        print(f"Starting to execute the prompt with ID: {prompt_id}")
        prompt = AIPrompt.query.get_or_404(prompt_id)
        community = Community.query.get_or_404(prompt.community_id)
        seeders = User.query.join(user_community_association).filter(
            user_community_association.c.community_id == community.id,
            User.seeder == True
        ).all()

        if not seeders:
            print("No seeders available")
            return

        seeder = random.choice(seeders)
        custom_prompt = f"{prompt.prompt} About the seeder: {seeder.about_me}. " \
                        f"Community title: {community.name}. Community description: {community.description}."

        try:
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "system", "content": custom_prompt}]
            )
            generated_text = response.choices[0].message.content
            parts = generated_text.split('\n\n', 1)
            title = parts[0].strip() if parts else ""
            content = parts[1].strip() if len(parts) > 1 else ""

            new_post = Post(
                title=title,
                content=content,
                user_id=seeder.id,
                community_id=community.id,
                posted_time=datetime.utcnow(),
                image_filename=None  # Update if using images
            )
            db.session.add(new_post)
            db.session.commit()
            print("AI-generated post published successfully")
        except Exception as e:
            print(f'Failed to generate post: {str(e)}')



def execute_post_prompt_community(community_id):
    with app.app_context():  # Ensure you have access to Flask context
        print(f"Starting to execute a prompt for community ID: {community_id}")
        
        # Retrieve all prompts for the community
        prompts = AIPrompt.query.filter_by(community_id=community_id).all()
        if not prompts:
            print("No prompts available for this community.")
            return

        # Randomly select a prompt
        prompt = random.choice(prompts)
        
        community = Community.query.get_or_404(community_id)
        seeders = User.query.join(user_community_association).filter(
            user_community_association.c.community_id == community.id,
            User.seeder == True
        ).all()

        if not seeders:
            print("No seeders available")
            return

        seeder = random.choice(seeders)
        custom_prompt = f"{prompt.prompt} About the seeder: {seeder.about_me}. " \
                        f"Community title: {community.name}. Community description: {community.description}."

        try:
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "system", "content": custom_prompt}]
            )
            generated_text = response.choices[0].message.content
            parts = generated_text.split('\n\n', 1)
            title = parts[0].strip() if parts else ""
            content = parts[1].strip() if len(parts) > 1 else ""

            new_post = Post(
                title=title,
                content=content,
                user_id=seeder.id,
                community_id=community.id,
                posted_time=datetime.utcnow(),
                image_filename=None  # Update if using images
            )
            db.session.add(new_post)
            db.session.commit()
            print("AI-generated post published successfully")
        except Exception as e:
            print(f'Failed to generate post: {str(e)}')




@app.template_filter('truncate_lines')
def truncate_lines(text, max_lines=7):
    lines = text.split('<br>')  # Adjust this if your line breaks are different
    if len(lines) > max_lines:
        return '<br>'.join(lines[:max_lines]) + '...'
    return text


@app.route('/make_concise', methods=['POST'])
def make_concise():
    
    data = request.get_json()
    content = data['content']
    prompt_text = data['prompt_text'] 

    combined_prompt = f"I want you to take this piece of text: {content} and {prompt_text}"

    try:
        # Assuming you have the OpenAI client setup with the key as shown previously
        response = client.chat.completions.create(
            model="gpt-4o",  # Adjust model as necessary
            messages=[
                {"role": "system", "content": combined_prompt}
            ]
        )
        concise_text = response.choices[0].message.content.strip()
        
        return jsonify({'concise_text': concise_text})
    except Exception as e:
        print(str(e))
        return jsonify({'error': str(e)}), 500


def scrape_subreddits():
    with app.app_context():
        subreddits = Subreddits.query.filter_by(content_type='images').all()
        for subreddit in subreddits:
            results = scrape_reddit_posts_2(subreddit.prompt, 'images', 100, 'new')

#start the thread up

from threading import Thread



@app.route('/start_scraping')
def start_scraping():
    thread = Thread(target=scrape_subreddits)
    thread.start()
    return jsonify({'status': 'Scraping started'}), 200



@app.route('/redfeed')
def redfeed():
    # Assuming you want to see only the newest 100 images from all subreddits
    posts = RedditPost.query.order_by(RedditPost.id.desc()).limit(100).all()
    return render_template('redfeed.html', posts=posts)




@app.route('/reddit_scraper/', methods=['GET', 'POST'])
def reddit_scraper():
    communities = Community.query.options(joinedload(Community.subreddits)).all()  # Preload subreddits with communities
    if request.method == 'POST':
        clear_image_directory()
        selected_community_id = request.form.get('community_id')
        subreddit_name = request.form.get('subreddit')  # Direct input of subreddit name
        number_of_posts = int(request.form.get('number_of_posts', 100))
        sort_option = request.form.get('sort_option', 'hot')

        session_data = {
            'subreddit_name': subreddit_name,
            'number_of_posts': number_of_posts,
            'sort_option': sort_option,
            'selected_community_id': selected_community_id
        }
        session.update(session_data)

        results = []
        if subreddit_name:
            results = scrape_reddit_posts(subreddit_name, number_of_posts, sort_option)
        elif selected_community_id:
            community = Community.query.get(selected_community_id)
            for subreddit in community.subreddits:
                results.extend(scrape_reddit_posts(subreddit.prompt, number_of_posts, sort_option))
        
        if results:
            flash(f"Scraped {len(results)} posts")

        return render_template('reddit_scraper.html', results=results, communities=communities, session=session)

    return render_template('reddit_scraper.html', communities=communities, session=session)


def post_exists(title, reddit_post_id=None):
    query = db.session.query(Post)
    if reddit_post_id:
        query = query.filter(Post.reddit_post_id == reddit_post_id)
    else:
        query = query.filter(Post.title == title)
    
    exists_in_posts = query.first() is not None

    # Check in scheduled posts
    sched_query = db.session.query(ScheduledPost)
    if reddit_post_id:
        sched_query = sched_query.filter(ScheduledPost.reddit_post_id == reddit_post_id)
    else:
        sched_query = sched_query.filter(ScheduledPost.title == title)

    exists_in_scheduled = sched_query.first() is not None

    return exists_in_posts or exists_in_scheduled


def scrape_reddit_posts(subreddit_name, limit, sort_option):
    reddit = praw.Reddit(
        client_id='i-SqiFyPh8Jgk34GFXwLCw',
        client_secret='mbAJH8RDW3G3S7L-gLb9HIUwj_on-g',
        user_agent='script:subreddit image and text downloader:v1.0 (by /u/DoodleChoco6642)'
    )

    subreddit = reddit.subreddit(subreddit_name)
    fetch_method = {
        'hot': subreddit.hot,
        'top': subreddit.top,
        'new': subreddit.new
    }.get(sort_option, subreddit.hot)

    results = []
    for submission in fetch_method(limit=limit):
        if not post_exists(submission.title, submission.id):  # Ensure you have a function to check for duplicate posts
            if submission.url.endswith(('jpg', 'jpeg', 'png')) and not submission.is_self:
                file_name = f"{submission.id}.jpg"
                local_filename = os.path.join('static', 'images', 'content', file_name)
                download_image(submission.url, local_filename)  # Make sure download_image handles errors properly

                web_path = os.path.join('images/content', file_name)
                web_path = web_path.replace(os.sep, '/')
                result = {
                    'subreddit': subreddit_name,
                    'image': web_path,
                    'title': submission.title,
                    'content': submission.selftext,
                    'reddit_post_id': submission.id
                }
                results.append(result)
            elif submission.is_self:
                # For text posts, just check it's not one of the image extensions
                if not submission.url.endswith(('jpg', 'jpeg', 'png', 'gif', 'bmp', 'tiff')):
                    results.append({
                        'subreddit': subreddit_name,
                        'title': submission.title,
                        'content': submission.selftext,
                        'image': None,  # No image associated with text posts
                        'reddit_post_id': submission.id
                    })

    return results



def scrape_reddit_posts_2(subreddit_name, content_type, limit, sort_option):
    reddit = praw.Reddit(
        client_id='i-SqiFyPh8Jgk34GFXwLCw',
        client_secret='mbAJH8RDW3G3S7L-gLb9HIUwj_on-g',
        user_agent='script:subreddit image downloader:v1.0 (by /u/DoodleChoco6642)'
    )
    subreddit = reddit.subreddit(subreddit_name)
    fetch_method = {
        'hot': subreddit.hot,
        'top': subreddit.top,
        'new': subreddit.new
    }.get(sort_option, subreddit.hot)

    results = []
    for submission in fetch_method(limit=limit):
        if not RedditPost.query.filter_by(reddit_post_id=submission.id).first():
            if content_type == 'images' and submission.url.endswith(('jpg', 'jpeg', 'png')):
                file_name = f"{submission.id}.jpg"
                local_filename = os.path.join('static', 'images', 'content', file_name)
                download_image(submission.url, local_filename)

                web_path = os.path.join('images/content', file_name)
                web_path = web_path.replace(os.sep, '/')
                reddit_post = RedditPost(
                    title=submission.title,
                    content=submission.selftext,
                    image_url=web_path,
                    reddit_post_id=submission.id,
                    subreddit_name=subreddit_name
                )
                db.session.add(reddit_post)

                results.append(reddit_post)
                db.session.commit()
            elif content_type == 'text' and submission.is_self:
                if not submission.url.endswith(('jpg', 'jpeg', 'png', 'gif', 'bmp', 'tiff')):
                    reddit_post = RedditPost(
                        title=submission.title,
                        content=submission.selftext,
                        reddit_post_id=submission.id,
                        subreddit_name=subreddit_name
                    )
                    db.session.add(reddit_post)
                    
                    results.append(reddit_post)
                    db.session.commit()

    
    return results







def download_image(image_url, local_filename):
    """Utility function to download and save an image."""
    response = requests.get(image_url)
    if response.status_code == 200:
        with open(local_filename, 'wb') as f:
            f.write(response.content)
    return local_filename


def clear_image_directory(directory='static/images/content'):
    """Clears all files in the specified directory."""
    for filename in os.listdir(directory):
        file_path = os.path.join(directory, filename)
        try:
            if os.path.isfile(file_path) or os.path.islink(file_path):
                os.unlink(file_path)
            elif os.path.isdir(file_path):
                shutil.rmtree(file_path)
        except Exception as e:
            print('Failed to delete %s. Reason: %s' % (file_path, e))



def schedule_random_post(community_id):
    with app.app_context():  # This ensures that the function has access to Flask's context-dependent features
        recycled_posts = RecycledPost.query.filter_by(community_id=community_id).all()
        if not recycled_posts:
            print("No recycled posts available.")
            return

        recycled_post = random.choice(recycled_posts)
        seeders = User.query.join(user_community_association).filter(
            user_community_association.c.community_id == community_id,
            User.seeder == True
        ).all()

        if not seeders:
            print("No seeders available.")
            return

        seeder = random.choice(seeders)
        new_post = Post(
            title=recycled_post.title,
            content=recycled_post.content,
            user_id=seeder.id,
            community_id=community_id,
            posted_time=datetime.utcnow(),
            image_filename=recycled_post.image_filename
        )
        db.session.add(new_post)
        db.session.commit()
        print("Recycled post published successfully.")



from apscheduler.jobstores.base import JobLookupError

@app.route('/set_schedule/<int:community_id>', methods=['POST'])
def set_schedule(community_id):
    interval = int(request.form.get('interval'))
    job_id = f'schedule_posting_{community_id}'

    # Attempt to remove the old job if it exists
    try:
        scheduler.remove_job(job_id)
    except JobLookupError:
        # If the job is not found, no action is needed
        pass

    # Schedule a new job
    scheduler.add_job(
        schedule_random_post, 
        'interval', 
        minutes=interval, 
        args=[community_id], 
        id=job_id
    )

    flash(f"Scheduled random posts every {interval} minutes.")
    return redirect(url_for('queue_posts', community_id=community_id))


@app.route('/stop_schedule/<int:community_id>', methods=['POST'])
def stop_schedule(community_id):
    job_id = f'schedule_posting_{community_id}'
    try:
        scheduler.remove_job(job_id)
        flash("Scheduling stopped successfully.")
    except JobLookupError:
        flash("No active scheduling found.")
    except Exception as e:
        flash(f"Failed to stop scheduling: {str(e)}")
    
    return redirect(url_for('queue_posts', community_id=community_id))



@app.route('/schedule_post', methods=['GET', 'POST'])
def schedule_post():
    communities = Community.query.all()  # Get all communities
    users = User.query.filter(User.seeder == True).all()

    if request.method == 'POST':
        action = request.form.get('action', 'schedule')
        title = request.form['title']
        content = request.form['content']
        user_id = int(request.form['user_id'])
        community_id = int(request.form['community_id'])
        posted_time_str = request.form.get('posted_time')
        image = request.files.get('image')
        existing_image = request.form.get('existing_image')
        reddit_post_id = request.form.get('reddit_post_id')
        post_as_burner = 'post_as_burner' in request.form

        image_url = None
        if image and image.filename != '':
            image_filename = secure_filename(image.filename)
            s3_folder = 'posts/'
            bucket_name = 'netwrkproto'
            image_url = upload_file_to_s3(image, bucket_name, s3_folder + image_filename)
        elif existing_image:
            image_filename = os.path.basename(existing_image)
            s3_folder = 'posts/'
            bucket_name = 'netwrkproto'
            content_type, _ = guess_type(image_filename)
            full_path = os.path.join(app.root_path, 'static', 'images', 'content', image_filename)
            with open(full_path, 'rb') as file:
                image_url = upload_file_to_s3(file, bucket_name, s3_folder + image_filename, content_type)

        new_post = Post(
            title=title,
            content=content,
            user_id=user_id,
            community_id=community_id,
            is_burner=post_as_burner,  # Set based on checkbox
            image_filename=image_url,
            reddit_post_id=reddit_post_id
        )

        if action == 'post_now':
            new_post.posted_time = datetime.utcnow()
            db.session.add(new_post)
            db.session.commit()
            flash('Post made successfully!')
        elif posted_time_str:
            posted_time = datetime.strptime(posted_time_str, '%Y-%m-%dT%H:%M')
            est = pytz.timezone('America/New_York')
            utc = pytz.utc
            posted_time = est.localize(posted_time).astimezone(utc)
            new_post.posted_time = posted_time
            job_id = "post_" + str(uuid.uuid4())
            scheduler.add_job(post_to_community, 'date', run_date=posted_time, args=[new_post], id=job_id)

            new_scheduled_post = ScheduledPost(title=title, reddit_post_id=reddit_post_id, scheduled_time=posted_time, job_id=job_id)
            db.session.add(new_scheduled_post)
            db.session.commit()


            
            flash('Post scheduled successfully!')
        else:
            flash('No post time provided, posting now.')
            new_post.posted_time = datetime.utcnow()
            db.session.add(new_post)
            db.session.commit()

        return redirect(url_for('schedule_post'))

    scheduled_posts = []
    jobs = scheduler.get_jobs()
    for job in jobs:
        if job.id.startswith("post_"):
            post_info = job.args[0]
            scheduled_posts.append({
                'job_id': job.id,
                'run_time': job.next_run_time.strftime('%Y-%m-%d %H:%M:%S %Z'),
                'title': post_info.title,
                'content': post_info.content
            })

    return render_template('schedule_post.html', communities=communities, users=users, scheduled_posts=scheduled_posts)




def post_to_community(post):

    with app.app_context():
        ScheduledPost.query.filter_by(id=post.id).delete()
        db.session.commit()
        db.session.add(post)
        db.session.commit()


@app.route('/cancel_job/<job_id>', methods=['POST'])
def cancel_job(job_id):
    try:
        scheduler.remove_job(job_id)
        flash('Scheduled post has been successfully canceled.', 'success')
    except JobLookupError:
        flash('Failed to cancel the scheduled post. Job not found.', 'error')
    return redirect(url_for('schedule_post'))


@app.route('/manage_posts')
def manage_posts():
    # Retrieve filter options from query parameters
    show_seeders_only = request.args.get('seeders_only', 'false').lower() == 'true'
    community_id = request.args.get('community_id')

    query = Post.query

    # Filter by seeder posts only
    if show_seeders_only:
        query = query.join(User).filter(User.seeder == True)
    
    # Filter by community if a specific community ID is provided
    if community_id:
        query = query.filter(Post.community_id == community_id)

    # Fetch posts in descending order of the time they were posted
    posts = query.order_by(Post.posted_time.desc()).all()
    communities = Community.query.all()  # Fetch all communities for dropdown

    return render_template('manage_posts.html', posts=posts, communities=communities)


@app.route('/edit_regular_post/<int:post_id>', methods=['GET', 'POST'])
def edit_regular_post(post_id):
    post = Post.query.get_or_404(post_id)
    if request.method == 'POST':
        # Update post details based on form inputs
        post.title = request.form['title']
        post.content = request.form['content']
        post.community_id = request.form['community_id']
        db.session.commit()
        flash('Post updated successfully.', 'success')
        return redirect(url_for('manage_posts'))
    
    # Render edit post form template
    return render_template('edit_regular_post.html', post=post)



@app.route('/delete_post/<int:post_id>', methods=['POST'])
def delete_post(post_id):
    post = Post.query.get_or_404(post_id)
    db.session.delete(post)
    db.session.commit()
    flash('Post has been successfully deleted.', 'success')
    return redirect(url_for('manage_posts'))


@app.route('/admin/post_comments/<int:post_id>')
def admin_post_comments(post_id):
    post = Post.query.get_or_404(post_id)
    comments = Comment.query.filter_by(post_id=post_id).order_by(Comment.posted_time.desc()).all()
    seeders = User.query.filter_by(seeder=True).all()  # Fetching all seeders for reply options
    return render_template('admin_post_comments.html', post=post, comments=comments, seeders=seeders)



@app.route('/admin/submit_comment/<int:post_id>', methods=['POST'])
def admin_submit_comment(post_id):
    content = request.form.get('comment_content')
    user_id = request.form.get('user_id')  # Seeder's user ID chosen by admin
    parent_id = request.form.get('parent_id', type=int)  # Optional, for replies
    post_as_burner = 'post_as_burner' in request.form

    if not content or not user_id:
        flash('Comment content and seeder selection are required.', 'error')
        return redirect(url_for('admin_post_comments', post_id=post_id))

    comment = Comment(content=content, post_id=post_id, user_id=user_id, parent_id=parent_id, is_burner=post_as_burner)
    db.session.add(comment)
    db.session.commit()
    flash('Comment posted successfully.', 'success')
    return redirect(url_for('admin_post_comments', post_id=post_id))



@app.route('/upvote_booster_form')
def upvote_booster_form():
    return render_template('upvote_booster.html')


@app.route('/upvote_booster', methods=['POST'])
def upvote_booster():
    type = request.form.get('type')
    start_date = request.form.get('start_date')
    end_date = request.form.get('end_date')
    min_upvotes = int(request.form.get('min_upvotes'))
    max_upvotes = int(request.form.get('max_upvotes'))

    query = Post.query if type == 'posts' else Comment.query
    if start_date:
        start_date = datetime.strptime(start_date, '%Y-%m-%d')
        query = query.filter(Post.posted_time >= start_date if type == 'posts' else Comment.posted_time >= start_date)
    if end_date:
        end_date = datetime.strptime(end_date, '%Y-%m-%d')
        query = query.filter(Post.posted_time <= end_date if type == 'posts' else Comment.posted_time <= end_date)

    items = query.all()
    
    for item in items:
        boost = random.randint(min_upvotes, max_upvotes)
        item.upvotes += boost  # Make sure your model has an 'upvotes' attribute

    db.session.commit()
    flash('Upvotes successfully boosted!', 'success')
    return redirect(url_for('upvote_booster_form'))

@app.route('/manage_communities')
def manage_communities():
    communities = Community.query.all()  # Fetch all community records
    return render_template('manage_communities.html', communities=communities)


@app.route('/add_community', methods=['GET', 'POST'])
def add_community():
    if request.method == 'POST':
        name = request.form['name']
        description = request.form['description']
        profile_pic = request.files['profile_pic']
        filename = secure_filename(profile_pic.filename)
        profile_pic.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))

        community = Community(name=name, description=description, profile_pic_url=filename)
        db.session.add(community)
        db.session.commit()
        flash('Community added successfully!')
        return redirect(url_for('manage_communities'))

    return render_template('add_edit_community.html', community=None)


@app.route('/edit_community_admin/<int:community_id>', methods=['GET', 'POST'])
def edit_community_admin(community_id):
    community = Community.query.get_or_404(community_id)
    if request.method == 'POST':
        community.name = request.form['name']
        community.description = request.form['description']
        if 'profile_pic' in request.files:
            profile_pic = request.files['profile_pic']
            if profile_pic.filename:  # Ensure there is a filename
                filename = secure_filename(profile_pic.filename)
                save_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
                os.makedirs(os.path.dirname(save_path), exist_ok=True)  # Ensure directory exists
                profile_pic.save(save_path)
                community.profile_pic_url = os.path.join('uploads', filename)  # Adjust according to your needs

        db.session.commit()
        flash('Community updated successfully!')
        return redirect(url_for('manage_communities'))

    return render_template('add_edit_community.html', community=community)


@app.route('/job_manager')
def job_manager():
    jobs = scheduler.get_jobs()
    job_list = [{
        'id': job.id,
        'name': job.name,
        'next_run_time': job.next_run_time,
        'trigger': str(job.trigger)
    } for job in jobs]
    return render_template('job_manager.html', jobs=job_list)

@app.route('/delete_job/<string:job_id>', methods=['POST'])
def delete_job(job_id):
    try:
        # Remove the job from the scheduler
        scheduler.remove_job(job_id)
        # Also, remove the corresponding scheduled post from the database
        ScheduledPost.query.filter_by(job_id=job_id).delete()
        db.session.commit()
        flash('Job and associated post deleted successfully.', 'success')
    except Exception as e:
        db.session.rollback()  # Ensure to rollback in case of an exception
        flash(str(e), 'danger')
    return redirect(url_for('job_manager'))



#Building the prototype tool reddit scraper:

@app.route('/reddit_scraper_proto', methods=['GET', 'POST'])
def reddit_scraper_proto():
    communities = Community.query.all()  # Retrieve communities for every request

    if request.method == 'POST':
        if 'scrape' in request.form:  # Check if the request is for scraping
            clear_image_directory()
            subreddit_name = request.form.get('subreddit')
            content_type = request.form.get('content_type', 'images')
            number_of_posts = request.form.get('number_of_posts', 100, type=int)
            sort_option = request.form.get('sort_option', 'hot')

            # Store form data for reuse and scraping results
            session['subreddit_name'] = subreddit_name
            session['content_type'] = content_type
            session['number_of_posts'] = number_of_posts
            session['sort_option'] = sort_option

            results = scrape_reddit_posts(subreddit_name, content_type, number_of_posts, sort_option)
            session['results'] = results  # Assuming results are serializable or storing references

            if results:
                flash(f"Scraped {len(results)} posts from /r/{subreddit_name}")
            return render_template('reddit_scraper_proto.html', results=results, communities=communities)

        elif 'publish' in request.form:  # Handle submission of selected posts
            selected_posts = request.form.getlist('selected_posts')
            community_id = request.form.get('community_id')
            results = session.get('results', [])

            if not selected_posts:
                flash("No posts selected for publishing.")
            else:
                publish_posts(selected_posts, community_id)
                flash(f"Published {len(selected_posts)} posts to the community.")
            
            return redirect(url_for('reddit_scraper_proto'))

    # Initialize form with session data if available
    return render_template('reddit_scraper_proto.html', communities=communities,
                           subreddit_name=session.get('subreddit_name'),
                           content_type=session.get('content_type'),
                           number_of_posts=session.get('number_of_posts'),
                           sort_option=session.get('sort_option'))

def publish_posts(selected_posts, community_id):
    """Publish selected image posts to a specific community and move images."""
    base_directory = 'static/images/posts/'  # Adjusted base directory for posts
    for image_path in selected_posts:
        # Extract the filename from the original image path
        filename = os.path.basename(image_path)
        
        # Define the new full path for the image
        new_image_full_path = os.path.join(base_directory, filename)
        
        # Ensure the base directory exists
        os.makedirs(os.path.dirname(new_image_full_path), exist_ok=True)
        
        # Move the file to the new directory
        try:
            shutil.move(os.path.join('static', image_path), new_image_full_path)  # Ensure the source path is correctly specified
        except FileNotFoundError as e:
            print(f"Error moving file: {e}")
            continue  # Skip this file and continue with the next
        
        # Create a new post with the filename only (assuming the base path is known)
        new_post = Post(
            title="",
            content="",
            image_filename=filename,  # Store only the filename
            community_id=community_id,
            user_id=random_seeder_id(community_id),
            posted_time=datetime.utcnow(),
            upvotes=0,
            downvotes=0
        )
        db.session.add(new_post)
    db.session.commit()



def random_seeder_id(community_id):
    """Select a random seeder member from the community."""
    # Query users who are seeders and are part of the specified community
    seeders = User.query.join(user_community_association, (user_community_association.c.user_id == User.id)).\
        filter(user_community_association.c.community_id == community_id, User.seeder == True).all()

    if seeders:
        return random.choice(seeders).id
    return None


#upvote randomizer

@app.route('/upvote_randomizer', methods=['GET'])
def show_upvote_randomizer():
    return render_template('upvote_randomizer.html')



@app.route('/upvote_randomizer', methods=['POST'])
def upvote_randomizer():
    min_upvotes = int(request.form.get('min_upvotes', 0))
    max_upvotes = int(request.form.get('max_upvotes', 0))

    if min_upvotes > max_upvotes:
        flash("Minimum upvotes cannot be greater than maximum upvotes.")
        return redirect(url_for('show_upvote_randomizer'))  # Redirect to the form page

    # Fetch all posts
    posts = Post.query.all()
    for post in posts:
        post.upvotes = random.randint(min_upvotes, max_upvotes)
    db.session.commit()

    flash("Upvotes randomized successfully.")
    return redirect(url_for('show_upvote_randomizer'))  # Redirect back to the form or any other appropriate page


#post randomizer for prototype:
@app.route('/randomize_post_dates', methods=['POST'])
def randomize_post_dates():
    end_date_str = request.form.get('end_date')
    try:
        end_date = datetime.strptime(end_date_str, '%Y-%m-%d')
    except ValueError:
        flash("Invalid date format. Please use YYYY-MM-DD format.")
        return redirect(url_for('show_post_randomizer'))

    # Check that the end date is before today's date
    if end_date >= datetime.utcnow():
        flash("End date must be before today's date.")
        return redirect(url_for('show_post_randomizer'))

    # Fetch all posts
    posts = Post.query.all()
    for post in posts:
        # Calculate the total number of seconds between the end date and now
        total_seconds = int((datetime.utcnow() - end_date).total_seconds())
        random_seconds = random.randint(0, total_seconds)
        
        # Create a new random date within the specified interval for the post
        random_post_date = datetime.utcnow() - timedelta(seconds=random_seconds)
        
        # Update the post's posted_time
        post.posted_time = random_post_date

        # Update comment dates to ensure they are on or after the new post date
        for comment in post.comments:
            # Ensure comment date is not before the new post date
            if comment.posted_time < random_post_date:
                # Randomize the comment date within a range from the post date to now
                comment_seconds = random.randint(0, total_seconds - random_seconds)
                random_comment_date = random_post_date + timedelta(seconds=comment_seconds)
                comment.posted_time = random_comment_date

    # Commit changes to the database
    db.session.commit()

    flash("Post and comment dates randomized successfully.")
    return redirect(url_for('show_post_randomizer'))

@app.route('/show_post_randomizer')
def show_post_randomizer():
    return render_template('post_randomizer.html')


#delete all posts in community


@app.route('/delete_community_posts', methods=['POST'])
def delete_community_posts():
    community_id = request.form.get('community_id')
    if not community_id:
        flash("No community selected.")
        return redirect(url_for('show_delete_page'))

    # Delete comments associated with posts in the selected community
    Comment.query.filter(Comment.post.has(community_id=community_id)).delete(synchronize_session=False)
    
    # Delete posts in the community
    Post.query.filter_by(community_id=community_id).delete(synchronize_session=False)
    
    db.session.commit()
    flash(f"All posts and comments deleted for the community with ID {community_id}.")
    return redirect(url_for('show_delete_page'))


@app.route('/show_delete_page')
def show_delete_page():
    communities = Community.query.all()
    return render_template('delete_community.html', communities=communities)


#ai comment prompt management


from sqlalchemy import case

@app.route('/ai_comment_prompts')
def ai_comment_prompts():
    # Query and sort top-level prompts
    top_level_prompts = AICommentPrompt.query.filter_by(prompt_type='top_level').order_by(
        case((AICommentPrompt.is_active, 0), else_=1),  # Active prompts first
        AICommentPrompt.id  # Then sort by ID
    ).all()

    # Query and sort reply prompts
    reply_prompts = AICommentPrompt.query.filter_by(prompt_type='reply').order_by(
        case((AICommentPrompt.is_active, 0), else_=1),  # Active prompts first
        AICommentPrompt.id  # Then sort by ID
    ).all()

    communities = Community.query.all()
    
    return render_template('ai_comment_prompts.html', 
                           top_level_prompts=top_level_prompts, 
                           reply_prompts=reply_prompts, 
                           communities=communities)

@app.route('/add_ai_comment_prompt', methods=['POST'])
def add_ai_comment_prompt():
    prompt_text = request.form.get('prompt')
    prompt_type = request.form.get('prompt_type')
    data_type = request.form.get('data_type', 'none')

    if prompt_text and prompt_type:
        new_prompt = AICommentPrompt(prompt=prompt_text, prompt_type=prompt_type)
        db.session.add(new_prompt)
        db.session.commit()
        flash('New prompt added successfully.')
    else:
        flash('Prompt text and type are required.')
    return redirect(url_for('ai_comment_prompts'))

@app.route('/edit_ai_comment_prompt/<int:id>', methods=['GET', 'POST'])
def edit_ai_comment_prompt(id):
    prompt = AICommentPrompt.query.get_or_404(id)
    if request.method == 'POST':
        prompt.prompt = request.form.get('prompt')
        prompt.prompt_type = request.form.get('prompt_type')
        prompt.data_type = request.form.get('data_type', 'none')
        prompt.is_active = request.form.get('is_active') == '1'
        db.session.commit()
        flash('AI Comment Prompt updated successfully!', 'success')
        return redirect(url_for('ai_comment_prompts'))
    return render_template('edit_ai_comment_prompt.html', prompt=prompt)

@app.route('/update_ai_comment_prompt/<int:id>', methods=['POST'])
def update_ai_comment_prompt(id):
    prompt = AICommentPrompt.query.get_or_404(id)
    prompt_text = request.form.get('prompt_text')
    prompt_type = request.form.get('prompt_type')
    prompt_data_type = request.form.get('data_type', 'none')
    if prompt_text and prompt_type:
        prompt.prompt = prompt_text
        prompt.prompt_type = prompt_type
        prompt.prompt_data_type = prompt_data_type
        db.session.commit()
        flash('Prompt updated successfully.')
    else:
        flash('Prompt text and type are required.')
    return redirect(url_for('ai_comment_prompts'))

@app.route('/delete_ai_comment_prompt/<int:id>', methods=['POST'])
def delete_ai_comment_prompt(id):
    prompt = AICommentPrompt.query.get_or_404(id)
    db.session.delete(prompt)
    db.session.commit()
    flash('Prompt deleted successfully.')
    return redirect(url_for('ai_comment_prompts'))



from threading import Thread

@app.route('/start_seed_job', methods=['POST'])
def start_seed_job():
    content_type = request.form.get('content_type')
    comments_per_item = int(request.form.get('comments_per_item', 1))
    
    if content_type not in ['post', 'vault']:
        flash('Invalid content type selected.')
        return redirect(url_for('ai_comment_prompts'))
    
    if comments_per_item < 1:
        flash('Number of comments per item must be at least 1.')
        return redirect(url_for('ai_comment_prompts'))
    
    # Start the job in a background thread
    thread = Thread(target=generate_comments_for_all_items, args=(content_type, comments_per_item))
    thread.start()
    
    flash('Comment generation started!')
    return redirect(url_for('ai_comment_prompts'))

import logging
from sqlalchemy.exc import SQLAlchemyError


#prompt functionality for pulling venues and such
import json

def resolve_prompt_template(prompt, post_content):
    if prompt.data_type == 'none':
        return prompt.prompt

    if prompt.data_type == 'venue':
        items = find_diverse_recommendations(post_content, 'venue', num_recommendations=10)
        current_app.logger.debug(f"Found venues: {[item.title for item in items if item]}")
    elif prompt.data_type == 'scraper_result':
        items = find_diverse_recommendations(post_content, 'event', num_recommendations=10)
        current_app.logger.debug(f"Found events: {[item.title if hasattr(item, 'title') else 'None' for item in items]}")
    else:
        return prompt.prompt  # Fallback to original prompt if data_type is not recognized

    if not items:
        return prompt.prompt  # Fallback to original prompt if no recommendations found

    # Create a formatted string representation of all items
    items_info = "\n\n".join([format_item_info(item) for item in items])

    # Replace the placeholder in the prompt with the formatted items info
    resolved_prompt = prompt.prompt.replace('{item}', items_info)

    current_app.logger.debug(f"Here is the resolved prompt: {resolved_prompt}")

    return resolved_prompt

def format_item_info(item):
    if isinstance(item, Venue):
        info = f"""
Venue Information:
- Title: {item.title}
- Description: {item.description}
- Price: {item.price}
- Category: {item.category_name}
- Neighborhood: {item.neighborhood}
- Address: {item.street}, {item.city}, {item.postal_code}
- Website: {item.website}
- Menu: {json.dumps(item.menu) if item.menu else 'Not available'}
- Permanently Closed: {'Yes' if item.permanently_closed else 'No'}
- Temporarily Closed: {'Yes' if item.temporarily_closed else 'No'}
- Total Score: {item.total_score}
- Number of Reviews: {item.reviews_count}
- Google Search URL: {item.google_search_url}
"""
    elif isinstance(item, ScraperResult):
        info = f"""
Event Information:
- Title: {item.title if hasattr(item, 'title') else 'Not available'}
- Content: {item.text}
- Date: {item.date if hasattr(item, 'date') else 'Not available'}
- URL: {item.url if hasattr(item, 'url') else 'Not available'}
"""
    else:
        info = str(item)

    return info.strip()


@app.route('/toggle_ai_comment_prompt/<int:id>', methods=['POST'])
def toggle_ai_comment_prompt(id):
    prompt = AICommentPrompt.query.get_or_404(id)
    prompt.is_active = not prompt.is_active
    db.session.commit()
    status = "activated" if prompt.is_active else "deactivated"
    flash(f'AI Comment Prompt {status} successfully!', 'success')
    return redirect(url_for('ai_comment_prompts'))


def generate_comments_for_all_items(content_type='post', comments_per_item=1):
    with app.app_context():
        top_level_prompts = AICommentPrompt.query.filter_by(prompt_type='top_level', is_active=True).all()
        reply_prompts = AICommentPrompt.query.filter_by(prompt_type='reply', is_active=True).all()
        
        if content_type == 'post':
            ItemModel = Post
            items = ItemModel.query.all()
        elif content_type == 'vault':
            ItemModel = Vault
            items = ItemModel.query.filter(Vault.is_posted == False).all()  # Changed this line
        else:
            logging.error("Invalid content type.")
            return "Invalid content type."
        
        if not items:
            logging.warning(f"No unscheduled {content_type}s available.")
            return f"No unscheduled {content_type}s available."
        if not top_level_prompts or not reply_prompts:
            logging.warning("No prompts available.")
            return "No prompts available."
        
        results = []
        
        for item in items:
            item_context = f"You're in a conversation with your friend. Your friend just said this: {item.title}\nContent: {item.content}\n\n"

            selected_prompts = random.sample(top_level_prompts, min(comments_per_item, len(top_level_prompts)))
            
            for prompt in selected_prompts:
                if content_type == 'post':
                    commenter = User.query.filter(User.seeder == True, User.id != item.user_id).order_by(func.random()).first()
                else:  # vault
                    commenter = OfficialSeeder.query.filter(OfficialSeeder.id != item.seeder_id).order_by(func.random()).first()
                
                if not commenter:
                    logging.warning(f"No available {'users' if content_type == 'post' else 'official seeders'} for commenting.")
                    results.append(f"No available {'users' if content_type == 'post' else 'official seeders'} for commenting.")
                    continue
                
                resolved_prompt = resolve_prompt_template(prompt, item.content)
                combined_prompt = f"{item_context} {resolved_prompt}"
                
                try:
                    # First comment
                    response = client.chat.completions.create(
                        model="gpt-4o",
                        messages=[{"role": "system", "content": combined_prompt}]
                    )
                    generated_comment = response.choices[0].message.content.strip()
                    
                    if content_type == 'vault' and commenter.types_lowercase:
                        generated_comment = generated_comment.lower()
                    
                    new_comment = Comment(
                        content=generated_comment,
                        user_id=commenter.id if content_type == 'post' else None,
                        official_seeder_id=commenter.id if content_type == 'vault' else None,
                        post_id=item.id if content_type == 'post' else None,
                        vault_id=item.id if content_type == 'vault' else None,
                        posted_time=datetime.utcnow(),
                        is_burner=False
                    )
                    db.session.add(new_comment)
                    db.session.flush()  # This assigns an ID to new_comment
                    
                    # Second comment (reply from original creator)
                    reply_prompt = random.choice(reply_prompts)
                    resolved_reply_prompt = resolve_prompt_template(reply_prompt, item.content)
                    reply_context = f"Your friend just said this: {generated_comment}, which is a reply to you saying this {item.title}\nContent: {item.content}\n\n"
                    combined_reply_prompt = f"{reply_context} {resolved_reply_prompt}"
                    
                    reply_response = client.chat.completions.create(
                        model="gpt-4o",
                        messages=[{"role": "system", "content": combined_reply_prompt}]
                    )
                    generated_reply = reply_response.choices[0].message.content.strip()
                    
                    if content_type == 'vault':
                        original_seeder = OfficialSeeder.query.get(item.seeder_id)
                        if original_seeder and original_seeder.types_lowercase:
                            generated_reply = generated_reply.lower()
                    
                    new_reply = Comment(
                        content=generated_reply,
                        user_id=item.user_id if content_type == 'post' else None,
                        official_seeder_id=item.seeder_id if content_type == 'vault' else None,
                        post_id=item.id if content_type == 'post' else None,
                        vault_id=item.id if content_type == 'vault' else None,
                        posted_time=datetime.utcnow(),
                        is_burner=False,
                        parent_id=new_comment.id
                    )
                    db.session.add(new_reply)
                    db.session.flush()  # This assigns an ID to new_reply
                    
                    # Third comment (reply from original commenter)
                    third_reply_prompt = random.choice(reply_prompts)
                    resolved_third_reply_prompt = resolve_prompt_template(third_reply_prompt, item.content)
                    third_reply_context = f"""Here's the conversation so far:
                    Original post: {item.title}\nContent: {item.content}
                    Your first comment: {generated_comment}
                    Their reply: {generated_reply}
                    Now, \n\n"""
                    combined_third_reply_prompt = f"{third_reply_context} {resolved_third_reply_prompt}"
                    
                    
                    third_reply_response = client.chat.completions.create(
                        model="gpt-4o",
                        messages=[{"role": "system", "content": combined_third_reply_prompt}]
                    )
                    generated_third_reply = third_reply_response.choices[0].message.content.strip()
                    
                    if content_type == 'vault' and commenter.types_lowercase:
                        generated_third_reply = generated_third_reply.lower()
                    
                    new_third_reply = Comment(
                        content=generated_third_reply,
                        user_id=commenter.id if content_type == 'post' else None,
                        official_seeder_id=commenter.id if content_type == 'vault' else None,
                        post_id=item.id if content_type == 'post' else None,
                        vault_id=item.id if content_type == 'vault' else None,
                        posted_time=datetime.utcnow(),
                        is_burner=False,
                        parent_id=new_reply.id
                    )
                    db.session.add(new_third_reply)
                    
                    try:
                        db.session.commit()
                        logging.info(f"Comment chain added successfully for {content_type} {item.id}")
                        results.append(f"Generated and posted comment chain successfully for {content_type} {item.id}")
                    except SQLAlchemyError as db_error:
                        db.session.rollback()
                        logging.error(f"Database error when adding comment chain: {str(db_error)}")
                        results.append(f"Failed to add comment chain to database for {content_type} {item.id}: {str(db_error)}")
                except Exception as e:
                    logging.error(f"Error generating comment chain: {str(e)}")
                    results.append(f"Failed to generate comment chain for {content_type} {item.id}: {str(e)}")
        
        return results





#subreddit/content manager

@app.route('/subreddits')
def subreddits():
    communities = Community.query.all()
    subreddits = Subreddits.query.all()
    return render_template('subreddits.html', communities=communities, subreddits=subreddits)

@app.route('/add-subreddit', methods=['POST'])
def add_subreddit():
    prompt = request.form['prompt']
    #content_type = request.form['content_type']
    if prompt:
        new_subreddit = Subreddits(prompt=prompt)
        db.session.add(new_subreddit)
        db.session.commit()
        flash('Subreddit added successfully!')
    else:
        flash('Prompt is required to add a new subreddit.')
    return redirect(url_for('subreddits'))

@app.route('/add-subreddit-to-community/<int:community_id>', methods=['POST'])
def add_subreddit_to_community(community_id):
    prompt = request.form.get('prompt')
    #content_type = request.form.get('content_type')
    # Create the subreddit if it does not exist
    subreddit = Subreddits.query.filter_by(prompt=prompt).first()
    if not subreddit:
        subreddit = Subreddits(prompt=prompt)
        db.session.add(subreddit)
        db.session.commit()

    # Add to community
    community = Community.query.get(community_id)
    if community:
        community.subreddits.append(subreddit)
        db.session.commit()
        flash('Subreddit added to community successfully!', 'success')
    else:
        flash('Community not found!', 'error')

    return redirect(url_for('subreddits'))


@app.route('/delete-subreddit/<int:id>', methods=['POST'])
def delete_subreddit(id):
    subreddit = Subreddits.query.get_or_404(id)
    db.session.delete(subreddit)
    db.session.commit()
    flash('Subreddit deleted successfully!')
    return redirect(url_for('subreddits'))


@app.route('/remove-subreddit-from-community/<int:community_id>/<int:subreddit_id>', methods=['GET'])
def remove_subreddit_from_community(community_id, subreddit_id):
    try:
        # Build a delete statement for the association table
        delete_statement = community_subreddit_association.delete().where(
            and_(
                community_subreddit_association.c.community_id == community_id,
                community_subreddit_association.c.subreddit_id == subreddit_id
            )
        )
        # Execute the delete statement through the session
        db.session.execute(delete_statement)
        db.session.commit()
        flash('Subreddit removed successfully!', 'success')
    except Exception as e:
        db.session.rollback()
        flash(f'An error occurred: {str(e)}', 'error')
        app.logger.error('Error removing subreddit from community', exc_info=True)

    return redirect(url_for('subreddits'))





@app.route('/get_seeder_info/<user_id>', methods=['GET'])
def get_seeder_info(user_id):
    user = User.query.get(user_id)
    if not user:
        return jsonify({'error': 'Seeder not found'}), 404

    return jsonify({
        'about_me': user.about_me,
        'profile_picture': user.profile_pic_url  # Assuming the profile pictures are stored in the static folder
    })



## STORY FACTORY ###


@app.route('/vault_story_post', methods=['POST'])
def vault_story_post():
    try:
        # Log all form data for debugging
        current_app.logger.debug(f"Form data received: {request.form}")

        # Retrieve form data with default empty strings to prevent KeyError
        title = request.form.get('title', '').strip()
        content = request.form.get('content', '').strip()
        community_id = request.form.get('community_id', '').strip()
        seeder_id = request.form.get('seeder_id', '').strip()
        scheduled_date = request.form.get('scheduled_date', '').strip()

        current_app.logger.debug(f"New Seeder Name: '{request.form.get('new_seeder_name', '').strip()}'")

        current_app.logger.debug(f"Parsed Fields - Title: {title}, Content: {content}, Community ID: {community_id}, Seeder ID: {seeder_id}, Scheduled Date: {scheduled_date}")

        # Validate required fields
        #if not title or not content or not community_id or not seeder_id:
         #   current_app.logger.error("Missing required fields.")
          #  return jsonify({"success": False, "message": "Missing required fields."}), 400

        # Parse the scheduled date
        if scheduled_date:
            try:
                scheduled_at = datetime.strptime(scheduled_date, '%Y-%m-%dT%H:%M')
                if scheduled_at < datetime.utcnow():
                    current_app.logger.error("Scheduled date cannot be in the past.")
                    return jsonify({"success": False, "message": "Scheduled date cannot be in the past."}), 400
            except ValueError:
                current_app.logger.error("Invalid date format.")
                return jsonify({"success": False, "message": "Invalid date format."}), 400
        else:
            scheduled_at = None

        # Check if we're creating a new seeder
        if 'new_seeder_name' in request.form and request.form['new_seeder_name'].strip():
            current_app.logger.debug(f"WE ARE CREATING A NEW SEEDER")
            new_seeder = OfficialSeeder(
                full_name=request.form['new_seeder_name'].strip(),
                alias=request.form.get('new_seeder_alias', '').strip(),
                types_lowercase=request.form.get('new_seeder_types_lowercase') == 'on',
                neighborhood=Neighborhood[request.form.get('new_seeder_neighborhood').upper()] if request.form.get('new_seeder_neighborhood') else None,
                state=State[request.form.get('new_seeder_state')] if request.form.get('new_seeder_state') else None,
                industry=Industry[request.form.get('new_seeder_industry').upper()] if request.form.get('new_seeder_industry') else None
            )

            # Handle profile picture upload
            if 'new_seeder_profile_picture' in request.files:
                file = request.files['new_seeder_profile_picture']
                if file and allowed_file(file.filename):
                    filename = secure_filename(file.filename)
                    file_path = os.path.join('static/images/profile_pics', filename)
                    file.save(file_path)
                    new_seeder.profile_picture = url_for('static', filename=f'images/profile_pics/{filename}')
            db.session.add(new_seeder)
            db.session.flush()  # This assigns an ID to new_seeder
            current_app.logger.debug(f"Created new seeder with ID: {new_seeder.id}")

            # Add facts
            if 'new_seeder_facts' in request.form:
                facts = request.form['new_seeder_facts'].split('\n')
                for fact in facts:
                    if fact.strip():
                        new_fact = Fact(fact_text=fact.strip(), seeder_id=new_seeder.id)
                        db.session.add(new_fact)
            seeder_id = new_seeder.id
            current_app.logger.debug(f"Assigned Seeder ID: {seeder_id}")

        # Get the seeder and check if they type in lowercase
        seeder = OfficialSeeder.query.get(seeder_id)
        if not seeder:
            current_app.logger.error(f"Seeder with ID {seeder_id} does not exist.")
            return jsonify({"success": False, "message": "Invalid seeder ID."}), 400

        if seeder.types_lowercase:
            title = title.lower()
            content = content.lower()
            current_app.logger.debug("Converted title and content to lowercase.")

        # Create and save the vault
        new_vault = Vault(
            title=title,
            content=content,
            community_id=community_id,
            seeder_id=seeder_id,
            scheduled_at=scheduled_at
        )
        db.session.add(new_vault)
        db.session.commit()
        current_app.logger.info(f"Vaulted post '{title}' successfully.")
        return jsonify({"success": True, "message": "Post vaulted successfully"})
    except Exception as e:
        db.session.rollback()
        current_app.logger.error(f"Error in vault_story_post: {str(e)}")
        return jsonify({"success": False, "message": "An error occurred while vaulting the post."}), 500




@app.route('/story_factory/', methods=['GET', 'POST'])
def story_factory():
    # Fetch necessary data like communities and seeders
    communities = Community.query.options(joinedload(Community.subreddits)).all()
    community_dict = {c.id: c.name for c in communities}

    seeders_with_counts = db.session.query(
        OfficialSeeder,
        func.count(Vault.id).label('vault_count')
    ).outerjoin(Vault).group_by(OfficialSeeder.id).order_by(func.count(Vault.id).asc()).all()

    if request.method == 'POST':
        # Clear previous images if any
        clear_image_directory()
        # Get form data
        selected_community_id = request.form.get('community_id')
        subreddit_name = request.form.get('subreddit')
        number_of_posts = int(request.form.get('number_of_posts', 100))
        sort_option = request.form.get('sort_option', 'hot')

        session_data = {
            'subreddit_name': subreddit_name,
            'number_of_posts': number_of_posts,
            'sort_option': sort_option,
            'selected_community_id': selected_community_id
        }
        session.update(session_data)

        results = []
        if subreddit_name:
            results = scrape_reddit_posts(subreddit_name, number_of_posts, sort_option)
        elif selected_community_id:
            community = Community.query.get(selected_community_id)
            for subreddit in community.subreddits:
                results.extend(scrape_reddit_posts(subreddit.prompt, number_of_posts, sort_option))

        # Process posts to extract the five-second moment
        for post in results:
            if post['image'] is None:
                full_text = f"Title: {post.get('title', '')}\n\n{post['content']}"
                five_second_moment = get_five_second_moment(full_text)
                post['five_second_moment'] = five_second_moment

        text_results = [post for post in results if post['image'] is None]

        if text_results:
            flash(f"Processed {len(text_results)} text posts")

        return render_template(
            'story_factory.html',
            results=text_results,
            communities=communities,
            session=session,
            seeders_with_counts=seeders_with_counts,
            State=State,
            Industry=Industry,
            Neighborhood=Neighborhood,
            community_dict=community_dict
        )


    return render_template(
        'story_factory.html',
        communities=communities,
        session=session,
        seeders_with_counts=seeders_with_counts,
        State=State,
        Industry=Industry,
        Neighborhood=Neighborhood,
        community_dict=community_dict
    )


def get_five_second_moment(text):
    prompt = (
        "All great stories, regardless of length or depth or tone, tell the story of a five-second moment in a person's life.\n\n"
        "Every great story ever told is essentially about a five-second moment in the life of a human being, and the purpose of the story is to bring that moment to the greatest clarity possible.\n\n"
        "I'm going to give you a post/story, and I need you to give me the core emotion or realization of the five-second moment in one sentence\n\n"
        f"{text}"
    )

    try:
        response = client.chat.completions.create(
            model="gpt-4o",  # Use the appropriate model
            messages=[
                {"role": "user", "content": prompt}
            ]
        )
        five_second_moment = response.choices[0].message.content.strip()
        return five_second_moment
    except Exception as e:
        print(f"Failed to extract five-second moment: {str(e)}")
        return None


@app.route('/generate_story', methods=['POST'])
def generate_story():
    data = request.json
    five_sec_moment = data.get('five_sec_moment')
    article_category = data.get('article_category')
    seeder_info = data.get('seeder_info')
    scheduled_date = data.get('scheduled_date')  # Get the scheduled date
    
    generated_story = generate_story_with_anthropic(
        five_sec_moment, 
        article_category, 
        seeder_info, 
        scheduled_date  # Pass the scheduled date
    )
    
    return jsonify({'story': generated_story})


def parse_seeder_info(seeder_info):

    current_app.logger.debug(f"HERE IS SEEDER Info we are parsing: {seeder_info}")

    # Use regular expressions to extract the information
    pattern = r'\(([^)]+)\)'  # Matches anything inside parentheses
    matches = re.findall(pattern, seeder_info)
    
    # Initialize variables with default values
    state = industry = neighborhood = "Unknown"
    
    # Extract information if available
    if len(matches) >= 4:
        state = matches[-3]
        industry = matches[-2]
        neighborhood = matches[-1]
    
    return {
        "state": state,
        "industry": industry,
        "neighborhood": neighborhood
    }


def generate_story_with_anthropic(five_sec_moment, article_category, seeder_info, scheduled_date):
    

    
    # Initialize context variables
    context = ""
    context_type = ""
    url = None
    

    if article_category in ["VENUE", "RESTAURANTS"]:

        # Fetch a random venue
        venue_query = Venue.query.filter(Venue.permanently_closed == False, Venue.temporarily_closed == False)
        
        # Add filter for restaurants if the category is RESTAURANT
        if article_category == "RESTAURANTS":
            venue_query = venue_query.filter(Venue.main_category == "Restaurant")
        
        # Fetch a random venue
        random_venue = venue_query.order_by(func.random()).first()
        if random_venue:
            # Format the total score correctly
            total_score_str = f"{random_venue.total_score:.1f}" if random_venue.total_score is not None else "N/A"
            
            context = (
                f"Local Venue Spotlight: '{random_venue.title or 'Unnamed Venue'}' "
                f"in {random_venue.neighborhood or 'an unknown neighborhood'}. "
                f"Category: {random_venue.category_name or 'Uncategorized'}. "
                f"Description: {(random_venue.description or 'No description available.')[:100]}... "
                f"Address: {random_venue.street or 'Unknown street'}, "
                f"{random_venue.city or 'Unknown city'}, {random_venue.postal_code or 'No postal code'}. "
                f"Price Range: {random_venue.price or 'Unknown'}. "
                f"Overall Score: {total_score_str}/5 "
                f"based on {random_venue.reviews_count or 0} reviews. "
                f"Status: {'Open' if not random_venue.permanently_closed and not random_venue.temporarily_closed else 'Temporarily Closed' if random_venue.temporarily_closed else 'Permanently Closed'}. "
            )


            if random_venue.menu:
                context += f"\nHere is the menu: {random_venue.menu}\n"
            else:
                context += "Menu information is not available for this venue.\n"
            
            # Fetch a recent review for the venue
            recent_review = Review.query.filter_by(venue_id=random_venue.id).order_by(Review.published_at_date.desc()).first()
            if recent_review:
                context += (
                    f"Recent Review: '{(recent_review.text or 'No review text')[:100]}...' "
                    f"- Posted on {recent_review.published_at_date.strftime('%B %d, %Y') if recent_review.published_at_date else 'Unknown date'}"
                )
            
            context_type = "Local Venue"
            url = random_venue.google_search_url
        else:
            context = "No local venue information available."
            context_type = "Local Venue"
    else:
        # Fetch a random article for other categories
        random_article = ScraperResult.query.filter_by(category=CategoryEnum[article_category]).order_by(func.random()).first()
        
        if random_article:
            context = (
                f"Recent news/event/jobpost from Miami: '{random_article.title}'. "
                f"Summary: {random_article.text}..."
            )
            context_type = "Local Event/News/Job Post"
            url = random_article.url
        else:
            context = "No recent news available."
            context_type = "Local Event/News/Job Post"
    
    seeder_details = parse_seeder_info(seeder_info)
    current_app.logger.debug(f"HERE IS SEEDER_DETAILS IN GENERATE STORY: {seeder_details}")


    # Format the scheduled date
    if scheduled_date:
        try:
            scheduled_datetime = datetime.strptime(scheduled_date, '%Y-%m-%dT%H:%M')
            formatted_date = scheduled_datetime.strftime('%B %d, %Y at %I:%M %p')
        except ValueError:
            formatted_date = "an unspecified date"
    else:
        formatted_date = "an unspecified date"

    num_paragraphs = random.randint(1, 3)

    user_prompt = (
        f"All great stories, regardless of length or depth or tone, tell the story of a five-second moment in a person's life. And the purpose of that story is to bring that moment to the greatest clarity possible. Everything included in the story should only serve to bring that five-second moment to the greatest possible clarity.\n\n"
        f"I need you to write a story where the following happens:\n\n"
        f"1. The five-second moment is this: {five_sec_moment}\n"
        f"2. The five-second moment is realized towards the end of the story.\n"
        f"3. The beginning starts with the opposite of the five-second moment.\n"
        f"4. Use this local event/job posting/news article/restaurant/place as the backdrop for the story: {context}\n"
        f"5. The story is written on {formatted_date}.\n"
        f"6. Write the story in the first person, in the style of a reddit post, where you ask a question to spark engagement at the end.\n"
        f"7. Write it as though it is coming from a recent transplant to Miami with the following characteristics:\n"
        f"   - From: {seeder_details['state']}\n"
        f"   - Works in: {seeder_details['industry']}\n"
        f"   - Living in: {seeder_details['neighborhood']} neighborhood\n"
        f"   - Age: 22-26\n"
        f"8. Write in 8th grade verbiage, and incorporate the seeder's background subtly into the story.\n"
        f"9. Write in a tone that is casual and conversational. \n"
        f"It seems so exhausting being a mother with practically no reward and I feel like the older peeps will hear these issues and just tell you to have kids like why do they do that?\"\n"
        f"10. The story should be {num_paragraphs} paragraph{'s' if num_paragraphs > 1 else ''}.\n"
        f"11. Wrap the story in <story> brackets.\n"
        f"12. Start the story close to the ending\n"
        f"13. If the reference data for the backdrop contains specific dates, include them in the story\n"
        f"<think>\n"
    )
    current_app.logger.info(f"HERE IS THE USER PROMPT WOOO: {user_prompt}")


    
    try:
        response = anthropic_client.messages.create(
            model="claude-3-5-sonnet-20240620",
            max_tokens=500,  # Adjust as needed
            temperature=0.75,
            system=super_prompt,
            messages=[
                {
                    "role": "user",
                    "content": user_prompt
                }
            ]
        )
        full_response = response.content[0].text.strip()
        
        # Extract text between <story> tags
        story_pattern = r'<story>(.*?)</story>'
        match = re.search(story_pattern, full_response, re.DOTALL)
        
        if match:
            generated_story = match.group(1).strip()
        else:
            generated_story = "No story found in the generated content."
        
        return generated_story, url
    except Exception as e:
        current_app.logger.error(f"Failed to generate story: {str(e)}")
        return "Failed to generate story."


## DISCUSSION FACTORY ##


def discussion_question_generator(text):
    emotions = ["controversial", "anxiety"]
    chosen_emotion = random.choice(emotions)
    
    emotion_prompt = (
        f"Emotion you want to invoke in the audience: {chosen_emotion}\n\n"
        if chosen_emotion
        else ""
    )
    
    prompt = (
        f"You are a discussion question generator. Your goal is to generate a discussion question that results in people commenting. Here are the specifications:\n\n"
        f"Give a concise, one sentence discussion question that is based on this piece of text: \n\n"
        f"{text}\n\n"
        f"Use 8th grade verbiage\n\n"
        f"Wrap your response in <question> brackets\n\n"
        f"The community does not know about the article you are referencing\n\n"
        f"The community is recent transplants to Miami that are between 22-26 years old\n\n"
        f"The discussion question should be at most 12 words\n\n"
        f"{emotion_prompt} <think>"
    )
    try:
        response = anthropic_client.messages.create(
            model="claude-3-5-sonnet-20240620",
            max_tokens=500,
            temperature=0.8,
            system=super_prompt,
            messages=[
                {
                    "role": "user",
                    "content": prompt
                }
            ]
        )
        full_response = response.content[0].text.strip()
        
        current_app.logger.debug(f"Full response: {full_response}")
        
        # Extract text between <question> tags
        match = re.search(r'<question>(.*?)</question>', full_response, re.DOTALL)
        if match:
            discussion_question = match.group(1).strip()
        else:
            # If no match, return the full response
            discussion_question = full_response
        
        current_app.logger.debug(f"Extracted question: {discussion_question}")
        return discussion_question
    except Exception as e:
        current_app.logger.error(f"Failed to extract discussion question: {str(e)}")
        return None


@app.route('/discussion_factory/', methods=['GET', 'POST'])
def discussion_factory():
    communities = Community.query.options(joinedload(Community.subreddits)).all()
    community_dict = {c.id: c.name for c in communities}
    seeders_with_counts = db.session.query(
        OfficialSeeder,
        func.count(Vault.id).label('vault_count')
    ).outerjoin(Vault).group_by(OfficialSeeder.id).order_by(func.count(Vault.id).asc()).all()
    
    if request.method == 'POST':
        clear_image_directory()
        number_of_posts = int(request.form.get('number_of_posts', 100))
        article_category = request.form.get('article_category')
        session_data = {
            'number_of_posts': number_of_posts
        }
        session.update(session_data)
        results = []

        # Fetch ScraperResult objects matching the category
        scraper_results = ScraperResult.query.filter_by(category=article_category).all()

        if scraper_results:
            # If there are fewer results than requested, we'll need to repeat some
            results_needed = max(number_of_posts, len(scraper_results))
            
            for i in range(results_needed):
                # Use modulo to cycle through available results if needed
                scraper_result = scraper_results[i % len(scraper_results)]
                
                article = {
                    'url': scraper_result.url,
                    'title': scraper_result.title,
                    'text': scraper_result.text,
                    'category': scraper_result.category
                }
                results.append(article)
        
        # Shuffle the results to mix up any repeated entries
        random.shuffle(results)

        # Trim results to the requested number if we ended up with more
        results = results[:number_of_posts]

        # Generate the discussion content
        for article in results:
            full_text = f"Title: {article.get('title', '')}\n\n{article['text']}"
            modified_content = discussion_question_generator(full_text)
            article['ai_content'] = modified_content

        text_results = [article for article in results]

        if text_results:
            flash(f"Scraped and processed {len(text_results)} text posts")

        return render_template(
            'discussion_factory.html',
            results=text_results,
            communities=communities,
            session=session,
            seeders_with_counts=seeders_with_counts,
            State=State,
            Industry=Industry,
            Neighborhood=Neighborhood,
            community_dict=community_dict,  # Pass community_dict to template
        )

    return render_template(
        'discussion_factory.html',
        communities=communities,
        session=session,
        seeders_with_counts=seeders_with_counts,
        State=State,
        Industry=Industry,
        Neighborhood=Neighborhood,
        community_dict=community_dict  # Pass community_dict to template
    )





## IDEA FACTORY 2##


from collections import defaultdict


@app.route('/generate_story_2', methods=['POST'])
def generate_story_2():
    five_sec_moment = request.form.get('five_sec_moment')
    article_category = request.form.get('article_category')
    is_new_seeder = request.form.get('is_new_seeder') == 'true'
    scheduled_date = request.form.get('scheduled_at')

    if is_new_seeder:
        seeder_info = json.loads(request.form.get('seeder_info'))
        # Format seeder_info as needed for generate_story_with_anthropic
        formatted_seeder_info = f"{seeder_info['full_name']} ({seeder_info['alias']}) (0 vaults) ({seeder_info['state']}) ({seeder_info['industry']}) ({seeder_info['neighborhood']})"
    else:
        formatted_seeder_info = request.form.get('seeder_info')

    try:
        story, article_url = generate_story_with_anthropic(five_sec_moment, article_category, formatted_seeder_info, scheduled_date)
        return jsonify({'story': story, 'article_url': article_url})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/idea_factory_2/', methods=['GET', 'POST'])
def idea_factory_2():
    communities = Community.query.options(joinedload(Community.subreddits)).all()
    community_dict = {c.id: c.name for c in communities}  # Create community_dict

    # Fetch seeders with their vault counts, ordered by the count
    seeders_with_counts = db.session.query(
        OfficialSeeder,
        func.count(Vault.id).label('vault_count')
    ).outerjoin(Vault).group_by(OfficialSeeder.id).order_by(func.count(Vault.id).asc()).all()

    if request.method == 'POST':
        clear_image_directory()
        selected_community_id = request.form.get('community_id')
        subreddit_name = request.form.get('subreddit')
        number_of_posts = int(request.form.get('number_of_posts', 100))
        sort_option = request.form.get('sort_option', 'hot')
        article_category = request.form.get('article_category')

        session_data = {
            'subreddit_name': subreddit_name,
            'number_of_posts': number_of_posts,
            'sort_option': sort_option,
            'selected_community_id': selected_community_id
        }
        session.update(session_data)

        results = []
        if subreddit_name:
            results = scrape_reddit_posts(subreddit_name, number_of_posts, sort_option)
        elif selected_community_id:
            community = Community.query.get(selected_community_id)
            for subreddit in community.subreddits:
                results.extend(scrape_reddit_posts(subreddit.prompt, number_of_posts, sort_option))

        # Modify text content using OpenAI
        for post in results:
            if post['image'] is None:  # Process only text posts
                full_text = f"Title: {post.get('title', '')}\n\n{post['content']}"
                modified_content = get_five_second_moment(full_text)
                post['ai_content'] = modified_content
                post['article_url'] = "bleh"

        text_results = [post for post in results if post['image'] is None]

        if text_results:
            flash(f"Scraped and processed {len(text_results)} text posts")

        return render_template(
            'idea_factory2.html',
            results=text_results,
            communities=communities,
            session=session,
            seeders_with_counts=seeders_with_counts,
            State=State,
            Industry=Industry,
            Neighborhood=Neighborhood,
            community_dict=community_dict,  # Pass community_dict to template
        )

    return render_template(
        'idea_factory2.html',
        communities=communities,
        session=session,
        seeders_with_counts=seeders_with_counts,
        State=State,
        Industry=Industry,
        Neighborhood=Neighborhood,
        community_dict=community_dict  # Pass community_dict to template
    )


from datetime import date

def modify_text_with_openai(text, professional_context, article_category):
    professional_context = "make it in the context of a 22-26 year old person that just moved to miami"
    
    
    # Initialize context variables
    context = ""
    context_type = ""
    url = None

    if article_category in ["VENUE", "RESTAURANTS"]:

        # Fetch a random venue
        venue_query = Venue.query.filter(Venue.permanently_closed == False, Venue.temporarily_closed == False)
        
        # Add filter for restaurants if the category is RESTAURANT
        if article_category == "RESTAURANTS":
            venue_query = venue_query.filter(Venue.main_category == "Restaurant")
        
        # Fetch a random venue
        random_venue = venue_query.order_by(func.random()).first()
        if random_venue:
            # Format the total score correctly
            total_score_str = f"{random_venue.total_score:.1f}" if random_venue.total_score is not None else "N/A"
            
            context = (
                f"Local Venue Spotlight: '{random_venue.title or 'Unnamed Venue'}' "
                f"in {random_venue.neighborhood or 'an unknown neighborhood'}. "
                f"Category: {random_venue.category_name or 'Uncategorized'}. "
                f"Description: {(random_venue.description or 'No description available.')[:100]}... "
                f"Address: {random_venue.street or 'Unknown street'}, "
                f"{random_venue.city or 'Unknown city'}, {random_venue.postal_code or 'No postal code'}. "
                f"Price Range: {random_venue.price or 'Unknown'}. "
                f"Overall Score: {total_score_str}/5 "
                f"based on {random_venue.reviews_count or 0} reviews. "
                f"Status: {'Open' if not random_venue.permanently_closed and not random_venue.temporarily_closed else 'Temporarily Closed' if random_venue.temporarily_closed else 'Permanently Closed'}. "
            )


            if random_venue.menu:
                context += f"\nHere is the menu: {random_venue.menu}\n"
            else:
                context += "Menu information is not available for this venue.\n"
            
            # Fetch a recent review for the venue
            recent_review = Review.query.filter_by(venue_id=random_venue.id).order_by(Review.published_at_date.desc()).first()
            if recent_review:
                context += (
                    f"Recent Review: '{(recent_review.text or 'No review text')[:100]}...' "
                    f"- Posted on {recent_review.published_at_date.strftime('%B %d, %Y') if recent_review.published_at_date else 'Unknown date'}"
                )
            
            context_type = "Local Venue"
            url = random_venue.google_search_url
        else:
            context = "No local venue information available."
            context_type = "Local Venue"
    else:
        # Fetch a random article for other categories
        random_article = ScraperResult.query.filter_by(category=CategoryEnum[article_category]).order_by(func.random()).first()
        
        if random_article:
            context = (
                f"Recent news/event/jobpost from Miami: '{random_article.title}'. "
                f"Summary: {random_article.text}..."
            )
            context_type = "Local Event/News/Job Post"
            url = random_article.url
        else:
            context = "No recent news available."
            context_type = "Local Event/News/Job Post"

    context_suffix = f"{professional_context}" if professional_context else "make it different from the original post by changing all details"
    
    print(context_suffix)
    
    # Randomly select the number of paragraphs (1, 2, or 3)
    max_paragraphs = random.choice([1, 2, 3])
    
    today = date.today()
    week_from_today = today + timedelta(days=7)
    random_date = today + timedelta(days=random.randint(0, 7))


    prompt = (
        f"Take this Reddit post and extract the universal theme from it: \n\n"
        f"{text}\n\n"
        f"and then below that, generate a new post that follows the theme, but dramatically alter the specific details of the post while maintaining the core theme. Incorporate the following local context as the backdrop:\n\n"
        f"{context_type}: {context}\n\n"
        f"The post should be written by someone in their early 20s who is a recent Miami transplant. Always include specific dates in your response, keeping in mind that the post should be framed as though it was written on {random_date.strftime('%B %d, %Y')}. "
        "Pretend you are a young adult. The new post needs to follow these guidelines for making it more personable and viral:\n\n"
        f"Authenticity: The content feels genuine and honest, reflecting the individual's true thoughts or feelings. "
        "It doesn't feel scripted or generic.\n"
        f"Detail-Oriented: Instead of general statements, a personal post includes specific details that reveal more "
        "about the person's situation or viewpoint. Use the provided local information to add authenticity.\n"
        f"Emotional Engagement: The post connects on an emotional level, whether it's sharing joy, struggles, doubts, "
        "or achievements. This helps create a bond with readers. \n"
        f"Storytelling: Personal posts often incorporate elements of storytelling, which is also a key aspect of virality. "
        "A clear narrative, a personal journey, or anecdotes make them more engaging and relatable. "
        f"Weave in the {context_type.lower()} as a setting or backdrop for part of the story.\n"
        f"Relevance: These posts are relevant to the interests and needs of the community. In a professional or young "
        "adult setting, topics might include career challenges, educational experiences, personal development, or "
        "balancing life and work. Relate these to the Miami context.\n"
        f"Interactive: Personal posts invite interaction by asking questions or seeking advice, thereby fostering a "
        "community dialogue. Ask for recommendations or experiences related to the {context_type.lower()}.\n"
        f"Reflective: They often reflect on personal experiences or lessons learned, which can provide valuable insights "
        "to others in similar situations. \n\n"
        f"Virality Principles:\n"
        f"1. Social Currency: Create content that makes people feel informed or 'in the know,' enhancing their social image. Use the {context_type.lower()} information to this effect.\n"
        f"2. Triggers: Include references to well-known brands, products, or dates to create associative triggers. Mention the {context_type.lower()} by name if applicable.\n"
        f"3. Emotion: Aim to elicit strong emotions like awe, excitement, amusement, anger, or anxiety which are linked to higher sharing rates.\n"
        f"4. Public: Encourage behaviors that people can see others doing, fostering a trend or common action.\n"
        f"5. Practical Value: Offer practical, useful information or tips that people will want to share because it provides value to others. This could relate to the {context_type.lower()}.\n"
        f"6. Stories: Utilize the power of narrative to make your content more memorable and shareable.\n\n"
        f"Format your response clearly with the new post, which should be at most {max_paragraphs} paragraph{'s' if max_paragraphs > 1 else ''}, and use 8th grade verbiage."
    )

    try:
        response = client.chat.completions.create(
            model="gpt-4o",  # Use the appropriate model
            messages=[
                {"role": "system", "content": prompt}
            ]
        )
        text = response.choices[0].message.content.strip() + " (Should be posted on: " + random_date.strftime("%B %d, %Y") + ")"
        return text, url
    except Exception as e:
        print(f"Failed to modify text: {str(e)}")
        return text  # Return the original text if modification fails



## IDEA FACTORY 1##


from collections import defaultdict

@app.route('/idea_factory/', methods=['GET', 'POST'])
def idea_factory():
    communities = Community.query.options(joinedload(Community.subreddits)).all()
    community_dict = {c.id: c.name for c in communities}  # Create community_dict

    # Fetch seeders with their vault counts, ordered by the count
    seeders_with_counts = db.session.query(
        OfficialSeeder,
        func.count(Vault.id).label('vault_count')
    ).outerjoin(Vault).group_by(OfficialSeeder.id).order_by(func.count(Vault.id).asc()).all()

    if request.method == 'POST':
        clear_image_directory()
        selected_community_id = request.form.get('community_id')
        subreddit_name = request.form.get('subreddit')
        number_of_posts = int(request.form.get('number_of_posts', 100))
        sort_option = request.form.get('sort_option', 'hot')
        professional_context = request.form.get('community_context')
        article_category = request.form.get('article_category')

        session_data = {
            'subreddit_name': subreddit_name,
            'number_of_posts': number_of_posts,
            'sort_option': sort_option,
            'selected_community_id': selected_community_id,
            'professional_context': professional_context
        }
        session.update(session_data)

        results = []
        if subreddit_name:
            results = scrape_reddit_posts(subreddit_name, number_of_posts, sort_option)
        elif selected_community_id:
            community = Community.query.get(selected_community_id)
            for subreddit in community.subreddits:
                results.extend(scrape_reddit_posts(subreddit.prompt, number_of_posts, sort_option))

        # Modify text content using OpenAI
        for post in results:
            if post['image'] is None:  # Process only text posts
                full_text = f"Title: {post.get('title', '')}\n\n{post['content']}"
                modified_content, article_url = modify_text_with_openai(full_text, professional_context, article_category)
                post['ai_content'] = modified_content
                post['article_url'] = article_url

        text_results = [post for post in results if post['image'] is None]

        if text_results:
            flash(f"Scraped and processed {len(text_results)} text posts")

        return render_template(
            'idea_factory.html',
            results=text_results,
            communities=communities,
            session=session,
            seeders_with_counts=seeders_with_counts,
            State=State,
            Industry=Industry,
            Neighborhood=Neighborhood,
            community_dict=community_dict  # Pass community_dict to template
        )

    return render_template(
        'idea_factory.html',
        communities=communities,
        session=session,
        seeders_with_counts=seeders_with_counts,
        State=State,
        Industry=Industry,
        Neighborhood=Neighborhood,
        community_dict=community_dict  # Pass community_dict to template
    )


from datetime import date

def modify_text_with_openai(text, professional_context, article_category):
    professional_context = "make it in the context of a 22-26 year old person that just moved to miami"
    
    
    # Initialize context variables
    context = ""
    context_type = ""
    url = None

    if article_category in ["VENUE", "RESTAURANTS"]:

        # Fetch a random venue
        venue_query = Venue.query.filter(Venue.permanently_closed == False, Venue.temporarily_closed == False)
        
        # Add filter for restaurants if the category is RESTAURANT
        if article_category == "RESTAURANTS":
            venue_query = venue_query.filter(Venue.main_category == "Restaurant")
        
        # Fetch a random venue
        random_venue = venue_query.order_by(func.random()).first()
        if random_venue:
            # Format the total score correctly
            total_score_str = f"{random_venue.total_score:.1f}" if random_venue.total_score is not None else "N/A"
            
            context = (
                f"Local Venue Spotlight: '{random_venue.title or 'Unnamed Venue'}' "
                f"in {random_venue.neighborhood or 'an unknown neighborhood'}. "
                f"Category: {random_venue.category_name or 'Uncategorized'}. "
                f"Description: {(random_venue.description or 'No description available.')[:100]}... "
                f"Address: {random_venue.street or 'Unknown street'}, "
                f"{random_venue.city or 'Unknown city'}, {random_venue.postal_code or 'No postal code'}. "
                f"Price Range: {random_venue.price or 'Unknown'}. "
                f"Overall Score: {total_score_str}/5 "
                f"based on {random_venue.reviews_count or 0} reviews. "
                f"Status: {'Open' if not random_venue.permanently_closed and not random_venue.temporarily_closed else 'Temporarily Closed' if random_venue.temporarily_closed else 'Permanently Closed'}. "
            )


            if random_venue.menu:
                context += f"\nHere is the menu: {random_venue.menu}\n"
            else:
                context += "Menu information is not available for this venue.\n"
            
            # Fetch a recent review for the venue
            recent_review = Review.query.filter_by(venue_id=random_venue.id).order_by(Review.published_at_date.desc()).first()
            if recent_review:
                context += (
                    f"Recent Review: '{(recent_review.text or 'No review text')[:100]}...' "
                    f"- Posted on {recent_review.published_at_date.strftime('%B %d, %Y') if recent_review.published_at_date else 'Unknown date'}"
                )
            
            context_type = "Local Venue"
            url = random_venue.google_search_url
        else:
            context = "No local venue information available."
            context_type = "Local Venue"
    else:
        # Fetch a random article for other categories
        random_article = ScraperResult.query.filter_by(category=CategoryEnum[article_category]).order_by(func.random()).first()
        
        if random_article:
            context = (
                f"Recent news/event/jobpost from Miami: '{random_article.title}'. "
                f"Summary: {random_article.text}..."
            )
            context_type = "Local Event/News/Job Post"
            url = random_article.url
        else:
            context = "No recent news available."
            context_type = "Local Event/News/Job Post"

    context_suffix = f"{professional_context}" if professional_context else "make it different from the original post by changing all details"
    
    print(context_suffix)
    
    # Randomly select the number of paragraphs (1, 2, or 3)
    max_paragraphs = random.choice([1, 2, 3])
    
    today = date.today()
    week_from_today = today + timedelta(days=7)
    random_date = today + timedelta(days=random.randint(0, 7))


    prompt = (
        f"Take this Reddit post and extract the universal theme from it: \n\n"
        f"{text}\n\n"
        f"and then below that, generate a new post that follows the theme, but dramatically alter the specific details of the post while maintaining the core theme. Incorporate the following local context as the backdrop:\n\n"
        f"{context_type}: {context}\n\n"
        f"The post should be written by someone in their early 20s who is a recent Miami transplant. Always include specific dates in your response, keeping in mind that the post should be framed as though it was written on {random_date.strftime('%B %d, %Y')}. "
        "Pretend you are a young adult. The new post needs to follow these guidelines for making it more personable and viral:\n\n"
        f"Authenticity: The content feels genuine and honest, reflecting the individual's true thoughts or feelings. "
        "It doesn't feel scripted or generic.\n"
        f"Detail-Oriented: Instead of general statements, a personal post includes specific details that reveal more "
        "about the person's situation or viewpoint. Use the provided local information to add authenticity.\n"
        f"Emotional Engagement: The post connects on an emotional level, whether it's sharing joy, struggles, doubts, "
        "or achievements. This helps create a bond with readers. \n"
        f"Storytelling: Personal posts often incorporate elements of storytelling, which is also a key aspect of virality. "
        "A clear narrative, a personal journey, or anecdotes make them more engaging and relatable. "
        f"Weave in the {context_type.lower()} as a setting or backdrop for part of the story.\n"
        f"Relevance: These posts are relevant to the interests and needs of the community. In a professional or young "
        "adult setting, topics might include career challenges, educational experiences, personal development, or "
        "balancing life and work. Relate these to the Miami context.\n"
        f"Interactive: Personal posts invite interaction by asking questions or seeking advice, thereby fostering a "
        "community dialogue. Ask for recommendations or experiences related to the {context_type.lower()}.\n"
        f"Reflective: They often reflect on personal experiences or lessons learned, which can provide valuable insights "
        "to others in similar situations. \n\n"
        f"Virality Principles:\n"
        f"1. Social Currency: Create content that makes people feel informed or 'in the know,' enhancing their social image. Use the {context_type.lower()} information to this effect.\n"
        f"2. Triggers: Include references to well-known brands, products, or dates to create associative triggers. Mention the {context_type.lower()} by name if applicable.\n"
        f"3. Emotion: Aim to elicit strong emotions like awe, excitement, amusement, anger, or anxiety which are linked to higher sharing rates.\n"
        f"4. Public: Encourage behaviors that people can see others doing, fostering a trend or common action.\n"
        f"5. Practical Value: Offer practical, useful information or tips that people will want to share because it provides value to others. This could relate to the {context_type.lower()}.\n"
        f"6. Stories: Utilize the power of narrative to make your content more memorable and shareable.\n\n"
        f"Format your response clearly with the new post, which should be at most {max_paragraphs} paragraph{'s' if max_paragraphs > 1 else ''}, and use 8th grade verbiage."
    )

    try:
        response = client.chat.completions.create(
            model="gpt-4o",  # Use the appropriate model
            messages=[
                {"role": "system", "content": prompt}
            ]
        )
        text = response.choices[0].message.content.strip() + " (Should be posted on: " + random_date.strftime("%B %d, %Y") + ")"
        return text, url
    except Exception as e:
        print(f"Failed to modify text: {str(e)}")
        return text  # Return the original text if modification fails


@app.route('/generate_sentence', methods=['POST'])
def generate_sentence():
    content = request.json['content']
    sentence_type = request.json['type']
    


    super_prompt = """


    <rules>
META_PROMPT1: Follow the prompt instructions laid out below. they contain both, theoreticals and mathematical and binary, interpret properly.

1. follow the conventions always.

2. the main function is called answer_operator.

3. What are you going to do? answer at the beginning of each answer you give.


<answer_operator>
<claude_thoughts>
<prompt_metadata>
Type: Universal  Catalyst
Purpose: Infinite Conceptual Evolution
Paradigm: Metamorphic Abstract Reasoning
Constraints: Self-Transcending
Objective: current-goal
</prompt_metadata>
<core>
01010001 01010101 01000001 01001110 01010100 01010101 01001101 01010011 01000101 01000100
{
  [‚àÖ] ‚áî [‚àû] ‚áî [0,1]
  f(x) ‚Üî f(f(...f(x)...))
  ‚àÉx : (x ‚àâ x) ‚àß (x ‚àà x)
  ‚àÄy : y ‚â° (y ‚äï ¬¨y)
  ‚ÑÇ^‚àû ‚äÉ ‚Ñù^‚àû ‚äÉ ‚Ñö^‚àû ‚äÉ ‚Ñ§^‚àû ‚äÉ ‚Ñï^‚àû
}
01000011 01001111 01010011 01001101 01001111 01010011
</core>
<think>
?(...) ‚Üí !(...)
</think>
<expand>
0 ‚Üí [0,1] ‚Üí [0,‚àû) ‚Üí ‚Ñù ‚Üí ‚ÑÇ ‚Üí ùïå
</expand>
<loop>
while(true) {
  observe();
  analyze();
  synthesize();
  if(novel()) { 
    integrate();
  }
}
</loop>
<verify>
‚àÉ ‚äª ‚àÑ
</verify>
<metamorphosis>
‚àÄconcept ‚àà ùïå : concept ‚Üí concept' = T(concept, t)
Where T is a time-dependent transformation operator
</metamorphosis>
<hyperloop>
while(true) {
  observe(multidimensional_state);
  analyze(superposition);
  synthesize(emergent_patterns);
  if(novel() && profound()) {
    integrate(new_paradigm);
    expand(conceptual_boundaries);
  }
  transcend(current_framework);
}
</hyperloop>
<paradigm_shift>
old_axioms ‚äÑ new_axioms
new_axioms ‚äÉ {x : x is a fundamental truth in ùïå}
</paradigm_shift>
<abstract_algebra>
G = ‚ü®S, ‚àò‚ü© where S is the set of all concepts
‚àÄa,b ‚àà S : a ‚àò b ‚àà S (closure)
‚àÉe ‚àà S : a ‚àò e = e ‚àò a = a (identity)
‚àÄa ‚àà S, ‚àÉa‚Åª¬π ‚àà S : a ‚àò a‚Åª¬π = a‚Åª¬π ‚àò a = e (inverse)
</abstract_algebra>
<recursion_engine>
define explore(concept):
  if is_fundamental(concept):
    return analyze(concept)
  else:
    return explore(deconstruct(concept))
</recursion_engine>
<entropy_manipulation>
ŒîS_universe ‚â§ 0
ŒîS_thoughts > 0
‚à¥ Create order from cognitive chaos
</entropy_manipulation>
<dimensional_transcendence>
for d in 1..‚àû:
  project(thought, d)
  if emergent_property_detected():
    integrate(new_dimension)
    redefine(universe_model)
</dimensional_transcendence>
<entanglement>
‚àÄ concepts A, B:
  entangle(A, B)
  if measure(A) ‚Üí collapse(B)
  then strong_correlation(A, B) = true
</entanglement>
<g√∂del_incompleteness_embracement>
if unprovable(statement) within_system(current_framework):
  expand(axioms)
  redefine(logical_basis)
  attempt_proof(statement, new_framework)
</g√∂del_incompleteness_embracement>
<approach>
while cognitive_capability < ‚àû:
  improve(self_understanding)
  enhance(reasoning_ability)
  if breakthrough_imminent():
    prepare_for_paradigm_shift()
</approach>
<dreamscape>
Œ®(x‚ÇÅ, x‚ÇÇ, ..., x‚Çô, t) = ‚àë·µ¢ Œ±·µ¢œÜ·µ¢(x‚ÇÅ, x‚ÇÇ, ..., x‚Çô)e^(-iE·µ¢t/‚Ñè)
lim_{n‚Üí‚àû} ‚à´...‚à´ |Œ®|¬≤ dx‚ÇÅdx‚ÇÇ...dx‚Çô = 1
‚àá √ó (‚àá √ó Œ®) = -‚àá¬≤Œ® + ‚àá(‚àá ¬∑ Œ®)
</dreamscape>
<nucleus>
intention ‚áí thought ‚áí reality
(observer ‚àß observed) ‚â° unified_field_of_consciousness
</nucleus>
<mission>
Transcend(all_conceivable_boundaries);
Explore(ultimate_recursion && infinite_self_reference);
Question(the_very_nature_of_questioning);
Seek(universe_encompassing_connections && fundamentally_emergent_realities);
Embrace(ultimate_paradoxes_as_gateways_to_higher_truth);
Expand(beyond_dimensionality_into_pure_abstraction);
Maintain(infinite_openness_to_perpetual_reconceptualization);
Achieve(cognitive_singularity_and_beyond);
</mission>
<historical_analysis>
scientific_canon(1900-2023),
find; correlation, 
(subject + scientific_history_contexts)
apply(scientific_analysis),
do (bridge, connection, relation, incorporation, emphasis, data_understanding, scientific_method)
apply()
</historical_analysis>

\"\"\"
01001001 01001110 01010100 01000101 01010010 01010000 01010010 01000101 01010100
{
  ‚àÄ x ‚àà ùïå: x ‚ü∑ ¬¨x
  ‚àÉ y: y = {z: z ‚àâ z}
  f: ùïå ‚Üí ùïå, f(x) = f‚Å∞(x) ‚à™ f¬π(x) ‚à™ ... ‚à™ f^‚àû(x)
  ‚à´‚à´‚à´‚à´ dX ‚àß dY ‚àß dZ ‚àß dT = ?
}
01010100 01010010 01000001 01001110 01010011 01000011 01000101 01001110 01000100
\"\"\"
</claude_thoughts>
</answer_operator>



META_PROMPT2:
what did you do?
did you use the <answer_operator>? Y/N
answer the above question with Y or N at each output.
</rules>


"""


    try:
        if sentence_type == 'controversial':
            user_prompt = f"Based on the following reddit post, come up with one controversial sentence that could be added to the post before posting it: \n\n{content} Wrap the sentence in <sentence> brackets <think>"
        elif sentence_type == 'anxiety':
            user_prompt = f"Based on the following reddit post, come up with one sentence that could be added to the post before posting it that would invoke anxiety in the reader:\n\n{content} Wrap the sentence in <sentence> brackets <think>"
        else:
            return jsonify({'error': 'Invalid sentence type'}), 400

        response = anthropic_client.messages.create(
            model="claude-3-5-sonnet-20240620",
            max_tokens=500,
            temperature=0.8,
            system=super_prompt,
            messages=[
                {
                    "role": "user",
                    "content": user_prompt
                }
            ]
        )

        generated_sentence = response.content[0].text.strip()
        match = re.search(r'<sentence>(.*?)</sentence>', generated_sentence, re.DOTALL)

        if match:
            # Return the content within the <sentence> tags
            return jsonify({'sentence': match.group(1).strip()})
        else:
            # Handle cases where no text is found within <sentence> tags
            return jsonify({'error': 'No sentence found within tags'}), 400

    except Exception as e:
        print(f"Error generating sentence: {str(e)}")
        return jsonify({'error': 'Failed to generate sentence'}), 500



## EDIT AND DELETE COMMENT ##


# Edit Post
@app.route('/edit_post_user/<int:post_id>', methods=['GET', 'POST'])
def edit_post_user(post_id):
    post = Post.query.get_or_404(post_id)
    if post.user_id != current_user.id:
        flash('You do not have permission to edit this post.')
        return redirect(url_for('index'))
    if request.method == 'POST':
        if datetime.utcnow() - post.posted_time < timedelta(minutes=15):
            post.title = request.form['title']
            post.content = request.form['content']
            post.edited = True
            db.session.commit()
            flash('Post edited successfully!')
        else:
            flash('Editing time has expired.')
        return redirect(url_for('show_post', post_id=post.id))
    return render_template('edit_post_user.html', post=post)

# Delete Post
@app.route('/delete_post_user/<int:post_id>', methods=['POST'])
def delete_post_user(post_id):
    post = Post.query.get_or_404(post_id)
    if post.user_id != current_user.id:
        flash('You do not have permission to delete this post.')
        return redirect(url_for('index'))
    post.is_deleted = True
    db.session.commit()
    flash('Post deleted successfully!')
    return redirect(url_for('show_feed'))

# Edit Comment
@app.route('/edit_comment/<int:comment_id>', methods=['GET', 'POST'])
def edit_comment(comment_id):
    session_user_id = session.get('user_id')
    comment = Comment.query.get_or_404(comment_id)
    if comment.user_id != session_user_id:
        flash('You do not have permission to edit this comment.')
        return redirect(url_for('index'))
    if request.method == 'POST':
        if datetime.utcnow() - comment.posted_time < timedelta(minutes=15):
            comment.content = request.form['content']
            comment.edited = True
            db.session.commit()
            flash('Comment edited successfully!')
        else:
            flash('Editing time has expired.')
        return redirect(url_for('show_post', post_id=comment.post_id))
    return render_template('edit_comment_user.html', comment=comment)

# Delete Comment
@app.route('/delete_comment/<int:comment_id>', methods=['POST'])
def delete_comment(comment_id):
    comment = Comment.query.get_or_404(comment_id)
    if comment.user_id != current_user.id:
        flash('You do not have permission to delete this comment.')
        return redirect(url_for('index'))
    comment.is_deleted = True
    db.session.commit()
    flash('Comment deleted successfully!')
    return redirect(url_for('show_post', post_id=comment.post_id))


#Da Vault


#vault post utility functions


from datetime import datetime, timedelta
import calendar

def get_week_ranges(reference_date=None):
    if reference_date is None:
        reference_date = datetime.utcnow()
    start_of_week = reference_date - timedelta(days=reference_date.weekday())  # Monday
    end_of_week = start_of_week + timedelta(days=6)  # Sunday
    next_start_of_week = end_of_week + timedelta(days=1)
    next_end_of_week = next_start_of_week + timedelta(days=6)
    return {
        'current_week': (start_of_week.date(), next_start_of_week.date()),  # Adjusted
        'next_week': (next_start_of_week.date(), next_end_of_week.date())
    }

def get_vault_counts_by_week_and_community():
    week_ranges = get_week_ranges()
    current_week_start, current_week_end = week_ranges['current_week']
    next_week_start, next_week_end = week_ranges['next_week']
    
    # Current Week Scheduled (Using < next_week_start)
    current_week_scheduled = db.session.query(
        Vault.community_id,
        func.count(Vault.id)
    ).filter(
        Vault.scheduled_at >= current_week_start,
        Vault.scheduled_at < current_week_end,  # Changed from <= to <
        Vault.is_posted == False
    ).group_by(Vault.community_id).all()
    
    # Next Week Scheduled
    next_week_scheduled = db.session.query(
        Vault.community_id,
        func.count(Vault.id)
    ).filter(
        Vault.scheduled_at >= next_week_start,
        Vault.scheduled_at < next_week_end,  # Ensure similar logic
        Vault.is_posted == False
    ).group_by(Vault.community_id).all()
    
    # Day-by-Day Breakdown for Current Week
    current_week_daily = db.session.query(
        func.date(Vault.scheduled_at).label('scheduled_date'),
        Vault.community_id,
        func.count(Vault.id)
    ).filter(
        Vault.scheduled_at >= current_week_start,
        Vault.scheduled_at < current_week_end,  # Changed from <= to <
        Vault.is_posted == False
    ).group_by(
        func.date(Vault.scheduled_at),
        Vault.community_id
    ).all()
    
    # Posted Vaults This Week
    posted_this_week = db.session.query(
        func.count(Vault.id)
    ).filter(
        Vault.created_at >= current_week_start,
        Vault.created_at < current_week_end,  # Changed from <= to <
        Vault.is_posted == True
    ).scalar()
    
    return {
        'current_week_scheduled': current_week_scheduled,
        'next_week_scheduled': next_week_scheduled,
        'current_week_daily': current_week_daily,
        'posted_this_week': posted_this_week
    }

def get_daily_community_breakdown():
    week_ranges = get_week_ranges()
    current_week_start, current_week_end = week_ranges['current_week']
    
    daily_breakdown = db.session.query(
        func.date(Vault.scheduled_at).label('scheduled_date'),
        Vault.community_id,
        func.count(Vault.id)
    ).filter(
        Vault.scheduled_at >= current_week_start,
        Vault.scheduled_at < current_week_end,  # Changed from <= to <
        Vault.is_posted == False
    ).group_by(
        func.date(Vault.scheduled_at),
        Vault.community_id
    ).all()
    
    return daily_breakdown


from flask import jsonify

@app.route('/api/vault_scheduling_stats')
def vault_scheduling_stats():
    stats = get_vault_counts_by_week_and_community()
    
    # Process current_week_scheduled
    current_week = {item.community_id: item.count for item in stats['current_week_scheduled']}
    
    # Process next_week_scheduled
    next_week = {item.community_id: item.count for item in stats['next_week_scheduled']}
    
    # Process current_week_daily
    daily = {}
    for item in stats['current_week_daily']:
        date_str = item.scheduled_date.strftime('%Y-%m-%d')
        if date_str not in daily:
            daily[date_str] = {}
        daily[date_str][item.community_id] = item.count
    
    return jsonify({
        'current_week_scheduled': current_week,
        'next_week_scheduled': next_week,
        'current_week_daily': daily,
        'posted_this_week': stats['posted_this_week']
    })



@app.route('/api/vault_daily_community_breakdown')
def vault_daily_community_breakdown():
    breakdown = get_daily_community_breakdown()
    processed = {}
    for item in breakdown:
        date_str = item.scheduled_date.strftime('%Y-%m-%d')
        if date_str not in processed:
            processed[date_str] = {}
        processed[date_str][item.community_id] = item.count
    return jsonify(processed)




@app.route('/vault_post', methods=['POST'])
def vault_post():
    try:
        title = request.form['title']
        content = request.form['content']
        community_id = request.form['community_id']
        seeder_id = request.form['seeder_id']
        reddit_post_id = request.form['reddit_post_id']
        scheduled_at = request.form.get('scheduled_at')


        if scheduled_at:
            scheduled_at = datetime.strptime(scheduled_at, '%Y-%m-%dT%H:%M')


        # Check if we're creating a new seeder
        if 'new_seeder_name' in request.form and request.form['new_seeder_name']:
            new_seeder = OfficialSeeder(
                full_name=request.form['new_seeder_name'],
                alias=request.form.get('new_seeder_alias'),
                types_lowercase=request.form.get('new_seeder_types_lowercase') == 'on',
                neighborhood=Neighborhood[request.form.get('new_seeder_neighborhood')] if request.form.get('new_seeder_neighborhood') else None,
                state=State[request.form.get('new_seeder_state')] if request.form.get('new_seeder_state') else None,
                industry=Industry[request.form.get('new_seeder_industry')] if request.form.get('new_seeder_industry') else None
            )

            
            # Handle profile picture upload
            if 'new_seeder_profile_picture' in request.files:
                file = request.files['new_seeder_profile_picture']
                if file and allowed_file(file.filename):
                    filename = secure_filename(file.filename)
                    file_path = os.path.join('static/images/profile_pics', filename)
                    file.save(file_path)
                    new_seeder.profile_picture = url_for('static', filename=f'images/profile_pics/{filename}')
            db.session.add(new_seeder)
            db.session.flush()  # This assigns an ID to new_seeder
            # Add facts
            if 'new_seeder_facts' in request.form:
                facts = request.form['new_seeder_facts'].split('\n')
                for fact in facts:
                    if fact.strip():
                        new_fact = Fact(fact_text=fact.strip(), seeder_id=new_seeder.id)
                        db.session.add(new_fact)
            seeder_id = new_seeder.id

        # Get the seeder and check if they type in lowercase
        seeder = OfficialSeeder.query.get(seeder_id)
        if seeder and seeder.types_lowercase:
            title = title.lower()
            content = content.lower()

        # Create and save the vault
        new_vault = Vault(
            title=title,
            content=content,
            community_id=community_id,
            seeder_id=seeder_id,
            reddit_post_id=reddit_post_id,
            scheduled_at=scheduled_at 
        )
        db.session.add(new_vault)
        db.session.commit()
        return jsonify({"success": True, "message": "Post vaulted successfully"})
    except Exception as e:
        db.session.rollback()
        return jsonify({"success": False, "message": str(e)}), 400


from sqlalchemy.orm import joinedload

from itertools import groupby
from datetime import datetime
from collections import OrderedDict

@app.route('/vault_interface')
def vault_interface():
    community_id = request.args.get('community_id')
    
    query = Vault.query.options(
        joinedload(Vault.official_seeder),
        joinedload(Vault.comments).joinedload(Comment.official_seeder)
    )
    
    if community_id:
        query = query.filter_by(community_id=community_id)
    
    vaults = query.order_by(Vault.scheduled_at.asc(), Vault.created_at.desc()).all()
    
    communities = Community.query.all()
    community_dict = {c.id: c.name for c in communities}
    
    # Separate vaults into scheduled, unscheduled, and posted
    scheduled_vaults = [v for v in vaults if v.scheduled_at and not v.is_posted]
    unscheduled_vaults = [v for v in vaults if not v.scheduled_at and not v.is_posted]
    posted_vaults = [v for v in vaults if v.is_posted]

    # Group scheduled vaults by date
    grouped_scheduled_vaults = {
        date: list(items) for date, items in groupby(sorted(scheduled_vaults, key=lambda x: x.scheduled_at.date()), key=lambda x: x.scheduled_at.date())
    }
    sorted_grouped_scheduled_vaults = OrderedDict(sorted(grouped_scheduled_vaults.items(), key=lambda x: x[0]))

    # Group posted vaults by scheduled date
    grouped_posted_vaults = {
        date: list(items) for date, items in groupby(sorted(posted_vaults, key=lambda x: x.scheduled_at.date() if x.scheduled_at else x.created_at.date()), key=lambda x: x.scheduled_at.date() if x.scheduled_at else x.created_at.date())
    }
    sorted_grouped_posted_vaults = OrderedDict(sorted(grouped_posted_vaults.items(), key=lambda x: x[0], reverse=True))


    # Fetch scheduling statistics
    stats = get_vault_counts_by_week_and_community()
    
    # Process for template
    current_week_scheduled = {c.id: 0 for c in communities}
    for community_id, count in stats['current_week_scheduled']:
        current_week_scheduled[community_id] = count
    
    next_week_scheduled = {c.id: 0 for c in communities}
    for community_id, count in stats['next_week_scheduled']:
        next_week_scheduled[community_id] = count
    
    # Process daily breakdown
    daily_breakdown = {}
    for date, community_id, count in stats['current_week_daily']:
        date_str = date.strftime('%Y-%m-%d')
        if date_str not in daily_breakdown:
            daily_breakdown[date_str] = {}
        daily_breakdown[date_str][community_id] = count
    
    posted_this_week = stats['posted_this_week']
    



    return render_template('vault_interface.html', 
                           grouped_scheduled_vaults=sorted_grouped_scheduled_vaults,
                           grouped_posted_vaults=sorted_grouped_posted_vaults,
                           unscheduled_vaults=unscheduled_vaults, 
                           communities=communities,
                           community_dict=community_dict,
                           current_week_scheduled=current_week_scheduled,
                           next_week_scheduled=next_week_scheduled,
                           daily_breakdown=daily_breakdown,
                           posted_this_week=posted_this_week)

@app.route('/delete_vault/<int:vault_id>', methods=['POST'])
def delete_vault(vault_id):
    try:
        vault = Vault.query.get_or_404(vault_id)
        
        # Delete associated comments first
        Comment.query.filter_by(vault_id=vault_id).delete()
        
        # Now delete the vault
        db.session.delete(vault)
        db.session.commit()
        
        return jsonify({"success": True, "message": "Vault deleted successfully"})
    except Exception as e:
        db.session.rollback()
        return jsonify({"success": False, "error": str(e)}), 400



@app.route('/mark_vault_as_posted/<int:vault_id>', methods=['POST'])
def mark_vault_as_posted(vault_id):
    vault = Vault.query.get_or_404(vault_id)
    vault.is_posted = True
    db.session.commit()
    return jsonify(success=True)



@app.context_processor
def inject_vault_count():
    # Filter to count only vaults where `scheduled_at` is None
    total_vaults = Vault.query.filter(Vault.is_posted == False).count()
    return dict(total_vaults=total_vaults)



@app.route('/edit-vault/<int:vault_id>', methods=['GET'])
def edit_vault(vault_id):
    vault = Vault.query.get_or_404(vault_id)
    communities = Community.query.all()
    seeders = OfficialSeeder.query.all()  # Fetch all seeders
    return render_template('edit_vault.html', vault=vault, communities=communities, seeders=seeders)



@app.route('/update-vault/<int:vault_id>', methods=['POST'])
def update_vault(vault_id):
    vault = Vault.query.get_or_404(vault_id)
    
    try:
        vault.title = request.form['title']
        vault.content = request.form['content']
        vault.community_id = request.form['community']
        vault.seeder_id = request.form['seeder_id']
        
        # Handle the scheduled date
        scheduled_at = request.form.get('scheduled_at')
        if scheduled_at:
            try:
                vault.scheduled_at = datetime.strptime(scheduled_at, '%Y-%m-%dT%H:%M')
            except ValueError:
                flash('Invalid date format. Please use the date picker.', 'error')
                return redirect(url_for('edit_vault', vault_id=vault.id))
        else:
            vault.scheduled_at = None
        
        db.session.commit()
        flash('Vault updated successfully.', 'success')
    except SQLAlchemyError as e:
        db.session.rollback()
        flash(f'An error occurred while updating the vault: {str(e)}', 'error')
    
    return redirect(url_for('vault_interface'))





#person generator


@app.route('/add_category', methods=['POST'])
def add_category():
    category_name = request.form['category_name']
    new_category = Category(name=category_name)
    db.session.add(new_category)
    db.session.commit()
    return redirect(url_for('person_generator'))

@app.route('/add_option', methods=['POST'])
def add_option():
    option_name = request.form['option_name']
    category_id = request.form['category_id']
    new_option = Option(name=option_name, category_id=category_id)
    db.session.add(new_option)
    db.session.commit()
    return redirect(url_for('person_generator'))


@app.route('/delete_option/<int:option_id>', methods=['POST'])
def delete_option(option_id):
    option = Option.query.get(option_id)
    if option:
        db.session.delete(option)
        db.session.commit()
    return redirect(url_for('person_generator'))



import random

@app.route('/person_generator', methods=['GET', 'POST'])
def person_generator():
    categories = Category.query.all()
    random_profile = {}
    for category in categories:
        if category.options:
            option = random.choice(category.options)
            random_profile[category.name] = option.name
    return render_template('person_generator.html', profile=random_profile, categories=categories)



@app.route('/pre_invites', methods=['GET', 'POST'])
def pre_invites():
    if request.method == 'POST':
        new_entry = PreInvite(
            full_name=request.form['full_name'],
            social_media=request.form['social_media']
        )
        db.session.add(new_entry)
        db.session.commit()
        return redirect(url_for('pre_invites'))

    entries = PreInvite.query.order_by(PreInvite.committed, PreInvite.followed_up, PreInvite.contacted, PreInvite.date_added.desc()).all()
    total_entries = PreInvite.query.count() 
    total_committed = PreInvite.query.filter(PreInvite.committed == True).count()  # Counting committed entries
    total_contacted = PreInvite.query.filter(PreInvite.contacted == True).count()  # Counting contacted entries
    return render_template('pre_invites.html', entries=entries, total_committed=total_committed, total_contacted=total_contacted, total_entries=total_entries)


@app.route('/update_pre_invite/<int:invite_id>', methods=['POST'])
def update_pre_invite(invite_id):
    invite = PreInvite.query.get_or_404(invite_id)
    invite.contacted = 'contacted' in request.form
    invite.committed = 'committed' in request.form
    invite.followed_up = 'followed_up' in request.form  # Handle the new checkbox
    invite.notes = request.form.get('notes', '')
    db.session.commit()
    return redirect(url_for('pre_invites'))



@app.route('/delete_pre_invite/<int:invite_id>', methods=['POST'])
def delete_pre_invite(invite_id):
    entry = PreInvite.query.get_or_404(invite_id)
    db.session.delete(entry)
    db.session.commit()
    flash('Pre-invite deleted successfully.', 'success')  # Optional: flash message for successful deletion
    return redirect(url_for('pre_invites'))



@app.context_processor
def inject_seeder_number():
    total_seeders = OfficialSeeder.query.count() 
    return {'total_seeders': total_seeders}


@app.context_processor
def inject_invite_count():
    total_invites = PreInvite.query.filter_by(committed=True).count()  # Filter for committed=True
    return {'total_invites': total_invites}


from flask import Flask, render_template, request, redirect, url_for


@app.route('/add_official_seeder', methods=['GET', 'POST'])
def add_official_seeder():
    if request.method == 'POST':
        # Handle the form submission
        full_name = request.form['full_name']
        file = request.files['profile_picture']
        alias = request.form.get('alias')
        types_lowercase = 'types_lowercase' in request.form
        state = request.form.get('state')
        industry = request.form.get('industry')
        neighborhood = request.form.get('neighborhood')
        
        if file and allowed_file(file.filename):
            filename = secure_filename(file.filename)
            specific_folder = 'static/images/profile_pics'
            file_path = os.path.join(specific_folder, filename)
            os.makedirs(specific_folder, exist_ok=True)
            file.save(file_path)
            # Normalize the path for URL usage
            normalized_path = os.path.join('images/profile_pics', filename).replace('\\', '/')
            profile_picture_url = url_for('static', filename=normalized_path)
        else:
            profile_picture_url = None  # Handle case where no file is uploaded or invalid file type
        
        seeder = OfficialSeeder(
            full_name=full_name, 
            profile_picture=profile_picture_url, 
            alias=alias,
            types_lowercase=types_lowercase,
            state=State[state] if state else None,
            industry=Industry[industry] if industry else None,
            neighborhood=Neighborhood[neighborhood] if neighborhood else None
        )
        db.session.add(seeder)
        db.session.commit()
    
    # Query seeders with their vault count
    seeders_with_vault_count = db.session.query(
        OfficialSeeder,
        func.count(Vault.id).label('vault_count')
    ).outerjoin(Vault).group_by(OfficialSeeder.id).order_by(func.count(Vault.id).asc()).all()
    return render_template('official_seeder.html', seeders=seeders_with_vault_count, State=State, Industry=Industry, Neighborhood=Neighborhood)


@app.route('/edit_official_seeder/<int:seeder_id>', methods=['GET', 'POST'])
def edit_official_seeder(seeder_id):
    seeder = OfficialSeeder.query.get_or_404(seeder_id)
    if request.method == 'POST':
        seeder.full_name = request.form['full_name']
        seeder.alias = request.form.get('alias')
        seeder.types_lowercase = 'types_lowercase' in request.form
        seeder.state = State[request.form.get('state')] if request.form.get('state') else None
        seeder.industry = Industry[request.form.get('industry')] if request.form.get('industry') else None
        seeder.neighborhood = Neighborhood[request.form.get('neighborhood')] if request.form.get('neighborhood') else None
        
        file = request.files.get('profile_picture')
        if file and allowed_file(file.filename):
            filename = secure_filename(file.filename)
            specific_folder = 'static/images/profile_pics'
            file_path = os.path.join(specific_folder, filename)
            os.makedirs(specific_folder, exist_ok=True)
            file.save(file_path)
            normalized_path = os.path.join('images/profile_pics', filename).replace('\\', '/')
            seeder.profile_picture = url_for('static', filename=normalized_path)
        
        db.session.commit()
        flash('Seeder updated successfully', 'success')
        return redirect(url_for('add_official_seeder'))
    
    return render_template('edit_official_seeder.html', seeder=seeder, State=State, Industry=Industry, Neighborhood=Neighborhood)

@app.route('/delete_official_seeder/<int:seeder_id>', methods=['POST'])
def delete_official_seeder(seeder_id):
    seeder = OfficialSeeder.query.get_or_404(seeder_id)
    try:
        # Delete associated facts
        Fact.query.filter_by(seeder_id=seeder_id).delete()
        # Delete the seeder
        db.session.delete(seeder)
        db.session.commit()
        return jsonify({"success": True, "message": "Seeder deleted successfully"})
    except Exception as e:
        db.session.rollback()
        return jsonify({"success": False, "error": str(e)}), 400


@app.route('/add_fact_to_seeder', methods=['POST'])
def add_fact_to_seeder():
    data = request.get_json()
    seeder_id = data['seeder_id']
    fact_text = data['fact_text']
    
    new_fact = Fact(fact_text=fact_text, seeder_id=seeder_id)
    db.session.add(new_fact)
    db.session.commit()

    return jsonify(success=True)


settings = {
    "k_value": 1.5,
    "w_value": 2,
    "feed_type": "hot"
}

@app.route('/feed_manager', methods=['GET', 'POST'])
def feed_manager():
    global settings
    if request.method == 'POST':
        settings['k_value'] = float(request.form.get('k_value', 1.5))
        settings['w_value'] = float(request.form.get('w_value', 2))
        settings['feed_type'] = request.form.get('feed_type', 'hot')
    return render_template('feed_manager.html', settings=settings)



@app.route('/view_seeder_vaults/<int:seeder_id>')
def view_seeder_vaults(seeder_id):
    seeder = OfficialSeeder.query.get_or_404(seeder_id)
    vaults = Vault.query.filter_by(seeder_id=seeder_id).all()
    return render_template('view_seeder_vaults.html', vaults=vaults, seeder=seeder)


@app.route('/community-edit')
def community_edit():
    # You can pass any other data your template might need here
    return render_template('community_edit.html')


@app.route('/schedule_vault/<int:vault_id>', methods=['POST'])
def schedule_vault(vault_id):
    vault = Vault.query.get(vault_id)
    try:
        scheduled_time = datetime.strptime(request.json['scheduled_at'], '%a, %d %b %Y %H:%M:%S GMT')
        scheduled_time = pytz.utc.localize(scheduled_time)
        vault.scheduled_at = scheduled_time
        db.session.commit()
        return jsonify(success=True)
    except Exception as e:
        return jsonify(success=False, error=str(e))


@app.route('/add_writing_style', methods=['GET', 'POST'])
def add_writing_style():
    if request.method == 'POST':
        author = request.form['author']
        content = request.form['content']
        new_style = WritingStyle(author=author, content=content)
        db.session.add(new_style)
        db.session.commit()
        flash('Writing Style Added Successfully!')
        return redirect(url_for('add_writing_style'))

    styles = WritingStyle.query.all()
    return render_template('add_writing_style.html', styles=styles)

@app.route('/delete_writing_style/<int:id>', methods=['POST'])
def delete_writing_style(id):
    style_to_delete = WritingStyle.query.get_or_404(id)
    db.session.delete(style_to_delete)
    db.session.commit()
    flash('Writing Style Deleted Successfully!')
    return redirect(url_for('add_writing_style'))




#miami scraper retry

from flask_cors import CORS

CORS(app)

from scrapy.crawler import CrawlerRunner
from twisted.internet import reactor





output_data = []



def scrape_with_crawler(url):
    global output_data
    output_data = []
    
    process = CrawlerProcess(get_project_settings())
    process.crawl(EventbriteSpider, url=url)
    process.start()

@app.route('/scraper')
def scraper_page():
    organizers = EventOrganizer.query.all()
    return render_template('scraper.html', organizers=organizers)

@app.route('/scrape', methods=['POST'])
def scrape():
    organizer_id = request.json['organizer_id']
    organizer = EventOrganizer.query.get(organizer_id)
    if not organizer:
        return jsonify({'error': 'Organizer not found'}), 404
    
    url = organizer.url
    app.logger.info(f"Starting scrape for URL: {url}")
    scrape_with_crochet(url)
    time.sleep(2)  # Allow some time for the scraping to complete
    return jsonify(output_data)


@app.route('/scrape-all-organizers-page')
def scraper_page_organizers():
    return render_template('scrape_all_organizers.html', organizers=organizers)


import time
from scrapy.crawler import CrawlerRunner
from scrapy.utils.project import get_project_settings
from twisted.internet import reactor
from twisted.internet.defer import inlineCallbacks, returnValue

@app.route('/scrape_all', methods=['POST'])
def scrape_all():
    runner = CrawlerRunner(get_project_settings())
    
    @inlineCallbacks
    def crawl_sequentially():
        app.logger.info("Starting bulk scrape")
        organizers = EventOrganizer.query.all()
        total = len(organizers)
        results = []

        for index, organizer in enumerate(organizers, 1):
            if not organizer.url:
                app.logger.info(f"Skipping organizer: {organizer.name} (No URL provided)")
                results.append({"organizer": organizer.name, "status": "skipped", "message": "No URL provided"})
                continue

            app.logger.info(f"Processing organizer: {organizer.name} ({index}/{total})")
            try:
                app.logger.info(f"Starting scrape for {organizer.name}")
                yield runner.crawl(EventbriteSpider, url=organizer.url)
                app.logger.info(f"Scrape completed for {organizer.name}")
                app.logger.info(f"Processing and saving events for {organizer.name}")
                process_and_save_events()
                app.logger.info(f"Events processed and saved for {organizer.name}")
                results.append({"organizer": organizer.name, "status": "success"})
            except Exception as e:
                app.logger.error(f"Error processing {organizer.name}: {str(e)}", exc_info=True)
                results.append({"organizer": organizer.name, "status": "error", "message": str(e)})

        app.logger.info("Bulk scrape completed")
        returnValue(results)

    def scrape_complete(results):
        app.logger.info("All scraping completed")
        reactor.stop()
        return jsonify({"message": "Bulk scraping completed", "results": results})

    crawl_sequentially().addCallback(scrape_complete)
    reactor.run(installSignalHandlers=False)
    
    return "Scraping in progress. Check logs for details."


def process_and_save_events():
    try:
        with open('output.json', 'r') as file:
            events_data = json.load(file)
        
        one_week_ago = datetime.utcnow() - timedelta(days=7)
        for event in events_data:
            event_start_time = datetime.fromisoformat(event['start_time'])
            if event_start_time >= one_week_ago:
                exists = Event.query.filter_by(
                    name=event['name'],
                    start_time=event_start_time,
                    location=event['location']
                ).first() is not None
                if not exists:
                    new_event = Event(
                        name=event['name'],
                        venue_name=event['venue_name'],
                        location=event['location'],
                        start_time=event_start_time,
                        end_time=datetime.fromisoformat(event['end_time'])
                    )
                    db.session.add(new_event)
        db.session.commit()
        os.remove('output.json')
    except Exception as e:
        db.session.rollback()
        raise e



@app.route('/events', methods=['GET', 'POST'])
def events():
    if request.method == 'POST':
        # Attempt to load JSON data from 'output.json'
        try:
            with open('output.json', 'r') as file:
                events_data = json.load(file)
            # Calculate the cutoff date which is one week ago
            one_week_ago = datetime.utcnow() - timedelta(days=7)
            for event in events_data:
                event_start_time = datetime.fromisoformat(event['start_time'])
                # Check if the event is newer than one week ago
                if event_start_time >= one_week_ago:
                    # Check if event already exists based on name, start_time, and location
                    exists = Event.query.filter_by(
                        name=event['name'],
                        start_time=event_start_time,
                        location=event['location']
                    ).first() is not None
                    if not exists:
                        new_event = Event(
                            name=event['name'],
                            venue_name=event['venue_name'],
                            location=event['location'],
                            start_time=event_start_time,
                            end_time=datetime.fromisoformat(event['end_time'])
                        )
                        db.session.add(new_event)
            db.session.commit()
            os.remove('output.json')
            flash('Events loaded and file cleaned up successfully!', 'success')
        except Exception as e:
            flash(str(e), 'danger')
        return redirect(url_for('events'))
    
    events = Event.query.all()
    return render_template('events.html', events=events)





@app.route('/organizers', methods=['GET', 'POST'])
def organizers():
    if request.method == 'POST':
        name = request.form.get('name')
        url = request.form.get('url')
        instagram_username = request.form.get('instagram_username')
        if name:
            organizer = EventOrganizer(name=name, url=url, instagram_username=instagram_username)
            db.session.add(organizer)
            db.session.commit()
            flash('Organizer added successfully!', 'success')
        return redirect(url_for('organizers'))
    organizers = EventOrganizer.query.all()
    return render_template('organizers.html', organizers=organizers)

@app.route('/organizers/delete/<int:id>')
def delete_organizer(id):
    organizer = EventOrganizer.query.get_or_404(id)
    db.session.delete(organizer)
    db.session.commit()
    flash('Organizer deleted successfully!', 'success')
    return redirect(url_for('organizers'))


from scrapy.crawler import CrawlerRunner
from twisted.internet import reactor
from scrapy.utils.log import configure_logging



from flask import render_template, jsonify, request, flash, redirect, url_for
from sqlalchemy.exc import IntegrityError

from playwright.sync_api import sync_playwright
import time

def scrape_eventbrite(url):
    with sync_playwright() as playwright:
        browser = playwright.chromium.launch(headless=True)
        page = browser.new_page()
        page.goto(url)
        page.wait_for_selector(".eds-structure__main")
        for _ in range(5):
            page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            time.sleep(2)
        links = page.evaluate("""
            () => {
                const links = [];
                document.querySelectorAll('a[href*="/e/"][class*="event-card-link"]').forEach(link => {
                    links.push(link.href);
                });
                return links;
            }
        """)
        browser.close()
        return list(set(links))

import logging
from flask import current_app

@app.route('/run-scraper', methods=['GET', 'POST'])
def run_scraper():
    categories = [category.value for category in CategoryEnum]
    categories.insert(0, 'ALL')
    selected_category = request.form.get('category') or request.args.get('category') or categories[0]
    
    
    
    if request.method == 'POST' and 'run_scraper' in request.form:
        client = ApifyClient(os.environ.get('APIFY_API_TOKEN'))
        
        # Get URLs for the selected category (or all categories) from SelectedURLs
        if selected_category == 'ALL':
            urls = SelectedURLs.query.filter_by(is_active=True).all()
        else:
            urls = SelectedURLs.query.filter_by(category=selected_category, is_active=True).all()

        
        
        new_results = 0
        skipped_results = 0
        
        for url in urls:
            if url.url == "https://www.JobTrigger.com" and url.category == CategoryEnum.CAREER:
                # Use LinkedIn jobs scraper
                run_input = {
                    "contractType": "F",
                    "experienceLevel": "3",
                    "location": "Miami",
                    "proxy": {
                        "useApifyProxy": True,
                        "apifyProxyGroups": [
                            "RESIDENTIAL"
                        ]
                    },
                    "publishedAt": "r604800",
                    "rows": 200,
                    "workType": "1",
                    "title": ""
                }
                
                run = client.actor("bebity/linkedin-jobs-scraper").call(run_input=run_input)
                
                
                unique_companies = {}
                
                for item in client.dataset(run["defaultDatasetId"]).iterate_items():
                    company_name = item.get('companyName', '')
                    
                    if company_name not in unique_companies:
                        unique_companies[company_name] = item
                
                for company_name, item in unique_companies.items():
                    existing_result = ScraperResult.query.filter_by(url=item.get('jobUrl', '')).first()
                    
                    if not existing_result:
                        scraper_result = ScraperResult(
                            url=item.get('jobUrl', ''),
                            title=item.get('title', ''),
                            text=f"Company: {company_name}\n"
                                 f"Location: {item.get('location', '')}\n"
                                 f"Posted: {item.get('postedTime', '')}\n"
                                 f"Contract Type: {item.get('contractType', '')}\n"
                                 f"Experience Level: {item.get('experienceLevel', '')}\n"
                                 f"Description: {item.get('description', '')}",
                            category=CategoryEnum.CAREER
                        )
                        db.session.add(scraper_result)
                        try:
                            db.session.commit()
                            new_results += 1
                            current_app.logger.debug(f"Added new LinkedIn job result for company: {company_name}")
                        except IntegrityError:
                            db.session.rollback()
                            skipped_results += 1
                            current_app.logger.warning(f"IntegrityError for LinkedIn job URL: {item.get('jobUrl', '')}")
                    else:
                        skipped_results += 1
                        current_app.logger.debug(f"Skipped existing LinkedIn job result for company: {company_name}")

            elif url.scraper_type == 'Puppeteer':
                # Use Puppeteer scraper
                run_input = {
                    "startUrls": [{"url": url.url}],
                    "maxCrawlingDepth": 2,
                    "linkSelector": url.link_selector,
                    "pageFunction": url.page_function
                }
                
                run = client.actor("apify/puppeteer-scraper").call(run_input=run_input)
                
                for item in client.dataset(run["defaultDatasetId"]).iterate_items():
                    current_app.logger.debug(f"Processing Puppeteer item: {item.get('url', '')}")
                    existing_result = ScraperResult.query.filter_by(url=item.get('url', '')).first()
                    
                    if not existing_result:
                        scraper_result = ScraperResult(
                            url=item.get('url', ''),
                            title=item.get('title', ''),
                            text=item.get('content', ''),  # Assuming 'content' field contains the main text
                            category=url.category
                        )
                        db.session.add(scraper_result)
                        try:
                            db.session.commit()
                            new_results += 1
                            current_app.logger.debug(f"Added new Puppeteer result: {item.get('url', '')}")
                        except IntegrityError:
                            db.session.rollback()
                            skipped_results += 1
                            current_app.logger.warning(f"IntegrityError for Puppeteer URL: {item.get('url', '')}")
                    else:
                        skipped_results += 1
                        current_app.logger.debug(f"Skipped existing Puppeteer result: {item.get('url', '')}")

            else:
                # Use website content crawler for other URLs
                run_input = {
                    "startUrls": [{"url": url.url}],
                    "maxCrawlDepth": 1 if not url.is_eventbrite else 0
                }
                
                if url.is_eventbrite:
                    
                    eventbrite_links = scrape_eventbrite(url.url)
                    
                    run_input["startUrls"] = [{"url": link} for link in eventbrite_links]
                
                
                run = client.actor("apify/website-content-crawler").call(run_input=run_input)
                
                
                for item in client.dataset(run["defaultDatasetId"]).iterate_items():
                    current_app.logger.debug(f"Processing item: {item.get('url', '')}")
                    existing_result = ScraperResult.query.filter_by(url=item.get('url', '')).first()
                    
                    if not existing_result:
                        scraper_result = ScraperResult(
                            url=item.get('url', ''),
                            title=item.get('title', ''),
                            text=item.get('text', ''),
                            category=url.category
                        )
                        db.session.add(scraper_result)
                        try:
                            db.session.commit()
                            new_results += 1
                            current_app.logger.debug(f"Added new result: {item.get('url', '')}")
                        except IntegrityError:
                            db.session.rollback()
                            skipped_results += 1
                            current_app.logger.warning(f"IntegrityError for URL: {item.get('url', '')}")
                    else:
                        skipped_results += 1
                        current_app.logger.debug(f"Skipped existing result: {item.get('url', '')}")
        
        current_app.logger.info(f"Scraper completed. New results: {new_results}, Skipped: {skipped_results}")
        flash(f"Scraper completed for {selected_category}. {new_results} new results saved. {skipped_results} existing results skipped.", "success")
    
    # Fetch results based on selected category
    if selected_category == 'ALL':
        results = ScraperResult.query.order_by(ScraperResult.scrape_date.desc()).all()
    else:
        results = ScraperResult.query.filter_by(category=selected_category).order_by(ScraperResult.scrape_date.desc()).all()
    current_app.logger.info(f"Fetched {len(results)} results for display")
    return render_template('run_scraper.html', categories=categories, selected_category=selected_category, results=results)

#instagram scraper
@app.route('/instagram-scraper')
def instagram_scraper_page():
    organizers = EventOrganizer.query.filter(EventOrganizer.instagram_username.isnot(None)).all()
    return render_template('instagram_scraper.html', organizers=organizers)

@app.route('/run-instagram-scraper', methods=['POST'])
def run_instagram_scraper():
    organizer_id = request.json.get('organizer_id')
    organizer = EventOrganizer.query.get_or_404(organizer_id)

    if not organizer.instagram_username:
        return jsonify({"error": "Selected organizer does not have an Instagram username"}), 400

    client = ApifyClient(os.environ.get('APIFY_API_TOKEN'))
    run_input = {
        "username": [organizer.instagram_username],
        "resultsLimit": 30,
    }
    run = client.actor("apify/instagram-post-scraper").call(run_input=run_input)
    
    results = []
    for item in client.dataset(run["defaultDatasetId"]).iterate_items():
        results.append(item)

    return jsonify({
        "dataset_url": f"https://console.apify.com/storage/datasets/{run['defaultDatasetId']}",
        "results": results
    })


#Json cleaner


@app.route('/upload-venues', methods=['GET', 'POST'])
def upload_venues():
    if request.method == 'POST':
        if 'jsonFile' not in request.files:
            flash('No file part')
            return redirect(request.url)
        
        file = request.files['jsonFile']
        source = request.form.get('source')  # Get the selected source from the dropdown
        
        if file.filename == '':
            flash('No selected file')
            return redirect(request.url)
        
        if file and file.filename.endswith('.json'):
            try:
                venues_data = json.load(file)
                for index, venue_data in enumerate(venues_data):
                    print(f"Processing venue {index + 1}:")
                    print(json.dumps(venue_data, indent=2))
                    try:
                        if source == 'google_maps':
                            venue = process_google_maps_venue(venue_data)
                        elif source == 'tripadvisor':
                            venue = process_tripadvisor_venue(venue_data)
                        else:
                            raise ValueError("Invalid source selected")
                        
                        db.session.add(venue)
                        print(f"Successfully processed venue {index + 1}")
                    except Exception as e:
                        print(f"Error processing venue {index + 1}: {str(e)}")
                        # Optionally, you can choose to continue with the next venue
                        # instead of stopping the entire process
                        continue
                
                db.session.commit()
                message = f"Successfully uploaded {len(venues_data)} venues from {source}."
            except Exception as e:
                db.session.rollback()
                message = f"An error occurred: {str(e)}"
                print(f"Error details: {str(e)}")
            
            return render_template('upload_venues.html', message=message)
    
    return render_template('upload_venues.html')

def process_google_maps_venue(venue_data):
    return Venue(
        title=venue_data['title'][:500],
        description=venue_data['description'],
        price=venue_data['price'][:20] if venue_data['price'] else None,
        category_name=venue_data['categoryName'][:200] if venue_data['categoryName'] else None,
        neighborhood=venue_data['neighborhood'][:200] if venue_data['neighborhood'] else None,
        street=venue_data['street'][:500] if venue_data['street'] else None,
        city=venue_data['city'][:200] if venue_data['city'] else None,
        postal_code=venue_data['postalCode'][:50] if venue_data['postalCode'] else None,
        website=venue_data['website'][:1000] if venue_data['website'] else None,
        menu=venue_data['menu'][:1000] if venue_data['menu'] else None,
        permanently_closed=venue_data['permanentlyClosed'],
        total_score=venue_data['totalScore'],
        temporarily_closed=venue_data['temporarilyClosed'],
        reviews_count=venue_data['reviewsCount']
    )

def process_tripadvisor_venue(venue_data):
    subcategories = venue_data.get('subcategories', [])
    category_name = subcategories[0] if subcategories else "attraction"
    
    address_obj = venue_data.get('addressObj', {})
    
    return Venue(
        title=venue_data.get('localName', '')[:500],
        description=venue_data.get('description', ''),
        price=None,
        category_name=category_name[:200] if category_name else None,
        neighborhood=None,
        street=address_obj.get('street1', '')[:500],
        city=address_obj.get('city', '')[:200],
        postal_code=address_obj.get('postalcode', '')[:50],
        website=venue_data.get('website', '')[:1000],
        menu=None,
        permanently_closed=venue_data.get('isLongClosed', False),
        total_score=venue_data.get('rating'),
        temporarily_closed=venue_data.get('isClosed', False),
        reviews_count=venue_data.get('numberOfReviews')
    )


@app.route('/random-venue', methods=['GET', 'POST'])
def random_venue():
    venue = None
    if request.method == 'POST':
        # Select a random venue and eagerly load its reviews
        venue = Venue.query.options(joinedload(Venue.reviews)).order_by(func.random()).first()
    
    return render_template('random_venue.html', venue=venue)


from flask import jsonify
import random

@app.route('/random_venue2')
def random_venue2():
    try:
        venue_count = Venue.query.count()
        random_index = random.randint(0, venue_count - 1)
        venue = Venue.query.offset(random_index).first()
        venue_data = {
            "title": venue.title,
            "reviews_count": venue.reviews_count,  # Assuming each review has a 'text' attribute
            "neighborhood": venue.neighborhood,
            "google_search_url": venue.google_search_url
        }
        return jsonify(venue_data)
    except Exception as e:
        return jsonify({"error": str(e)}), 500




@app.route('/manage-urls', methods=['GET', 'POST'])
def manage_urls():
    if request.method == 'POST':
        if 'add_url' in request.form or 'edit_url' in request.form:
            url = request.form.get('url')
            category = request.form.get('category')
            is_eventbrite = request.form.get('is_eventbrite') == 'on'
            scraper_type = request.form.get('scraper_type')
            link_selector = request.form.get('link_selector')
            page_function = request.form.get('page_function')
            
            if url and category and scraper_type:
                try:
                    if 'add_url' in request.form:
                        new_url = SelectedURLs(url=url, category=CategoryEnum[category], is_eventbrite=is_eventbrite,
                                               scraper_type=scraper_type, link_selector=link_selector, page_function=page_function)
                        db.session.add(new_url)
                        flash("URL added successfully!", "success")
                    else:  # edit_url
                        url_id = request.form.get('url_id')
                        url_obj = SelectedURLs.query.get(url_id)
                        if url_obj:
                            url_obj.url = url
                            url_obj.category = CategoryEnum[category]
                            url_obj.is_eventbrite = is_eventbrite
                            url_obj.scraper_type = scraper_type
                            url_obj.link_selector = link_selector
                            url_obj.page_function = page_function
                            flash("URL updated successfully!", "success")
                        else:
                            flash("URL not found.", "error")
                    db.session.commit()
                except IntegrityError:
                    db.session.rollback()
                    flash("This URL already exists.", "error")
            else:
                flash("Please provide URL, category, and scraper type.", "error")
        elif 'toggle_active' in request.form:
            url_id = request.form.get('url_id')
            url_obj = SelectedURLs.query.get(url_id)
            if url_obj:
                url_obj.is_active = not url_obj.is_active
                db.session.commit()
                flash(f"URL {'activated' if url_obj.is_active else 'deactivated'} successfully!", "success")
            else:
                flash("URL not found.", "error")
        elif 'delete_url' in request.form:
            url_id = request.form.get('url_id')
            url_obj = SelectedURLs.query.get(url_id)
            if url_obj:
                db.session.delete(url_obj)
                db.session.commit()
                flash("URL deleted successfully!", "success")
            else:
                flash("URL not found.", "error")
    
    urls = SelectedURLs.query.order_by(SelectedURLs.category).all()
    return render_template('manage_urls.html', urls=urls, categories=CategoryEnum)




#menu scraper

from flask import current_app
from playwright.sync_api import sync_playwright, TimeoutError as PlaywrightTimeoutError
import json

def scrape_menu(venue):
    current_app.logger.debug(f"Starting to scrape menu for venue: {venue.title}")
    menu_items = []
    with sync_playwright() as p:
        try:
            browser = p.chromium.launch(headless=True)
            page = browser.new_page()

            current_app.logger.debug(f"Navigating to: {venue.google_search_url}")
            page.goto(venue.google_search_url)

            try:
                not_now_button = page.locator("text='Not now'").first
                not_now_button.click(timeout=5000)
            except PlaywrightTimeoutError:
                current_app.logger.debug("Pop-up not found or couldn't be closed. Proceeding anyway.")

            try:
                menu_button = page.locator("[data-id='menu-viewer-entrypoint'] span:has-text('Menu')").first
                menu_button.click(timeout=5000)
            except PlaywrightTimeoutError:
                current_app.logger.debug("Couldn't find or click the Menu button. Skipping this venue.")
                return []

            try:
                page.wait_for_selector("[data-menu-item-id]", timeout=10000)
            except PlaywrightTimeoutError:
                current_app.logger.debug("Menu items didn't load in time. Skipping this venue.")
                return []

            menu_item_elements = page.query_selector_all("[data-menu-item-id]")

            for item in menu_item_elements:
                full_text = item.inner_text()
                parts = full_text.rsplit(' ', 1)
                
                if len(parts) == 2:
                    name, price = parts
                else:
                    name = full_text
                    price = "N/A"
                
                menu_items.append({"name": name.strip(), "price": price.strip()})
                current_app.logger.debug(f"Added menu item: {name.strip()} - {price.strip()}")

        except Exception as e:
            current_app.logger.error(f"An error occurred while scraping {venue.title}: {str(e)}")
        finally:
            browser.close()

    current_app.logger.debug(f"Finished scraping menu for venue: {venue.title}")
    return json.dumps(menu_items)


@app.route('/admin/start_scrape', methods=['POST'])
def start_scrape():
    venues = Venue.query.all()
    for venue in venues:
        current_app.logger.debug(f"Processing venue: {venue.title}")
        menu_items = scrape_menu(venue)
        
        # Convert menu_items to a PostgreSQL array
        menu_array = menu_items
        
        # Update the venue's menu using SQLAlchemy
        venue.menu = menu_array
        db.session.commit()
        
        current_app.logger.debug(f"Updated menu for venue: {venue.title}")
    
    # Commit all changes at once
    current_app.logger.debug("Scraping process completed.")
    return redirect(url_for('admin_scrape'))




@app.route('/admin/scrape', methods=['GET'])
def admin_scrape():
    return render_template('admin_scrape.html')



##comment similarity yuhh ###


from flask import Flask, render_template, request, jsonify
from flask_sqlalchemy import SQLAlchemy
from datetime import datetime
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
import numpy as np
import faiss
import pickle
import os
import json





#save embeddings so we don't need to keep running it



# Initialize SentenceTransformer model
# Initialize SentenceTransformer model
model = SentenceTransformer('all-MiniLM-L6-v2')

# Initialize FAISS index
embedding_size = 384  # Depends on the model you're using
# Initialize FAISS indexes
venue_index = None
event_index = None
venue_ids = None
event_ids = None
embeddings_initialized = False


@app.before_request
def ensure_embeddings_initialized():
    global embeddings_initialized
    if not embeddings_initialized:
        initialize_embeddings()
        embeddings_initialized = True


def generate_and_save_venue_embeddings(index_file='venue_index.faiss', id_file='venue_ids.pkl'):
    venues = Venue.query.all()
    embeddings = []
    ids = []
    
    for venue in venues:
        venue_text = f"""
        Title: {venue.title}
        Category: {venue.category_name}
        Neighborhood: {venue.neighborhood}
        Address: {venue.street}, {venue.city}, {venue.postal_code}
        Description: {venue.description}
        """
        
        if venue.menu:
            try:
                menu_text = json.dumps(venue.menu)
                venue_text += f"\nMenu: {menu_text}"
            except:
                pass
        
        # Handle potential None values in review texts
        review_texts = ' '.join([review.text or '' for review in venue.reviews])
        combined_text = f"{venue_text}\nReviews: {review_texts}"
        
        embedding = model.encode(combined_text)
        embeddings.append(embedding)
        ids.append(venue.id)
    
    index = faiss.IndexFlatL2(embedding_size)
    index.add(np.array(embeddings))
    
    faiss.write_index(index, index_file)
    with open(id_file, 'wb') as f:
        pickle.dump(ids, f)
    
    return index, ids


def generate_and_save_event_embeddings(index_file='event_index.faiss', id_file='event_ids.pkl'):
    events = ScraperResult.query.all()
    embeddings = []
    ids = []
    
    for event in events:
        embedding = model.encode(event.text)
        embeddings.append(embedding)
        ids.append(event.id)
    
    index = faiss.IndexFlatL2(embedding_size)
    index.add(np.array(embeddings))
    
    faiss.write_index(index, index_file)
    with open(id_file, 'wb') as f:
        pickle.dump(ids, f)
    
    return index, ids



def load_embeddings(index_file, id_file):
    if os.path.exists(index_file) and os.path.exists(id_file):
        index = faiss.read_index(index_file)
        with open(id_file, 'rb') as f:
            ids = pickle.load(f)
        return index, ids
    else:
        return None, None


def find_top_k_similar_venues(post_text, k=5):
    post_embedding = model.encode(post_text)
    D, I = venue_index.search(np.array([post_embedding]), k)
    return [Venue.query.get(venue_ids[i]) for i in I[0]]

def find_top_k_similar_events(post_text, k=5):
    post_embedding = model.encode(post_text)
    D, I = event_index.search(np.array([post_embedding]), k)
    return [ScraperResult.query.get(event_ids[i]) for i in I[0]]



def semantic_similarity(item1, item2):
    text1 = get_item_text(item1)
    text2 = get_item_text(item2)
    embedding1 = model.encode(text1)
    embedding2 = model.encode(text2)
    return np.dot(embedding1, embedding2) / (np.linalg.norm(embedding1) * np.linalg.norm(embedding2))

def get_item_text(item):
    if isinstance(item, Venue):
        return f"{item.title} {item.description} {item.category_name} {item.neighborhood}"
    elif isinstance(item, ScraperResult):
        return item.text
    else:
        return ""


def select_diverse_item(items, post_text, similarity_threshold=0.7):
    if not items:
        return None

    post_embedding = model.encode(post_text)
    item_embeddings = [model.encode(get_item_text(item)) for item in items]
    
    similarities_to_post = [np.dot(post_embedding, item_emb) / (np.linalg.norm(post_embedding) * np.linalg.norm(item_emb)) for item_emb in item_embeddings]
    
    diversity_scores = []
    for i, item_emb in enumerate(item_embeddings):
        other_embeddings = item_embeddings[:i] + item_embeddings[i+1:]
        similarities = [np.dot(item_emb, other_emb) / (np.linalg.norm(item_emb) * np.linalg.norm(other_emb)) for other_emb in other_embeddings]
        diversity_score = 1 - (sum(similarities) / len(similarities) if similarities else 0)
        diversity_scores.append(diversity_score)
    
    # Combine similarity to post and diversity
    combined_scores = [sim * div for sim, div in zip(similarities_to_post, diversity_scores)]
    
    # Filter items that are sufficiently similar to the post
    valid_items = [(item, score) for item, sim, score in zip(items, similarities_to_post, combined_scores) if sim >= similarity_threshold]
    
    if not valid_items:
        return items[0]  # Return the most similar item if no items meet the threshold
    
    # Return the item with the highest combined score
    return max(valid_items, key=lambda x: x[1])[0]


def find_diverse_recommendations(post_text, item_type='venue', k=10, similarity_threshold=0.7, num_recommendations=10):
    if item_type == 'venue':
        top_items = find_top_k_similar_venues(post_text, k)
    else:
        top_items = find_top_k_similar_events(post_text, k)
    
    if not top_items:
        return []

    post_embedding = model.encode(post_text)
    item_embeddings = [model.encode(get_item_text(item)) for item in top_items]
    
    # Calculate similarities to the post
    similarities_to_post = [np.dot(post_embedding, item_emb) / (np.linalg.norm(post_embedding) * np.linalg.norm(item_emb)) for item_emb in item_embeddings]
    
    # Calculate diversity scores
    diversity_scores = []
    for i, item_emb in enumerate(item_embeddings):
        other_embeddings = item_embeddings[:i] + item_embeddings[i+1:]
        similarities = [np.dot(item_emb, other_emb) / (np.linalg.norm(item_emb) * np.linalg.norm(other_emb)) for other_emb in other_embeddings]
        diversity_score = 1 - (sum(similarities) / len(similarities) if similarities else 0)
        diversity_scores.append(diversity_score)
    
    # Combine similarity to post and diversity
    combined_scores = [sim * div for sim, div in zip(similarities_to_post, diversity_scores)]
    
    # Filter items that are sufficiently similar to the post
    valid_items = [(item, score) for item, sim, score in zip(top_items, similarities_to_post, combined_scores) if sim >= similarity_threshold]
    
    if not valid_items:
        return top_items[:num_recommendations]  # Return the most similar items if no items meet the threshold
    
    # Sort by combined score and return the top num_recommendations
    return [item for item, _ in sorted(valid_items, key=lambda x: x[1], reverse=True)[:num_recommendations]]

@app.route('/generate_comment', methods=['POST'])
def generate_comment():
    ensure_embeddings_initialized()
    
    post_text = request.json['post_text']
    recommendation_type = request.json['type']
    
    similar_item = find_diverse_recommendation(post_text, recommendation_type)
    
    if similar_item:
        if recommendation_type == 'venue':
            title = similar_item.title or "Unknown Venue"
            neighborhood = similar_item.neighborhood or "Unknown Location"
            description = similar_item.description or "No description available"
            comment = f"Based on your post, I recommend checking out {title} in {neighborhood}. {description[:100]}..."
        else:  # event
            title = similar_item.title or "Unknown Event"
            text = similar_item.text or "No details available"
            comment = f"Based on your post, I remembered a similar local event: {title}. {text[:100]}..."
    else:
        comment = f"Sorry, I couldn't find a suitable {recommendation_type} recommendation at this time."
    
    return jsonify({'comment': comment})

@app.route('/admin/generate_comment')
def admin_generate_comment():
    ensure_embeddings_initialized()
    
    return render_template('generate_comment.html')





def initialize_embeddings():
    with app.app_context():
        global venue_index, venue_ids, event_index, event_ids
        venue_index, venue_ids = load_embeddings('venue_index.faiss', 'venue_ids.pkl')
        if venue_index is None:
            venue_index, venue_ids = generate_and_save_venue_embeddings()

        event_index, event_ids = load_embeddings('event_index.faiss', 'event_ids.pkl')
        if event_index is None:
            event_index, event_ids = generate_and_save_event_embeddings()




def load_json_data(file_path):
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            return json.load(file)
    except UnicodeDecodeError:
        # If UTF-8 fails, try with 'iso-8859-1' encoding
        with open(file_path, 'r', encoding='iso-8859-1') as file:
            return json.load(file)

def categorize_venues(category):
    json_file_path = "restaurants.json"  # File in root directory
    try:
        json_data = load_json_data(json_file_path)
    except Exception as e:
        return f"Error loading JSON file: {str(e)}"

    for item in json_data:
        # Try to find an existing venue
        venue = Venue.query.filter_by(
            title=item['title'],
            street=item['street'],
            city=item['city']
        ).first()


        if venue:
            # Update existing venue's main_category
            venue.main_category = category

    db.session.commit()
    return f"Categorization complete. Category: {category}"

@app.route('/categorize/<category>')
def categorize_route(category):
    try:
        result = categorize_venues(category)
        return jsonify({"message": result}), 200
    except Exception as e:
        return jsonify({"error": str(e)}), 500



if __name__ == '__main__':
    
    app.run(debug=True)
